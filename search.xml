<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Beautify The Mac Bash Base on iTerm2 And oh-my-zsh</title>
    <url>/2022/04/02/%20Beautify-The-Mac-Bash/</url>
    <content><![CDATA[<p>在公司实习需要使用mac电脑来进行工作，其中bash是非常重要的工具，本文也是对bash进行了美化，提升使用的效率。<br>本文采用的方案是利用ITerm2 与 oh-my-zsh来进行美化,同时也要将其配置在vscode中。</p>
<p>在配置的过程中，发现如果路径层级过长，主机名的信息较长，会导致代码容易换行，影响观看。所以选了隐藏路径以及主机名，仅保留当前文件名，效果如图所示：</p>
<p><img src="/2022/04/02/%20Beautify-The-Mac-Bash/demo.jpg" alt="demo show1"></p>
<span id="more"></span>

<h1 id="1-Iterm2安装及其陪配置"><a href="#1-Iterm2安装及其陪配置" class="headerlink" title="1. Iterm2安装及其陪配置"></a>1. Iterm2安装及其陪配置</h1><p>手动安装: <a href="https://iterm2.com/">打开Iterm2 的官方网址</a>，下载相应的Iterm2 安装包，并安装。<br>Homebrew安装: 为了方便后期管理，采用homebrew进行安装。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># use brew to install iterm2</span></span><br><span class="line">brew install iTerm2</span><br></pre></td></tr></table></figure>

<p>设置iTerm2为默认的终端</p>
<center>
    <img src="/2022/04/02/%20Beautify-The-Mac-Bash/default-iterm2.jpg" width="80%">
</center>

<p>设置iTerm2的字体为 <em>Meslo LG L DZ for powerline</em>，之后vscode的terminal字体也设置为<em>Meslo LG L DZ for powerline</em>。</p>
<h1 id="2-oh-my-zsh"><a href="#2-oh-my-zsh" class="headerlink" title="2. oh-my-zsh"></a>2. oh-my-zsh</h1><p> 首先，在进入oh-my-zsh之前，要先了解zsh。</p>
<blockquote>
<p> <strong>zsh又称为z-shell</strong>，是一款可用作交互式登录的shell及脚本编写的命令解释器。Zsh对Bourne shell做出了大量改进，同时加入了Bash、ksh及tcsh的某些功能。自2019年起，macOS的默认Shell已从Bash改为Zsh。</p>
</blockquote>
<p> zsh 有如下几个特点：</p>
<ul>
<li>可帮助用户键入常用命令选项及参数的可编程命令行补全功能，自带对数百条命令的支持</li>
<li>可与任意Shell共享命令历史</li>
<li>多种兼容模式（例如，Zsh可在运行为&#x2F;bin&#x2F;sh的情况下伪装成Bourne shell）</li>
<li>自带where命令，其与which命令类似，但是显示指定于$PATH中所指定指令的全部位置，而不是仅显示所使用指令的位置。</li>
</ul>
<p>其中，用户社区网站”Oh My Zsh”收集Z shell的第三方插件及主题。</p>
<p>本文也是利用oh-my-zsh来美化oh-my-zsh，利用如下指令进行安装，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># curl 安装</span></span><br><span class="line"><span class="built_in">export</span> REMOTE=https://gitee.com/imirror/ohmyzsh.git</span><br><span class="line">sh -c <span class="string">&quot;<span class="subst">$(curl -fsSL https://cdn.jsdelivr.net/gh/ohmyzsh/ohmyzsh/tools/install.sh)</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># wget安装</span></span><br><span class="line"><span class="built_in">export</span> REMOTE=https://gitee.com/imirror/ohmyzsh.git</span><br><span class="line">sh -c <span class="string">&quot;<span class="subst">$(wget -O- https://cdn.jsdelivr.net/gh/ohmyzsh/ohmyzsh/tools/install.sh)</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fetch安装</span></span><br><span class="line"><span class="built_in">export</span> REMOTE=https://gitee.com/imirror/ohmyzsh.git</span><br><span class="line">sh -c <span class="string">&quot;<span class="subst">$(fetch -o - https://cdn.jsdelivr.net/gh/ohmyzsh/ohmyzsh/tools/install.sh)</span>&quot;</span></span><br></pre></td></tr></table></figure>
<p>安装界面如下：</p>
<center>
<img src="/2022/04/02/%20Beautify-The-Mac-Bash/oh-my-zsh安装.jpg" width="80%">
</center>

<h1 id="3-主题配置"><a href="#3-主题配置" class="headerlink" title="3. 主题配置"></a>3. 主题配置</h1><p>oh-my-zsh主题很多，其中 <em>agnoster</em> 是比较常用的主题，本文也是打算使用该主题（更多的主题可以查看<a href="https://github.com/ohmyzsh/ohmyzsh/wiki/Themes">theme主题</a>。</p>
<h1 id="3-1-ZSH-THEME配置"><a href="#3-1-ZSH-THEME配置" class="headerlink" title="3.1 ZSH_THEME配置"></a>3.1 ZSH_THEME配置</h1><p>打开 ~&#x2F;.zshrc,修改ZSH-THEME这一配置.</p>
<blockquote>
<p><em>zshrc</em> file is where <em>you’d place customizations to the z shell</em>.</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ZSH_THEME =&quot;agnoster</span><br></pre></td></tr></table></figure>
<center>
<img src="/2022/04/02/%20Beautify-The-Mac-Bash/ZSH_THEME.jpg" width="80%">
</center>

<h1 id="3-2-字体安装与配置"><a href="#3-2-字体安装与配置" class="headerlink" title="3.2  字体安装与配置"></a>3.2  字体安装与配置</h1><p>注意agnoster需要安装额外的字体<a href="https://cdn.jsdelivr.net/gh/powerline/fonts/Meslo%20Slashed/Meslo%20LG%20S%20Regular%20for%20Powerline.ttf">Meslo for Powerline</a>,　下载安装相应的ttf文件。</p>
<p>配置完字体之后，打开iTerm -&gt; Preferences -&gt; Profiles -&gt; Text -&gt; Change Font，选择Meslo LG S Regular for Powerline。</p>
<center>
    <img src="/2022/04/02/%20Beautify-The-Mac-Bash/iterm-pref.jpg" , width="80%">
</center>


<center>
    <img src="/2022/04/02/%20Beautify-The-Mac-Bash/zsh-font.jpg" , width="80%">
</center>

<center>
    <img src="/2022/04/02/%20Beautify-The-Mac-Bash/zsh-demo.jpg" , width="80%">
</center>

<h1 id="4-优化zsh"><a href="#4-优化zsh" class="headerlink" title="4. 优化zsh"></a>4. 优化zsh</h1><p>在3.2 中，看到安装oh-my-zsh后的效果。但是存在一定的不足，比如命令行开头都有主机名，文件路径，能够看到当层级增多的时候，会显得非常的长，影响输入，需要一定的优化。笔者选择的方式，是隐去主机名和层级路径，仅保留用户名和当前文件路径，当需要查看路径的时候调用指令pwd即可。</p>
<h1 id="4-1-隐藏主机名"><a href="#4-1-隐藏主机名" class="headerlink" title="4.1 隐藏主机名"></a>4.1 隐藏主机名</h1><p>根据3.1可知，zsh的配置信息主要在~&#x2F;.zshrc这个文件，在该<strong>文件底部增加</strong>下添加</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># * 方法一：隐藏主机和用户名-是笔者选择的方案</span></span><br><span class="line"><span class="function"><span class="title">prompt_context</span></span>() &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法二：隐藏主机名</span></span><br><span class="line"><span class="function"><span class="title">prompt_context</span></span>() &#123;</span><br><span class="line">  <span class="keyword">if</span> [[ <span class="string">&quot;<span class="variable">$USER</span>&quot;</span> != <span class="string">&quot;<span class="variable">$DEFAULT_USER</span>&quot;</span> || -n <span class="string">&quot;<span class="variable">$SSH_CLIENT</span>&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    prompt_segment black default <span class="string">&quot;%(!.%&#123;%F&#123;yellow&#125;%&#125;.)<span class="variable">$USER</span>&quot;</span></span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法三：隐藏用户名</span></span><br><span class="line"><span class="function"><span class="title">prompt_context</span></span>() &#123;</span><br><span class="line">  <span class="keyword">if</span> [[ <span class="string">&quot;<span class="variable">$USER</span>&quot;</span> != <span class="string">&quot;<span class="variable">$DEFAULT_USER</span>&quot;</span> || -n <span class="string">&quot;<span class="variable">$SSH_CLIENT</span>&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    prompt_segment black default <span class="string">&quot;%(!.%&#123;%F&#123;yellow&#125;%&#125;.)<span class="variable">$HOST</span>&quot;</span></span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#  更新 ~/.zshrc</span></span><br><span class="line"><span class="built_in">source</span> ~/.zshrc</span><br></pre></td></tr></table></figure>

<h1 id="4-2-隐藏层级路径，保留当前路径"><a href="#4-2-隐藏层级路径，保留当前路径" class="headerlink" title="4.2 隐藏层级路径，保留当前路径"></a>4.2 隐藏层级路径，保留当前路径</h1><p>在路径 &#x2F;Users&#x2F;username&#x2F;.oh-my-zsh&#x2F;themes&#x2F;agnoster.zsh-theme 下，打开后找到prompt_dir() {}这个函数，然后将prompt_segment blue black ‘%~’ , 最后面的波浪线改为c即可：prompt_segment blue black ‘%c’,。</p>
<p>最后调用指令 source &#x2F;User&#x2F;username&#x2F;.zshrc, 完成刷新，实现了保留用户名以及当前层级用户。</p>
<center>
    <img src="/2022/04/02/%20Beautify-The-Mac-Bash/hide-host-name.jpg" , width="80%">
</center>

<h1 id="5-插件"><a href="#5-插件" class="headerlink" title="5. 插件"></a>5. 插件</h1><p>为了进一步提高zsh的效率，笔者添加了部分插件。但是，调用终端的好处在于其快速，便捷，过多的插件反而会使得终端显得臃肿，得不偿失，我们故仅添加必要的插件。<br>首先安装oh-my-zsh，打开~&#x2F;.zshrc文件找到plugins&#x3D;( git )，这里是我们已经启用了那些插件.如果想要启用某个插件，装好之后直接修改</p>
<blockquote>
<p>plugins &#x3D; (插件A 插件B 插件C)</p>
</blockquote>
<ol>
<li><p>zsh-autosuggestions<br>非常好用的一个插件，会记录你之前输入过的所有命令，并且自动匹配你可能想要输入命令，然后按→补全</p>
</li>
<li><p>zsh-syntax-highlighting<br>这个插件直接在输入过程中就会提示你，当前命令是否正确，错误红色，正确绿色</p>
</li>
</ol>
<h1 id="6-vscode-配置"><a href="#6-vscode-配置" class="headerlink" title="6. vscode 配置"></a>6. vscode 配置</h1><p>在vscode中有可能会出现乱码的情况，这是因为终端的字体没有设置好。在设置搜索中，打开setting.json文件，加入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;terminal.integrated.defaultProfile.osx&quot;</span>: <span class="string">&quot;zsh&quot;</span>,</span><br><span class="line"><span class="string">&quot;terminal.integrated.fontFamily&quot;</span>: <span class="string">&quot;Meslo LG L DZ for Powerline&quot;</span>,</span><br></pre></td></tr></table></figure>

<h1 id="7-拓展"><a href="#7-拓展" class="headerlink" title="7. 拓展"></a>7. 拓展</h1><h2 id="7-1-不同环境的profile切换"><a href="#7-1-不同环境的profile切换" class="headerlink" title="7.1 不同环境的profile切换"></a>7.1 不同环境的profile切换</h2><p>在开发过程，我们会经常掉用到ssh，连接服务器进行开发，此时会产生如下需求：</p>
<p><strong>希望在不同的环境，自动切换对应的profile。</strong></p>
<p>比如，我们在local的时候能够使用local profile， 在ssh连接 服务器时，能切换到开发profile。</p>
<h3 id="7-1-1-构建profiles"><a href="#7-1-1-构建profiles" class="headerlink" title="7.1.1 构建profiles"></a>7.1.1 构建profiles</h3><p>根据我们需求，构建指定profile。<br>例如笔者在开发过程中，会存在本地，与开发环境两种环境，所以构造了三种不同的profile（Mars_Default, Mars_Server, Mars_other）,其中profile命名可以自行定义。</p>
<center>
<img src="/2022/04/02/%20Beautify-The-Mac-Bash/profiles.jpg" width="80%">
</center>

<h3 id="7-1-2-修改域名映射"><a href="#7-1-2-修改域名映射" class="headerlink" title="7.1.2 修改域名映射"></a>7.1.2 修改域名映射</h3><p>实现不同环境自动切换profile的原理，为识别server名中指定部分，触发profile的切换。所以我们需要修改本地的域名映射, 添加上前缀即可。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /etc/hosts</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hosts example</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">[server ip1] ser_spider</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">[server ip2] ser_stats1</span></span><br></pre></td></tr></table></figure>


<h3 id="7-1-3-创建custom-shell-脚本"><a href="#7-1-3-创建custom-shell-脚本" class="headerlink" title="7.1.3 创建custom shell 脚本"></a>7.1.3 创建custom shell 脚本</h3><p>进入路径, 创建<code>iTrem2-ssh.zsh</code>，其中有样例<code>example.zsh</code>可做参考。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd ~/.oh-my-zsh/custom</span><br></pre></td></tr></table></figure>
<p>往<code>iTrem2-ssh.zsh</code>文件写入脚本，注意其中Mars_Default, Mars_Server, Mars_other 需要根据自身需求进行替换。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">## reference: https://gist.github.com/erangaeb/78614828234323f57b328b61a588209e#file-itrem2-ssh-zsh</span></span><br><span class="line"><span class="comment"># tabc &lt;profile name&gt; do the profile change</span></span><br><span class="line">function tabc() &#123;</span><br><span class="line">  NAME=$<span class="number">1</span>; <span class="keyword">if</span> [ -z <span class="string">&quot;$NAME&quot;</span> ]; then NAME=<span class="string">&quot;Mars_Default&quot;</span>; fi </span><br><span class="line">  <span class="comment"># if you have trouble with this, change</span></span><br><span class="line">  <span class="comment"># &quot;Default&quot; to the name of your default theme</span></span><br><span class="line">  echo -e <span class="string">&quot;\033]50;SetProfile=$NAME\a&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># reset the terminal profile to Default  when exit from the ssh session</span></span><br><span class="line">function tab-reset() &#123;</span><br><span class="line">    NAME=<span class="string">&quot;Mars_Default&quot;</span></span><br><span class="line">    echo -e <span class="string">&quot;\033]50;SetProfile=$NAME\a&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># selecting different terminal profile according to ssh&#x27;ing host</span></span><br><span class="line"><span class="comment"># tabc &lt;profile name&gt; do the profile change</span></span><br><span class="line"><span class="comment">#   1. Production profile to production server (ssh eranga@production_box) </span></span><br><span class="line"><span class="comment">#   2. Staging profile to staging server(ssh eranga@staging_box) </span></span><br><span class="line"><span class="comment">#   3. Other profile to any other server(test server, amazon box etc)</span></span><br><span class="line">function colorssh() &#123;</span><br><span class="line">    <span class="keyword">if</span> [[ -n <span class="string">&quot;$ITERM_SESSION_ID&quot;</span> ]]; then</span><br><span class="line">        trap <span class="string">&quot;tab-reset&quot;</span> INT EXIT</span><br><span class="line">        <span class="keyword">if</span> [[ <span class="string">&quot;$*&quot;</span> =~ <span class="string">&quot;ser_*&quot;</span> ]]; then</span><br><span class="line">            tabc Mars_Server</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            tabc Mars_other</span><br><span class="line">        fi</span><br><span class="line">    fi</span><br><span class="line">    ssh $*</span><br><span class="line">&#125;</span><br><span class="line">compdef _ssh tabc=ssh</span><br><span class="line"></span><br><span class="line"><span class="comment"># creates an alias to ssh</span></span><br><span class="line"><span class="comment"># when execute ssh from the terminal it calls to colorssh function</span></span><br><span class="line">alias ssh=<span class="string">&quot;colorssh&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="7-1-4-效果"><a href="#7-1-4-效果" class="headerlink" title="7.1.4 效果"></a>7.1.4 效果</h3><center>
<img src="/2022/04/02/%20Beautify-The-Mac-Bash/local_profile.jpg" width="80%">
</center>

<center>
<img src="/2022/04/02/%20Beautify-The-Mac-Bash/ser_profile.jpg" width="80%">
</center>

<h2 id="自定义oh-my-zsh-颜色"><a href="#自定义oh-my-zsh-颜色" class="headerlink" title="自定义oh-my-zsh 颜色"></a>自定义oh-my-zsh 颜色</h2><h3 id="自定义提示项颜色"><a href="#自定义提示项颜色" class="headerlink" title="自定义提示项颜色"></a>自定义提示项颜色</h3><p>在使用iterm2的过程，出现了如下的问题。<br>在pycharm， vscode中集成了zsh, 由于iterm2默认背景为黑色，而pycharm，vscode背景颜色为白色，导致提示项（标签以及hostname）的颜色不协调。</p>
<ol>
<li>原iterm2颜色<center>
<img src="/2022/04/02/%20Beautify-The-Mac-Bash/defalut_zsh_color.jpg" width="80%">
</center></li>
<li>原pycharm终端颜色<center>
<img src="/2022/04/02/%20Beautify-The-Mac-Bash/defalut_pycahrm_zsh_color.jpg" width="80%">
</center></li>
<li>原vscode终端颜色<center>
<img src="/2022/04/02/%20Beautify-The-Mac-Bash/default_vscode_zsh_color.jpg" width="80%">
</center></li>
</ol>
<p>希望能够对提示项的颜色自定义。</p>
<p>修改 ~&#x2F;.oh-my-zsh&#x2F;themes&#x2F;agnoster.zsh-theme 文件（该文件取决与主题选择）中prompt_context() ，将原black修改为自定颜色代码(Xterm Number，Xterm Name皆可name注意大小写)，参考<a href="https://www.ditig.com/256-colors-cheat-sheet">256 Colors Cheat Sheet</a>.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">the theme file depend on your customer theme</span></span><br><span class="line">vi ~/.oh-my-zsh/themes/agnoster.zsh-theme</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## Prompt components</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Each component will draw itself, and hide itself <span class="keyword">if</span> no information needs to be shown</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Context: user@hostname (<span class="built_in">who</span> am I and <span class="built_in">where</span> am I)</span></span><br><span class="line">prompt_context() &#123;</span><br><span class="line">  if [[ &quot;$USERNAME&quot; != &quot;$DEFAULT_USER&quot; || -n &quot;$SSH_CLIENT&quot; ]]; then</span><br><span class="line">      # prompt_segment black default &quot;%(!.%&#123;%F&#123;black&#125;%&#125;.)%n@%m&quot;</span><br><span class="line">     prompt_segment cyan default &quot;%(!.%&#123;%F&#123;black&#125;%&#125;.)%n@%m&quot;</span><br><span class="line">  fi</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>修改完成后，调用<code>source ~/.zshrc</code>激活设置。</p>
<p>笔者选用cyan，效果如下：</p>
<ol>
<li>iterm2 终端效果<center>
<img src="/2022/04/02/%20Beautify-The-Mac-Bash/beautify_zsh.jpg" width="80%">
</center></li>
<li>vscode 效果<center>
<img src="/2022/04/02/%20Beautify-The-Mac-Bash/beautify_vscode_zsh.jpg" width="80%">
</center></li>
</ol>
<h2 id="自定义hostname颜色"><a href="#自定义hostname颜色" class="headerlink" title="自定义hostname颜色"></a>自定义hostname颜色</h2><p>虽然完成了提示项颜色的自定义，但是发现在终端中cyan背景和绿色字体显示效果不佳，希望能将hotsname修改为黑色。修改hostname与修改提示项颜色类似，在原prompt_context()，中<code>%n@%m</code>代表用户名与主机名，在该项前添加颜色项%F{custom_color}即可，笔者最终代码如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">the theme file depend on your customer theme</span></span><br><span class="line">vi ~/.oh-my-zsh/themes/agnoster.zsh-theme</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## Prompt components</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Each component will draw itself, and hide itself <span class="keyword">if</span> no information needs to be shown</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Context: user@hostname (<span class="built_in">who</span> am I and <span class="built_in">where</span> am I)</span></span><br><span class="line">prompt_context() &#123;</span><br><span class="line">  if [[ &quot;$USERNAME&quot; != &quot;$DEFAULT_USER&quot; || -n &quot;$SSH_CLIENT&quot; ]]; then</span><br><span class="line">      # prompt_segment black default &quot;%(!.%&#123;%F&#123;black&#125;%&#125;.)%n@%m&quot;</span><br><span class="line">     prompt_segment cyan default &quot;%(!.%&#123;%F&#123;black&#125;%&#125;.)%F&#123;black&#125;%n@%m&quot;</span><br><span class="line">  fi</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>修改完成后，调用<code>source ~/.zshrc</code>激活设置,最终iterm效果如下：</p>
<center>
<img src="/2022/04/02/%20Beautify-The-Mac-Bash/beautify_hostname.jpg" width="80%">
</center>



<h1 id="参考文档："><a href="#参考文档：" class="headerlink" title="参考文档："></a>参考文档：</h1><p><a href="https://iterm2.com/">1. Iterm2官方文档以及下载链接</a></p>
<p><a href="https://segmentfault.com/a/1190000039834490">2. mac之 iTerm2 + Oh My Zsh 终端安装教程</a></p>
<p><a href="https://github.com/ohmyzsh/ohmyzsh/wiki/Themes">3. oh-my-zsh theme主题方案</a></p>
<p><a href="https://0clickjacking0.github.io/2020/10/04/oh-my-zsh%E9%9A%90%E8%97%8F%E7%94%A8%E6%88%B7%E5%90%8D%E6%88%96%E8%80%85%E4%B8%BB%E6%9C%BA%E5%90%8D/">4. oh-my-zsh 隐藏主机名</a></p>
<p><a href="https://www.jianshu.com/p/ee442cb4d6c2">5. Bash shell &#x2F; Zsh 里修改前缀 (隐藏用户@主机，添加Git分支名称)</a></p>
<p><a href="https://www.ioiox.com/archives/34.html">6.macOS使用oh-my-zsh美化Terminal,iTerm2,VSCode命令行终端配置教程</a></p>
<p><a href="https://medium.com/rahasak/change-terminal-color-when-ssh-e2a13ccee681">7. Change terminal color when SSH
</a></p>
]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>zsh</tag>
        <tag>iterm2</tag>
      </tags>
  </entry>
  <entry>
    <title>A Private Blog Built By Github + Hexo + NexT</title>
    <url>/2022/03/18/A-Private-Blog-Built-By-Github-Hexo-Next/</url>
    <content><![CDATA[<p>这个私人博客的搭建是基于Github Page创建最基础的个人静态网站，Hexo则是一个快速、简洁且高效的博客框架，利用Markdown进行文章的解析，NexT是其中的一种主题theme，其拓展性优秀，后期能基于该框架与主题进行个性化的修改。基于Github + Hexo + NexT模式的博客在管理方便，实现本地-远程简单部署的同时，也保证了博客网页的美观与整洁。</p>
<p>本文将从以下几个部分来记录该博客的搭建:</p>
<pre><code>- 项目构建及其部署
- 配置文件功能解析
- 基于该框架主题的DIY
- 难点与收获
</code></pre>
<span id="more"></span>


<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>​        度过了迷茫的半年，终于摸清楚了自己未来职业的方向，不再畏畏缩缩，要勇于去拼搏，去争取机会。在接下来的5年会是我未来非常重要的一段时光，实习、研究生、工作等等，每一步得需要万分的努力才能一步一个台阶的往上爬。所以我想创捷属于自己的blog，来记录自己未来几年的自己在技术、项目、职场等方面的一些心得与体会。之前也有类似的想法，但是经常就是做到一半中途而废。这次我是想认真的经营自己blog，不断的督促自己学习进步。同时blog也利于自己对过去经历进行记录与复盘，查漏补缺更进一步。</p>
<p>​        这个私人博客的搭建是基于Github Page创建最基础的个人静态网站，Hexo则是一个快速、简洁且高效的博客框架，利用Markdown进行文章的解析，NexT是其中的一种主题theme，其拓展性优秀，后期能基于该框架与主题进行个性化的修改。基于Github + Hexo + NexT模式的博客在管理方便，本地-远程简单部署的同时，也保证了博客网页的美观与整洁。</p>
<p>​        本文将从以下几个部分来记录该博客的搭建:</p>
<ul>
<li>项目构建及其部署</li>
<li>配置文件功能解析</li>
<li>基于该框架主题的DIY</li>
<li>难点与收获</li>
</ul>
<p>​        个人链接: </p>
<blockquote>
<ol>
<li><p><a href="https://github.com/wjmars98">Mars’ Github Home</a></p>
</li>
<li><p><a href="https://wjmars98.github.io/">Mars’ Blog Home Page</a></p>
</li>
</ol>
</blockquote>
<h1 id="项目构建及其部署"><a href="#项目构建及其部署" class="headerlink" title="项目构建及其部署"></a>项目构建及其部署</h1><h2 id="准备条件"><a href="#准备条件" class="headerlink" title="准备条件"></a>准备条件</h2><p>​        该博客主要是利用Github为其每个用户提供的Github Pages服务，允许用户搭建一个静态网站。所以首先需要Github上构建名为:{username}.github.io的仓库，其名字必须由“.github.io”结尾。同时为了后续的操作便利，<a href="https://docs.github.com/cn/authentication/connecting-to-github-with-ssh/about-ssh">需要配置本地与Github的ssh连接</a>。</p>
<p>​        同时还需安装Node.js，Hexo。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># node.js</span></span><br><span class="line"><span class="comment"># download from https://nodejs.org/zh-cn/download/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Hexo 安装</span></span><br><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure>



<center>
    <img src="/2022/03/18/A-Private-Blog-Built-By-Github-Hexo-Next/build_repository.png" width="80%">
</center>



<center>
     <img src="/2022/03/18/A-Private-Blog-Built-By-Github-Hexo-Next/ssh-key.png" width="80%">
</center>



<h2 id="项目初始及本地搭建"><a href="#项目初始及本地搭建" class="headerlink" title="项目初始及本地搭建"></a>项目初始及本地搭建</h2><p>​        首先, 需要创建项目，利用指令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># hexo init &#123;name&#125;</span></span><br><span class="line"><span class="comment"># 我的项目名为wjmars98</span></span><br><span class="line">hexo init wjmars98</span><br></pre></td></tr></table></figure>

<p>在wjmars98文件夹下面出现Hexo的初始化文件，各个文件的具体细节下一章再展开。</p>
<center>
     <img src="/2022/03/18/A-Private-Blog-Built-By-Github-Hexo-Next/file_structure.png" width="80%">
</center>

<p>​        第二，需要将Hexo编译成HTML文件，调用指令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 编译形成HTML文件</span></span><br><span class="line">hexo generate</span><br></pre></td></tr></table></figure>

<p>输出结果里面包含了 js、css、font 等内容，处在了项目根目录下的 public 文件夹下面，随后利用Hexo提供的Server服务，将其在本地运行起来</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 启动hexo服务器</span></span><br><span class="line">hexo server</span><br></pre></td></tr></table></figure>

<p>随后可以在本地4000端口查看博客站点，如下所示,其中图例是已经选用next的情况。</p>
<center>
     <img src="/2022/03/18/A-Private-Blog-Built-By-Github-Hexo-Next/hexo_server.png" width="80%">
</center>



<center>
     <img src="/2022/03/18/A-Private-Blog-Built-By-Github-Hexo-Next/localhost.png" width="80%">
</center>



<h2 id="项目部在Github-Page上的部署"><a href="#项目部在Github-Page上的部署" class="headerlink" title="项目部在Github Page上的部署"></a>项目部在Github Page上的部署</h2><p>​        为了便利后面的操作，我们将部署的shell脚本写在 <em>deploy.sh</em> 的脚本文件上</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># deploy.sh 文件</span></span><br><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br><span class="line">hexo deploy</span><br></pre></td></tr></table></figure>

<p>利用 <em>sh deploy.sh</em> 指令就能完成部署操作。</p>
<p>​        在部署之前，我们还需要修改部署文件细节。打开根目录下的 _config.yml 文件，找到 Deployment 这个地方，把刚才新建的 Repository 的地址贴过来，然后指定分支为 master 分支，最终修改为如下内容：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Deployment</span></span><br><span class="line"><span class="comment">## Docs: https://hexo.io/docs/deployment.html</span></span><br><span class="line">deploy:</span><br><span class="line">  <span class="built_in">type</span>: git</span><br><span class="line">  <span class="comment"># 替换成个人github上的git地址</span></span><br><span class="line">  repo: &#123;git repo ssh address&#125;</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure>

<p>还需安装支持 Git 的部署插件，名字叫做 hexo-deployer-git，然后才能顺利部署到Github上</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 插件安装</span></span><br><span class="line">npm install hexo-deployer-git --save</span><br><span class="line"></span><br><span class="line"><span class="comment"># 部署命令</span></span><br><span class="line">hexo deploy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果不按照会报错</span></span><br><span class="line"><span class="comment"># Deployer not found: git</span></span><br></pre></td></tr></table></figure>

<center>
     <img src="/2022/03/18/A-Private-Blog-Built-By-Github-Hexo-Next/deploy.png" width="80%">
</center>

<p>​        此时打开<a href="https://wjmars98.github.io/">https://wjmars98.github.io</a> 便可以打开网站。</p>
<h1 id="配置文件功能解析"><a href="#配置文件功能解析" class="headerlink" title="配置文件功能解析"></a>配置文件功能解析</h1><p>​        在第二章中，我们初步完成了hexo地搭建以及在Github Page上地部署，文件夹为wjmars98，本章将对该文件夹下地配置文件进行详细解析。    </p>
<p>​        首先是wjmars98文件夹的文件树:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── _config.yml <span class="comment"># 网站的 配置 信息，您可以在此配置大部分的参数</span></span><br><span class="line">├── package.json <span class="comment"># 应用程序的信息。</span></span><br><span class="line">├── scaffolds <span class="comment"># 模版 文件夹。当您新建文章时，Hexo 会根据 scaffold 来建立文件。</span></span><br><span class="line">├── <span class="built_in">source</span> <span class="comment"># 资源文件夹是存放用户资源的地方。</span></span><br><span class="line">|   ├── _drafts	<span class="comment"># 草稿</span></span><br><span class="line">|   └── _posts <span class="comment"># 文章</span></span><br><span class="line">└── themes <span class="comment"># 主题 文件夹。Hexo 会根据主题来生成静态页面。</span></span><br></pre></td></tr></table></figure>

<p>​        我们可以在_config.yml中修改大部分配置。</p>
<h2 id="Site"><a href="#Site" class="headerlink" title="Site"></a>Site</h2><table>
<thead>
<tr>
<th align="left">参数</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>title</code></td>
<td align="left">网站标题</td>
</tr>
<tr>
<td align="left"><code>subtitle</code></td>
<td align="left">网站副标题</td>
</tr>
<tr>
<td align="left"><code>description</code></td>
<td align="left">网站描述</td>
</tr>
<tr>
<td align="left"><code>keywords</code></td>
<td align="left">网站的关键词。支持多个关键词。</td>
</tr>
<tr>
<td align="left"><code>author</code></td>
<td align="left">您的名字</td>
</tr>
<tr>
<td align="left"><code>language</code></td>
<td align="left">网站使用的语言。对于简体中文用户来说，使用不同的主题可能需要设置成不同的值，请参考你的主题的文档自行设置，常见的有 <code>zh-Hans</code>和 <code>zh-CN</code>。</td>
</tr>
<tr>
<td align="left"><code>timezone</code></td>
<td align="left">网站时区。Hexo 默认使用您电脑的时区。请参考 <a href="https://en.wikipedia.org/wiki/List_of_tz_database_time_zones">时区列表</a> 进行设置，如 <code>America/New_York</code>, <code>Japan</code>, 和 <code>UTC</code> 。一般的，对于中国大陆地区可以使用 <code>Asia/Shanghai</code>。</td>
</tr>
</tbody></table>
<h2 id="Categories"><a href="#Categories" class="headerlink" title="Categories"></a>Categories</h2><table>
<thead>
<tr>
<th align="left"></th>
<th align="left"></th>
<th align="left"></th>
</tr>
</thead>
<tbody><tr>
<td align="left">参数</td>
<td align="left">描述</td>
<td align="left">默认值</td>
</tr>
<tr>
<td align="left"><code>source_dir</code></td>
<td align="left">资源文件夹，这个文件夹用来存放内容。</td>
<td align="left"><code>source</code></td>
</tr>
<tr>
<td align="left"><code>public_dir</code></td>
<td align="left">公共文件夹，这个文件夹用于存放生成的站点文件。</td>
<td align="left"><code>public</code></td>
</tr>
<tr>
<td align="left"><code>tag_dir</code></td>
<td align="left">标签文件夹</td>
<td align="left"><code>tags</code></td>
</tr>
<tr>
<td align="left"><code>archive_dir</code></td>
<td align="left">归档文件夹</td>
<td align="left"><code>archives</code></td>
</tr>
<tr>
<td align="left"><code>category_dir</code></td>
<td align="left">分类文件夹</td>
<td align="left"><code>categories</code></td>
</tr>
<tr>
<td align="left"><code>code_dir</code></td>
<td align="left">Include code 文件夹，<code>source_dir</code> 下的子目录</td>
<td align="left"><code>downloads/code</code></td>
</tr>
<tr>
<td align="left"><code>i18n_dir</code></td>
<td align="left">国际化（i18n）文件夹</td>
<td align="left"><code>:lang</code></td>
</tr>
<tr>
<td align="left"><code>skip_render</code></td>
<td align="left">跳过指定文件的渲染。匹配到的文件将会被不做改动地复制到 <code>public</code> 目录中。您可使用 <a href="https://github.com/micromatch/micromatch#extended-globbing">glob 表达式</a>来匹配路径。</td>
<td align="left"></td>
</tr>
</tbody></table>
<h2 id="Writing"><a href="#Writing" class="headerlink" title="Writing"></a>Writing</h2><table>
<thead>
<tr>
<th align="left">参数</th>
<th align="left">描述</th>
<th align="left">默认值</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>new_post_name</code></td>
<td align="left">新文章的文件名称</td>
<td align="left">:title.md</td>
</tr>
<tr>
<td align="left"><code>default_layout</code></td>
<td align="left">预设布局</td>
<td align="left">post</td>
</tr>
<tr>
<td align="left"><code>auto_spacing</code></td>
<td align="left">在中文和英文之间加入空格</td>
<td align="left">false</td>
</tr>
<tr>
<td align="left"><code>titlecase</code></td>
<td align="left">把标题转换为 title case</td>
<td align="left">false</td>
</tr>
<tr>
<td align="left"><code>external_link</code></td>
<td align="left">在新标签中打开链接</td>
<td align="left">true</td>
</tr>
<tr>
<td align="left"><code>external_link.enable</code></td>
<td align="left">在新标签中打开链接</td>
<td align="left"><code>true</code></td>
</tr>
<tr>
<td align="left"><code>external_link.field</code></td>
<td align="left">对整个网站（<code>site</code>）生效或仅对文章（<code>post</code>）生效</td>
<td align="left"><code>site</code></td>
</tr>
<tr>
<td align="left"><code>external_link.exclude</code></td>
<td align="left">需要排除的域名。主域名和子域名如 <code>www</code> 需分别配置</td>
<td align="left"><code>[]</code></td>
</tr>
<tr>
<td align="left"><code>filename_case</code></td>
<td align="left">把文件名称转换为 (1) 小写或 (2) 大写</td>
<td align="left">0</td>
</tr>
<tr>
<td align="left"><code>render_drafts</code></td>
<td align="left">显示草稿</td>
<td align="left">false</td>
</tr>
<tr>
<td align="left"><code>post_asset_folder</code></td>
<td align="left">启动 <a href="https://hexo.io/zh-cn/docs/asset-folders">Asset 文件夹</a></td>
<td align="left">false</td>
</tr>
<tr>
<td align="left"><code>relative_link</code></td>
<td align="left">把链接改为与根目录的相对位址</td>
<td align="left">false</td>
</tr>
<tr>
<td align="left"><code>future</code></td>
<td align="left">显示未来的文章</td>
<td align="left">true</td>
</tr>
<tr>
<td align="left"><code>highlight</code></td>
<td align="left">代码块的设置, 请参考 <a href="https://hexo.io/docs/syntax-highlight#Highlight-js">Highlight.js</a> 进行设置</td>
<td align="left"></td>
</tr>
<tr>
<td align="left"><code>prismjs</code></td>
<td align="left">代码块的设置, 请参考 <a href="https://hexo.io/docs/syntax-highlight#PrismJS">PrismJS</a> 进行设置</td>
<td align="left"></td>
</tr>
</tbody></table>
<h2 id="Date"><a href="#Date" class="headerlink" title="Date"></a>Date</h2><p>Hexo 使用 <a href="http://momentjs.com/">Moment.js</a> 来解析和显示时间。</p>
<table>
<thead>
<tr>
<th align="left">参数</th>
<th align="left">描述</th>
<th align="left">默认值</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>date_format</code></td>
<td align="left">日期格式</td>
<td align="left"><code>YYYY-MM-DD</code></td>
</tr>
<tr>
<td align="left"><code>time_format</code></td>
<td align="left">时间格式</td>
<td align="left"><code>HH:mm:ss</code></td>
</tr>
<tr>
<td align="left"><code>updated_option</code></td>
<td align="left">当 Front Matter 中没有指定 <a href="https://hexo.io/zh-cn/docs/variables#%E9%A1%B5%E9%9D%A2%E5%8F%98%E9%87%8F"><code>updated</code></a> 时 <code>updated</code> 的取值</td>
<td align="left"><code>mtime</code></td>
</tr>
</tbody></table>
<h2 id="Extensions"><a href="#Extensions" class="headerlink" title="Extensions"></a>Extensions</h2><table>
<thead>
<tr>
<th align="left">参数</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>theme</code></td>
<td align="left">当前主题名称。值为<code>false</code>时禁用主题</td>
</tr>
<tr>
<td align="left"><code>theme_config</code></td>
<td align="left">主题的配置文件。在这里放置的配置会覆盖主题目录下的 <code>_config.yml</code> 中的配置</td>
</tr>
<tr>
<td align="left"><code>deploy</code></td>
<td align="left">部署部分的设置</td>
</tr>
<tr>
<td align="left"><code>meta_generator</code></td>
<td align="left"><a href="https://developer.mozilla.org/zh-CN/docs/Web/HTML/Element/meta#%E5%B1%9E%E6%80%A7">Meta generator</a> 标签。 值为 <code>false</code> 时 Hexo 不会在头部插入该标签</td>
</tr>
</tbody></table>
<h2 id="Front-Matter"><a href="#Front-Matter" class="headerlink" title="Front-Matter"></a>Front-Matter</h2><p>Front-matter 是文件最上方以 <code>---</code> 分隔的区域，用于指定个别文件的变量，举例来说：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">Hello</span> <span class="string">World</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2013</span><span class="string">/7/13</span> <span class="number">20</span><span class="string">:46:25</span></span><br><span class="line"><span class="meta">---</span></span><br></pre></td></tr></table></figure>

<p>以下是预先定义的参数，您可在模板中使用这些参数值并加以利用。</p>
<table>
<thead>
<tr>
<th align="left">参数</th>
<th align="left">描述</th>
<th align="left">默认值</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>layout</code></td>
<td align="left">布局</td>
<td align="left"><a href="https://hexo.io/zh-cn/docs/configuration#%E6%96%87%E7%AB%A0"><code>config.default_layout</code></a></td>
</tr>
<tr>
<td align="left"><code>title</code></td>
<td align="left">标题</td>
<td align="left">文章的文件名</td>
</tr>
<tr>
<td align="left"><code>date</code></td>
<td align="left">建立日期</td>
<td align="left">文件建立日期</td>
</tr>
<tr>
<td align="left"><code>updated</code></td>
<td align="left">更新日期</td>
<td align="left">文件更新日期</td>
</tr>
<tr>
<td align="left"><code>comments</code></td>
<td align="left">开启文章的评论功能</td>
<td align="left">true</td>
</tr>
<tr>
<td align="left"><code>tags</code></td>
<td align="left">标签（不适用于分页）</td>
<td align="left"></td>
</tr>
<tr>
<td align="left"><code>categories</code></td>
<td align="left">分类（不适用于分页）</td>
<td align="left"></td>
</tr>
<tr>
<td align="left"><code>permalink</code></td>
<td align="left">覆盖文章网址</td>
<td align="left"></td>
</tr>
<tr>
<td align="left"><code>excerpt</code></td>
<td align="left">Page excerpt in plain text. Use <a href="https://hexo.io/docs/tag-plugins#Post-Excerpt">this plugin</a> to format the text</td>
<td align="left"></td>
</tr>
<tr>
<td align="left"><code>disableNunjucks</code></td>
<td align="left">Disable rendering of Nunjucks tag <code>&#123;&#123; &#125;&#125;</code>&#x2F;<code>&#123;% %&#125;</code> and <a href="https://hexo.io/docs/tag-plugins">tag plugins</a> when enabled</td>
<td align="left"></td>
</tr>
<tr>
<td align="left"><code>lang</code></td>
<td align="left">Set the language to override <a href="https://hexo.io/docs/internationalization#Path">auto-detection</a></td>
<td align="left">Inherited from <code>_config.yml</code></td>
</tr>
</tbody></table>
<p>​        </p>
<p>更多细节可以查阅:<a href="https://hexo.io/zh-cn/docs/configuration">官方文档</a></p>
<h1 id="基于NexT框架主题的DIY"><a href="#基于NexT框架主题的DIY" class="headerlink" title="基于NexT框架主题的DIY"></a>基于NexT框架主题的DIY</h1><p>​        我们选择框架在themes文件夹下，文件树如图所示:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── _config.yml <span class="comment"># 主题的配置文件。</span></span><br><span class="line">├── languages	<span class="comment"># 语言文件夹</span></span><br><span class="line">├── layout <span class="comment"># 布局文件夹</span></span><br><span class="line">├── scripts <span class="comment"># 脚本文件夹</span></span><br><span class="line">└── <span class="built_in">source</span> <span class="comment"># 资源文件夹，除了模板以外的 Asset，例如 CSS、JavaScript 文件等，都应该放在这个文件夹中</span></span><br></pre></td></tr></table></figure>

<p>​        目前 Hexo 里面应用最多的主题基本就是 Next 主题了，个人感觉这个主题还是挺好看的，另外它支持的插件和功能也极为丰富，配置了这个主题，我们的博客可以支持更多的扩展功能，比如阅览进度条、中英文空格排版、图片懒加载等等。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/theme-next/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>

<p>​        执行完毕之后 <a href="https://theme-next.js.org/">Next 主题</a>的源码就会出现在项目的 themes&#x2F;next 文件夹下。 然后我们需要修改下博客所用的主题名称，修改项目根目录下的 _config.yml 文件，找到 theme 字段，修改为 next 即可，修改如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">theme: next</span><br></pre></td></tr></table></figure>
<h2 id="添加Gitalk评论区"><a href="#添加Gitalk评论区" class="headerlink" title="添加Gitalk评论区"></a>添加Gitalk评论区</h2><p>打开 github.com&#x2F;settings&#x2F;applications&#x2F;new ，具体填法如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Application name //应用名称，随便填</span><br><span class="line">Homepage URL //没有过多要求，可以填自己的博客地址</span><br><span class="line">Application description //应用描述，描述一下，无要求</span><br><span class="line">Authorization callback URL //这个就有要求了，填自己要使用Gitalk的博客地址，不可乱填</span><br></pre></td></tr></table></figure>
<p>接着，你就可以得到Client ID和Client Secret，之后会用到的。接下来，我们回到hexo的主题配置里.</p>
<p>在next主题中，修改_config.xml文件，如图所示</p>
<center>
          <img src="/2022/03/18/A-Private-Blog-Built-By-Github-Hexo-Next/gitalk1.jpg" , width="80%">
</center>

<center>
          <img src="/2022/03/18/A-Private-Blog-Built-By-Github-Hexo-Next/gitalk2.jpg" , width="80%">
</center>


<h1 id="难点与收获"><a href="#难点与收获" class="headerlink" title="难点与收获"></a>难点与收获</h1><h2 id="Tags-And-Categories"><a href="#Tags-And-Categories" class="headerlink" title="Tags And Categories"></a>Tags And Categories</h2><p>​        只有文章支持分类和标签，您可以在 Front-matter 中设置。在其他系统中，分类和标签听起来很接近，但是在 Hexo 中两者有着明显的差别：分类具有顺序性和层次性，也就是说 <code>Foo, Bar</code> 不等于 <code>Bar, Foo</code>；而标签没有顺序和层次。</p>
<figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">categories:</span><br><span class="line">- Diary</span><br><span class="line"><span class="keyword">tags:</span></span><br><span class="line">- PS3</span><br><span class="line">- Games</span><br></pre></td></tr></table></figure>

<p>但是 Hexo <strong>不支持指定多个同级分类</strong>。下面的指定方法：</p>
<figure class="highlight nestedtext"><table><tr><td class="code"><pre><span class="line"><span class="attribute">categories</span><span class="punctuation">:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Diary</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Life</span></span><br></pre></td></tr></table></figure>

<p><em>会使分类<code>Life</code>成为<code>Diary</code>的子分类</em>，而不是并列分类.</p>
<p>如果你需要为文章添加多个分类，可以尝试以下 list 中的方法。</p>
<figure class="highlight ldif"><table><tr><td class="code"><pre><span class="line"><span class="attribute">categories</span>:</span><br><span class="line"><span class="literal">-</span> [Diary, PlayStation]</span><br><span class="line"><span class="literal">-</span> [Diary, Games]</span><br><span class="line"><span class="literal">-</span> [Life]</span><br></pre></td></tr></table></figure>

<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><blockquote>
<ol>
<li><u><a href="https://hexo.io/zh-cn/">Hexo官方参考资料</a></u></li>
<li><a href="https://cuiqingcai.com/7625.html">崔庆才-利用 GitHub + Hexo + Next 从零搭建一个博客)</a></li>
<li><a href="https://docs.github.com/cn/authentication/connecting-to-github-with-ssh/about-ssh">Github的SSH连接</a></li>
<li><a href="https://www.npmjs.com/package/hexo-asset-image-for-hexo5">Hexo 图片部署</a></li>
</ol>
</blockquote>
]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Big Query-Basic</title>
    <url>/2022/04/11/Big-Query/</url>
    <content><![CDATA[<p>BigQuery 是一种全代管式企业数据仓库，可帮助您使用机器学习、地理空间分析和商业智能等内置功能管理和分析数据。</p>
<p>BigQuery 实现分析数据的计算引擎与存储选项分离，可最大限度地提高灵活性。</p>
<p>BigQuery 界面包括 Google Cloud Console 界面和 BigQuery 命令行工具。</p>
<p><strong>TO BE CONTINUED …</strong></p>
<center>
        <img src="/2022/04/11/Big-Query/bq_logo.jpg" width="80%">
</center>

<span id="more"></span>

<h1 id="Quick-Begin"><a href="#Quick-Begin" class="headerlink" title="Quick Begin"></a>Quick Begin</h1><p>笔者感觉bq的配置、指令、命令行类的操作细节不该是本篇的关注的重点，否则文章会显得冗杂、无味，故对于此部分只会摘录google官网上的相关的文档链接，读者自行通读，在工作中边实践边学习。</p>
<p>本篇将主要集中于bq的存储、分析、管理等工作原理，以及工作中遇到的有价值的问题与知识。</p>
<h2 id="快速入门"><a href="#快速入门" class="headerlink" title="快速入门"></a>快速入门</h2><p><a href="https://cloud.google.com/bigquery/docs/quickstarts/query-public-dataset-console?hl=zh-cn">1. Cloud Console</a><br><a href="https://cloud.google.com/bigquery/docs/quickstarts/load-data-console?hl=zh-cn">2. 加载与查询数据</a><br><a href="https://cloud.google.com/bigquery/docs/quickstarts/load-data-bq?hl=zh-cn">3. 命令行工具</a><br><a href="https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=zh-cn#bigquery_simple_app_client-java">4.  客户端库</a><br><a href="https://github.com/googleapis/java-bigquery/tree/f9f7abdede91e8f780d5a60b6ee9a26e9316d04d">5. BQ java指令 github仓库</a></p>
<h2 id="付费情况"><a href="#付费情况" class="headerlink" title="付费情况"></a>付费情况</h2><h2 id="流媒体"><a href="#流媒体" class="headerlink" title="流媒体"></a>流媒体</h2><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol>
<li><a href="https://cloud.google.com/bigquery/docs/introduction?hl=zh-cn">BQ官方文档</a></li>
</ol>
]]></content>
      <categories>
        <category>Big Data</category>
      </categories>
      <tags>
        <tag>big query</tag>
      </tags>
  </entry>
  <entry>
    <title>Cockpit - A monitor program basing on grafana, glances and influxdb</title>
    <url>/2022/08/05/Cockpit-A-monitor-program-basing-on-grafana-glances-and-influxdb/</url>
    <content><![CDATA[<p>A monitor project for server resources basing on glances, influxdb 1.7 and grafana 8.</p>
<center>
    <img src="/2022/08/05/Cockpit-A-monitor-program-basing-on-grafana-glances-and-influxdb/cockpit-framwork.png" width="80%">
</center>

<span id="more"></span>

<h2 id="Environment"><a href="#Environment" class="headerlink" title="Environment"></a>Environment</h2><blockquote>
<p>Python 3.9.4 <br><br>Glances 3.2.7 <br><br>Influxdb 1.7.10 <br><br>Grafana 8.5.9</p>
</blockquote>
<h2 id="Show"><a href="#Show" class="headerlink" title="Show"></a>Show</h2><center>
    <img src="/2022/08/05/Cockpit-A-monitor-program-basing-on-grafana-glances-and-influxdb/cockpit-display.png" width="80%">
</center>

<p><strong>Major Monitored Objects:</strong></p>
<ul>
<li>CPU(%)</li>
<li>Disk</li>
<li>Memory</li>
<li>Network</li>
</ul>
<h2 id="Deploy"><a href="#Deploy" class="headerlink" title="Deploy"></a>Deploy</h2><h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h3><p>There existed a dependence between influxdb and grafana and it’s significant to choose the<br>suitable version.</p>
<blockquote>
<p>The instructions in this guide require Grafana Cloud or Grafana v7.1+. For information about<br>using InfluxDB with other versions of Grafana, see the Grafana documentation.</p>
</blockquote>
<h3 id="Glances"><a href="#Glances" class="headerlink" title="Glances"></a>Glances</h3><p>Glances is on PyPI, To install, simply use pip</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install glances</span><br></pre></td></tr></table></figure>
<p>After installing glances, we can use command <code>glances</code> to test it.</p>
<center>
    <img src="/2022/08/05/Cockpit-A-monitor-program-basing-on-grafana-glances-and-influxdb/cockpit-glances.png" width="80%">
</center>


<h3 id="Influxdb1-7"><a href="#Influxdb1-7" class="headerlink" title="Influxdb1.7"></a>Influxdb1.7</h3><h4 id="install-online"><a href="#install-online" class="headerlink" title="install online"></a>install online</h4><p><a href="https://docs.influxdata.com/influxdb/v1.7/introduction/installation/">influxdata.com documents</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/yum.repos.d/influxdb.repo</span><br><span class="line">[influxdb]</span><br><span class="line">name = InfluxDB Repository - RHEL \$releasever</span><br><span class="line">baseurl = https://repos.influxdata.com/rhel/\$releasever/\$basearch/stable</span><br><span class="line">enabled = 1</span><br><span class="line">gpgcheck = 1</span><br><span class="line">gpgkey = https://repos.influxdata.com/influxdb.key</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum install influxdb</span><br><span class="line">sudo service influxdb start</span><br></pre></td></tr></table></figure>

<h4 id="install-offline"><a href="#install-offline" class="headerlink" title="install offline"></a>install offline</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /PATH/TO/cockpit/pkg/</span><br><span class="line">yum installlocal  influxdb-1.7.10.x86_64.rpm</span><br></pre></td></tr></table></figure>

<h4 id="start-influx-service"><a href="#start-influx-service" class="headerlink" title="start influx service"></a>start influx service</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo service influxdb start</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">start, status, stop</span></span><br><span class="line">sudo systemctl start influxdb.service</span><br><span class="line">sudo systemctl status influxdb.service</span><br><span class="line">sudo systemctl stop influxdb.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># check the influx service log</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">real-time</span></span><br><span class="line">journalctl -f -u influxdb.service</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">latest 100 lines</span></span><br><span class="line">journalctl -n 100 -u influxdb.service</span><br></pre></td></tr></table></figure>

<h3 id="Grafana"><a href="#Grafana" class="headerlink" title="Grafana"></a>Grafana</h3><h4 id="install-offline-1"><a href="#install-offline-1" class="headerlink" title="install offline"></a>install offline</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">download grafana</span></span><br><span class="line">cd /PATH/TO/cockpit/pkg/</span><br><span class="line">yum installlocal grafana-8.5.9-1.x86_64.rpm</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">start the grafana service</span></span><br><span class="line">service grafana-service satrt</span><br></pre></td></tr></table></figure>

<h3 id="Combination"><a href="#Combination" class="headerlink" title="Combination"></a>Combination</h3><h4 id="1-Create-database"><a href="#1-Create-database" class="headerlink" title="1. Create database"></a>1. Create database</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">influx</span><br><span class="line">create database glances</span><br><span class="line">use database</span><br></pre></td></tr></table></figure>

<h4 id="2-Load-glances-data"><a href="#2-Load-glances-data" class="headerlink" title="2. Load glances data"></a>2. Load glances data</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">single <span class="built_in">command</span></span></span><br><span class="line">glances --export influxdb</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">service</span></span><br><span class="line">vi /etc/systemd/system/glances.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># service config, and focus on ExecStart</span></span></span><br><span class="line">[Unit]</span><br><span class="line">Description=Glances</span><br><span class="line">After=network.target influxd.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/glances --config /etc/glances/glances.conf --quiet --export influxdb</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=30s</span><br><span class="line">TimeoutSec=30s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reload the systemctl</span></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start glances.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">auto start glance service when server start</span></span><br><span class="line">systemctl enable glances.service</span><br></pre></td></tr></table></figure>

<p>Try to select data from influxdb glances databases or read glances log to ensuring data loaded.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">select database data, new tables will be created <span class="keyword">if</span> data loaded successfully.</span></span><br><span class="line">influx</span><br><span class="line">use glances</span><br><span class="line">show merasurements</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">use journalctl to check influxdb <span class="built_in">log</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">real-time</span></span><br><span class="line">journalctl -f -u influxdb.service </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">latest 100 <span class="built_in">log</span> line</span></span><br><span class="line">journalctl -n 100 -u influxdb.service </span><br></pre></td></tr></table></figure>

<h4 id="3-Crate-Grafana-Dashboard"><a href="#3-Crate-Grafana-Dashboard" class="headerlink" title="3. Crate Grafana Dashboard"></a>3. Crate Grafana Dashboard</h4><p>Open <a href="http://localhost:3000/">http://localhost:3000</a> in the local browser.</p>
<center>
    <img src="/2022/08/05/Cockpit-A-monitor-program-basing-on-grafana-glances-and-influxdb/cockpit-datasource.png" width="80%">
</center>

<center>
    <img src="/2022/08/05/Cockpit-A-monitor-program-basing-on-grafana-glances-and-influxdb/cockpit-datasource1.png" width="80%">
</center>

<center>
    <img src="/2022/08/05/Cockpit-A-monitor-program-basing-on-grafana-glances-and-influxdb/cockpit-datasource2.png" width="80%">
</center>

<center>
    <img src="/2022/08/05/Cockpit-A-monitor-program-basing-on-grafana-glances-and-influxdb/cockpit-datasource3.png" width="80%">
</center>

<p>The datasource was created, and then we need to import the dashboard.</p>
<center>
    <img src="/2022/08/05/Cockpit-A-monitor-program-basing-on-grafana-glances-and-influxdb/cockpit-dashboard.png" width="80%">
</center>

<center>
    <img src="/2022/08/05/Cockpit-A-monitor-program-basing-on-grafana-glances-and-influxdb/cockpit-dashboard1.png" width="80%">
</center>

<p>Finally, click the import to finish creating the monitor program.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="https://grafana.com/">Grafana Office</a></li>
<li><a href="https://nicolargo.github.io/glances/">Glances Ofiice</a></li>
<li><a href="https://docs.influxdata.com/influxdb/v1.7/">Influx 1.7 Office Doc</a></li>
<li><a href="https://glances.readthedocs.io/en/latest/gw/influxdb.html">Glances, InfluxDB, Glances</a></li>
</ol>
]]></content>
      <tags>
        <tag>Basic</tag>
      </tags>
  </entry>
  <entry>
    <title>Dolphin Scheduler Project</title>
    <url>/2022/08/09/Dolphin-Scheduler-Project/</url>
    <content><![CDATA[<p>This purpose of this repo is to record some tricks and solutions during the process of<br>the ds-cluster building.</p>
<center>
   <img src="/2022/08/09/Dolphin-Scheduler-Project/ds_logo.png" width="80%">
</center>

<span id="more"></span>

<h2 id="Catalogue"><a href="#Catalogue" class="headerlink" title="Catalogue"></a>Catalogue</h2><ul>
<li><a href="#catalogue">Catalogue</a></li>
<li><a href="#main-ds-service-composition">Main DS Service Composition</a></li>
<li><a href="#important-glossary">Important Glossary</a></li>
<li><a href="#build-a-cluster">Build a Cluster</a><ul>
<li><a href="#configuration-information">Configuration Information</a><ul>
<li><a href="#1-test-servers-info">1. Test Servers Info</a></li>
<li><a href="#2-zookeeper">2. zookeeper</a></li>
<li><a href="#3-mysql">3. mysql</a></li>
<li><a href="#4-dolphin-scheduler-project">4. dolphin scheduler project</a></li>
<li><a href="#5-others">5. others</a></li>
</ul>
</li>
<li><a href="#aso-alert-project-deployment-test"><em>aso-alert</em> project deployment test</a></li>
</ul>
</li>
<li><a href="#problem-and-solution">Problem And Solution</a><ul>
<li><a href="#1-telant-dosent-exist">1. Telant dosen’t exist</a></li>
<li><a href="#2-datasource-fail-to-connect-mysql">2. Datasource fail to connect mysql</a><ul>
<li><a href="#pseudo-cluster">(Pseudo) cluster</a></li>
<li><a href="#dockerk8s">Docker，K8s</a></li>
</ul>
</li>
<li><a href="#3-storage-not-enabled">3. Storage Not Enabled</a><ul>
<li><a href="#1-k8s">1. K8s:</a></li>
<li><a href="#2-cluster">2. Cluster</a></li>
</ul>
</li>
<li><a href="#4-work-group-default-have-not-received-the-heartbeat">4. work group default have not received the heartbeat</a></li>
</ul>
</li>
<li><a href="#reference">Reference</a></li>
</ul>
<h2 id="Main-DS-Service-Composition"><a href="#Main-DS-Service-Composition" class="headerlink" title="Main DS Service Composition"></a>Main DS Service Composition</h2><p>DolphinScheduler mainly consists of five services: </p>
<ul>
<li>MasterServer：Mainly responsible for DAG segmentation and task status monitoring</li>
<li>WorkerServer&#x2F;LoggerServer：Mainly responsible for the submission, execution and update of task status. LoggerServer is used for Rest Api to view logs through RPC</li>
<li>ApiServer：Provides the Rest Api service for the UI to call</li>
<li>AlertServer：Provide alarm service</li>
<li>UI: Front page display</li>
</ul>
<h2 id="Important-Glossary"><a href="#Important-Glossary" class="headerlink" title="Important Glossary"></a>Important Glossary</h2><ul>
<li><strong>Priority</strong>: Support the priority of process instances and task instances, if the priority of process instances and task instances is not set, the default is <strong>first-in-first-out</strong>.</li>
<li><strong>Task&#x2F;Process Priority</strong>: When the number of <strong>worker&#x2F;process threads</strong> is insufficient, high-level tasks will be executed first in the execution queue, and tasks&#x2F;process with the same priority will be executed in the order of first in, first out.</li>
<li><strong>Failure Strategy</strong>: notification strategy, process priority, worker group, notification group, recipient, and CC are the same as workflow running parameters.</li>
<li><strong>SubProcess</strong>: The sub-process node is to execute a certain external workflow definition as a task node.</li>
</ul>
<h2 id="Build-a-Cluster"><a href="#Build-a-Cluster" class="headerlink" title="Build a Cluster"></a>Build a Cluster</h2><h3 id="Configuration-Information"><a href="#Configuration-Information" class="headerlink" title="Configuration Information"></a>Configuration Information</h3><h4 id="1-Test-Servers-Info"><a href="#1-Test-Servers-Info" class="headerlink" title="1. Test Servers Info"></a>1. Test Servers Info</h4><ul>
<li>backend-pulsar-101</li>
<li>backend-pulsar-102</li>
<li>backend-pulsar-103</li>
</ul>
<h4 id="2-zookeeper"><a href="#2-zookeeper" class="headerlink" title="2. zookeeper"></a>2. zookeeper</h4><p>version：3.7.1</p>
<ul>
<li>leader: backend-pulsar-102</li>
<li>follower: backend-pulsar-101, backend-pulsar-103</li>
</ul>
<h4 id="3-mysql"><a href="#3-mysql" class="headerlink" title="3. mysql"></a>3. mysql</h4><p>version：8.0<br>Depoy on the docker on the <em>backend-pulsar-101</em> server. </p>
<blockquote>
<p>Due to ds meta data are stored in the database, it’s recommended that the mysql database should be built in the cluster server or the server which owns the <strong>low latency</strong> to the ds cluster. Otherwise, the io, ui and so on of ds cluster will be badly affected.</p>
</blockquote>
<center>
   <img src="/2022/08/09/Dolphin-Scheduler-Project/stat_mysql.png" width="80%">
</center>

<h4 id="4-dolphin-scheduler-project"><a href="#4-dolphin-scheduler-project" class="headerlink" title="4. dolphin scheduler project"></a>4. dolphin scheduler project</h4><p>ds version: 2.0.5</p>
<center>
   <img src="/2022/08/09/Dolphin-Scheduler-Project/ds_services.png" width="80%">
</center>

<h4 id="5-others"><a href="#5-others" class="headerlink" title="5. others"></a>5. others</h4><p>configuration:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The directory to install DolphinScheduler <span class="keyword">for</span> all machine we config above. It will automatically be created by `install.sh` script <span class="keyword">if</span> not exists.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Do not <span class="built_in">set</span> this configuration same as the current path (<span class="built_in">pwd</span>)</span></span><br><span class="line">installPath=&quot;/data1_1T/dolphinscheduler&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Log path</span></span><br><span class="line">logpath=&quot;/data1_1T/dolphinscheduler/logs&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The directory to store <span class="built_in">local</span> data <span class="keyword">for</span> all machine we config above. Make sure user `deployUser` have permissions to <span class="built_in">read</span> and write this directory.</span></span><br><span class="line">dataBasedirPath=&quot;/tmp/dolphinscheduler&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">resource store on HDFS/S3 path, resource file will store to this hdfs path, self configuration, please make sure the directory exists on hdfs and has <span class="built_in">read</span> write permissions. <span class="string">&quot;/dolphinscheduler&quot;</span> is recommended</span></span><br><span class="line">resourceUploadPath=&quot;/dolphinscheduler&quot;</span><br></pre></td></tr></table></figure>

<h3 id="aso-alert-project-deployment-test"><a href="#aso-alert-project-deployment-test" class="headerlink" title="aso-alert project deployment test"></a><em>aso-alert</em> project deployment test</h3><ol>
<li>worker group</li>
</ol>
<p>DS is allowed to divide workers to organize as work group, and appoint related task executed on specific group.</p>
<p>User need to configure the required environment (such as JAVA_HOME, PYTHON_HOME and so on) in the group to support the program.</p>
<ol start="2">
<li>environment manage</li>
</ol>
<p>I used pyenv and virtualenv to install the python3.9.4, and ds allow user to export environment variables configs in ui, as shown in following pic.</p>
<center>
   <img src="/2022/08/09/Dolphin-Scheduler-Project/stat_ds_env.png" width="80%">
</center>

<ol start="3">
<li>resources</li>
</ol>
<p>To run alert project, related resources need to be uploaded. Resources -&gt; upload.</p>
<blockquote>
<p>  <strong>Attention</strong>:</p>
<ol>
<li>DS 2.0.5 only support upload file level resources and batch upload method is not allowed currently.<br> Also, if user selects local-storage method for resource, only upoload resource on ui or api are valid,copying file to the target server folder will not map to the meta database.</li>
<li>There is a bug in DS 2.0.5 that process cannot find the resource, which may be caused by server saving the upload resources in the error local storage path.<br>Please check it in the server or reupload the resource.</li>
</ol>
</blockquote>
<ul>
<li><p>Server：</p>
 <center>
    <img src="/2022/08/09/Dolphin-Scheduler-Project/stat_store_local.png" width="80%">
 </center></li>
<li><p>ui：</p>
   <center>
 <img src="/2022/08/09/Dolphin-Scheduler-Project/stat_store_ui.png" width="80%">
   </center>
</li>
<li><p>DAG</p>
 <center>
    <img src="/2022/08/09/Dolphin-Scheduler-Project/stat_dags.png" width="80%">
 </center>
</li>
<li><p>Task</p>
 <center>
    <img src="/2022/08/09/Dolphin-Scheduler-Project/stat_online.png" width="80%">
 </center>
</li>
<li><p>Log</p>
 <center>
    <img src="/2022/08/09/Dolphin-Scheduler-Project/stat_run_log.png" width="80%">
 </center></li>
</ul>
<h2 id="Problem-And-Solution"><a href="#Problem-And-Solution" class="headerlink" title="Problem And Solution"></a>Problem And Solution</h2><h3 id="1-Telant-dosen’t-exist"><a href="#1-Telant-dosen’t-exist" class="headerlink" title="1. Telant dosen’t exist"></a>1. Telant dosen’t exist</h3><blockquote>
<p>Cause：In meta database, table t_ds_user’s tenant_id dosen’t match t_ds_tenant’s id, which cause the telant dosen’t exist.</p>
</blockquote>
<center>
   <img src="/2022/08/09/Dolphin-Scheduler-Project/pro_tenant_not_exist.png" width="80%">
</center>

<p><strong>Solution：</strong></p>
<p>update the tenant_id to match the with id.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># check data of tables t_ds_tenant and t_ds_user.</span><br><span class="line">use dolphinscheduler;</span><br><span class="line">select * from t_ds_tenant;</span><br><span class="line">select * from t_ds_user;    </span><br></pre></td></tr></table></figure>
<p>As shown following, tenant_id didn’t match ID, update tenant_id.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">update t_ds_user set tenant_id=[] where user_name=[];</span><br></pre></td></tr></table></figure>
<center>
   <img src="/2022/08/09/Dolphin-Scheduler-Project/sol_tenant_not_exist.png" width="80%">
</center>


<h3 id="2-Datasource-fail-to-connect-mysql"><a href="#2-Datasource-fail-to-connect-mysql" class="headerlink" title="2. Datasource fail to connect mysql"></a>2. Datasource fail to connect mysql</h3><blockquote>
<p>Cause：The license of mysql jdbc connector is not compatible with apache v2 license, so it can’t be included by docker image.</p>
</blockquote>
<center>
   <img src="/2022/08/09/Dolphin-Scheduler-Project/pro_jdbc_driver.png" width="80%">
</center>

<p>Dolphinscheduler acquiescently appoint PostgreSQL as meta database, so mysql driven should be added to connect mysql database.</p>
<p><strong>Solution：</strong></p>
<h4 id="Pseudo-cluster"><a href="#Pseudo-cluster" class="headerlink" title="(Pseudo) cluster"></a>(Pseudo) cluster</h4><ol>
<li><p>add jdbc driven</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir tmp &amp;&amp; cd tmp</span><br><span class="line">wget https://downloads.mysql.com/archives/get/p/3/file/mysql-connector-java-8.0.16.tar.gz</span><br><span class="line">tar -zxvf mysql-connector-java-8.0.16.tar.gz</span><br><span class="line">cd mysql-connector-java-8.0.16</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ds version 2.0.*</span></span><br><span class="line">cp mysql-connector-java-8.0.16.jar /path/to/apache-dolphinscheduler-2.0.*-bin/lib</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ds version 3.0.*</span></span><br><span class="line">cp mysql-connector-java-8.0.16.jar /path/to/apache-dolphinscheduler-3.0.*-bin/tools/libs</span><br></pre></td></tr></table></figure>
</li>
<li><p>init meta database</p>
</li>
</ol>
<p>grant the privilege of dolphinscheduler database to appointed user.</p>
<p><em>mysql 5.6 &#x2F; 5.7</em></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql -uroot -p</span><br><span class="line"></span><br><span class="line">mysql&gt; CREATE DATABASE dolphinscheduler DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</span><br><span class="line"></span><br><span class="line"># 修改 &#123;user&#125; 和 &#123;password&#125; </span><br><span class="line">mysql&gt; GRANT ALL PRIVILEGES ON dolphinscheduler.* TO &#x27;&#123;user&#125;&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;&#123;password&#125;&#x27;;</span><br><span class="line">mysql&gt; GRANT ALL PRIVILEGES ON dolphinscheduler.* TO &#x27;&#123;user&#125;&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;&#123;password&#125;&#x27;;</span><br><span class="line"></span><br><span class="line">mysql&gt; flush privileges;</span><br></pre></td></tr></table></figure>

<p><em>mysql 8</em></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql -uroot -p</span><br><span class="line"></span><br><span class="line">mysql&gt; CREATE DATABASE dolphinscheduler DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</span><br><span class="line"></span><br><span class="line"># 修改 &#123;user&#125; 和 &#123;password&#125; </span><br><span class="line">mysql&gt; CREATE USER &#x27;&#123;user&#125;&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;&#123;password&#125;&#x27;;</span><br><span class="line">mysql&gt; GRANT ALL PRIVILEGES ON dolphinscheduler.* TO &#x27;&#123;user&#125;&#x27;@&#x27;%&#x27;;</span><br><span class="line">mysql&gt; CREATE USER &#x27;&#123;user&#125;&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;&#123;password&#125;&#x27;;</span><br><span class="line">mysql&gt; GRANT ALL PRIVILEGES ON dolphinscheduler.* TO &#x27;&#123;user&#125;&#x27;@&#x27;localhost&#x27;;</span><br><span class="line">mysql&gt; FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>update dolphinscheduler_env.sh<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改ds环境配置，修改指定数据库为mysql，以及元数据库</span></span><br><span class="line">export DATABASE=$&#123;DATABASE:-mysql&#125;</span><br><span class="line">export SPRING_PROFILES_ACTIVE=$&#123;DATABASE&#125;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">SPRING_DATASOURCE_URL EXAMPLE:</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">export</span> SPRING_DATASOURCE_URL=<span class="string">&quot;jdbc:mysql://127.0.0.1:3306/dolphinscheduler?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false&quot;</span></span></span><br><span class="line">export SPRING_DATASOURCE_URL=&quot;jdbc:mysql://[ip]:[port]/dolphinscheduler?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false&quot;</span><br><span class="line">export SPRING_DATASOURCE_USERNAME=&#123;user&#125;</span><br><span class="line">export SPRING_DATASOURCE_PASSWORD=&#123;password&#125; </span><br></pre></td></tr></table></figure></li>
<li>init database<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /path/to/dolphinscheduler</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ds version 2.0.*</span></span><br><span class="line">sh script/create-dolphinscheduler.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ds version 3.0.*</span></span><br><span class="line">sh tools/bin/upgrade-schema.sh</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="Docker，K8s"><a href="#Docker，K8s" class="headerlink" title="Docker，K8s"></a>Docker，K8s</h4><p>Docker:<br><a href="https://dolphinscheduler.apache.org/zh-cn/docs/2.0.6/user_doc/guide/installation/docker.html">Docker: How to replace Database as MySQL to DolphinScheduler meta database?</a></p>
<p>K8s:<br><a href="https://dolphinscheduler.apache.org/zh-cn/docs/2.0.6/user_doc/guide/installation/kubernetes.html">K8s: How to replace Database as MySQL to DolphinScheduler meta database?</a></p>
<h3 id="3-Storage-Not-Enabled"><a href="#3-Storage-Not-Enabled" class="headerlink" title="3. Storage Not Enabled"></a>3. Storage Not Enabled</h3><blockquote>
<p>Cause：Currently, ETL selects local file storage, which needs to be configured correctly in the DS environment, otherwise the “storage not enabled” problem will occur.</p>
</blockquote>
<center>
   <img src="/2022/08/09/Dolphin-Scheduler-Project/pro_local_storage.png" width="80%">
</center>

<p><strong>Solution:</strong></p>
<h4 id="1-K8s"><a href="#1-K8s" class="headerlink" title="1. K8s:"></a>1. K8s:</h4><p>update values.yaml as follow:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">common:</span></span><br><span class="line">  <span class="attr">configmap:</span></span><br><span class="line">    <span class="attr">RESOURCE_STORAGE_TYPE:</span> <span class="string">&quot;HDFS&quot;</span></span><br><span class="line">    <span class="attr">RESOURCE_UPLOAD_PATH:</span> <span class="string">&quot;/dolphinscheduler&quot;</span></span><br><span class="line">    <span class="attr">FS_DEFAULT_FS:</span> <span class="string">&quot;file:///&quot;</span></span><br><span class="line">  <span class="attr">fsFileResourcePersistence:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;ReadWriteMany&quot;</span></span><br><span class="line">    <span class="attr">storageClassName:</span> <span class="string">&quot;-&quot;</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">&quot;20Gi&quot;</span></span><br></pre></td></tr></table></figure>
<p>The values of storageClassName and storage depend on actual value.</p>
<p>Attention: storageClassName must support access mode: <em>ReadWriteMany</em>.</p>
<h4 id="2-Cluster"><a href="#2-Cluster" class="headerlink" title="2. Cluster"></a>2. Cluster</h4><p>修改 &#x2F;path&#x2F;to&#x2F;ds&#x2F;conf&#x2F;config&#x2F;install_config.conf</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">resource storage <span class="built_in">type</span>: HDFS, S3, NONE</span></span><br><span class="line">resourceStorageType=&quot;HDFS&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">resource store on HDFS/S3 path, resource file will store to this hdfs path, self configuration, please make sure the directory exists on hdfs and has <span class="built_in">read</span> write permissions. <span class="string">&quot;/dolphinscheduler&quot;</span> is recommended</span></span><br><span class="line">resourceUploadPath=&quot;/dolphinscheduler&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="keyword">if</span> resourceStorageType is HDFS，defaultFS write namenode address，HA, you need to put core-site.xml and hdfs-site.xml <span class="keyword">in</span> the conf directory.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="keyword">if</span> S3，write S3 address，HA，<span class="keyword">for</span> example ：s3a://dolphinscheduler，</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Note，S3 be sure to create the root directory /dolphinscheduler</span></span><br><span class="line">defaultFS=&quot;file:///&quot;</span><br></pre></td></tr></table></figure>
<p><strong>make sure that user owns the right to access the folder</strong></p>
<h3 id="4-work-group-default-have-not-received-the-heartbeat"><a href="#4-work-group-default-have-not-received-the-heartbeat" class="headerlink" title="4. work group default have not received the heartbeat"></a>4. work group default have not received the heartbeat</h3><blockquote>
<p>Cause：In multi-NIC environment, zookeeper, dolphinscheduler, &#x2F;etc&#x2F;hosts and so on should be config correctly.</p>
</blockquote>
<center>
   <img src="/2022/08/09/Dolphin-Scheduler-Project/pro_multi_NIC.png" width="80%">
</center>

<p><strong>Solution:</strong></p>
<ol>
<li><p><em>ipconfig -a</em>: check NIC</p>
<center>
<img src="/2022/08/09/Dolphin-Scheduler-Project/sol_multi_NIC_ipconfig.png" width="80%">
</center>
</li>
<li><p><em>cat &#x2F;etc&#x2F;hosts</em>: ip map</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-- backend-pulsar-101</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-- backend-pulsar-102</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-- backend-pulsar-103</span></span><br><span class="line">-- backend-pulsar-101</span><br><span class="line">-- backend-pulsar-102</span><br><span class="line">-- backend-pulsar-103</span><br></pre></td></tr></table></figure>
</li>
<li><p><em>conf&#x2F;common.properties</em>: dolphinscheduler register ip in zookeeper</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">network interface preferred like eth0, default: empty</span></span><br><span class="line">dolphin.scheduler.network.interface.preferred=eth1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">network IP gets priority, default: inner outer</span></span><br><span class="line">dolphin.scheduler.network.priority.strategy=outer</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="https://dolphinscheduler.apache.org/en-us/docs/2.0.5/user_doc/guide/installation/docker.html">Dolphinscheduler(2.0.5) docker deploy</a></li>
<li><a href="https://programmersought.com/article/432910485874/">ProgrammerSought: dolphinscheduler-2.0.3</a></li>
<li><a href="https://www.its203.com/article/yj970605/121029526">Dolphinscheduler + Mysql搭建部署</a></li>
<li><a href="https://blog.csdn.net/weixin_37681466/article/details/123126799">Dolphinscheduler 上传文件出现租户不存在的问题</a></li>
</ol>
]]></content>
      <tags>
        <tag>Big Data</tag>
      </tags>
  </entry>
  <entry>
    <title>Brew</title>
    <url>/2022/03/28/Homebrew/</url>
    <content><![CDATA[<p>在使用mac系统的时候，和win 的一个区别在于sofeware的安装，要将从int下载下来的包，拽入app store中，安装在指定的位置。后来发现mac中存在一个工具——homebrew，能有效的帮助用户下载和管理相应的应用软件。本文也是记录下一些常用的homebrew的用法，提高homebrew的使用。</p>
<blockquote>
<p>What Does Homebrew Do?</p>
<ul>
<li>Homebrew installs the stuff you need that Apple (or your Linux system) didn’t.</li>
<li>Homebrew installs packages to their own directory and then symlinks their files into &#x2F;usr&#x2F;local (on macOS Intel).</li>
<li>It’s all Git and Ruby underneath, so hack away with the knowledge that you can easily revert your modifications and merge upstream updates.</li>
</ul>
</blockquote>
<center>
  <img src="/2022/03/28/Homebrew/logo.png" width="80%">
</center>

<span id="more"></span>

<h1 id="What-Is-Homebrew"><a href="#What-Is-Homebrew" class="headerlink" title="What Is Homebrew?"></a>What Is Homebrew?</h1><p>Homebrew: 是一款自由及开放源代码的软件包管理系统，用以简化macOS系统上的软件安装过程，最初由马克斯·霍威尔（Max Howell）写成。因其可扩展性得到了一致好评，而在Ruby on Rails社区广为人知。</p>
<p>Homebrew使用GitHub，通过用户的贡献扩大对软件包的支持。2012年，Homebrew是GitHub上拥有最多新贡献者的项目。2013年，Homebrew同时成为GitHub上最多贡献者及最多已关闭问题的项目。</p>
<p>默认安装在&#x2F;usr&#x2F;local，由一个核心git版本库构成，以使用户能更新Homebrew。包管理器使用一种称为“公式”（formula）的DSL脚本来管理依赖、下载源代码及配置和编译软件，从源代码中构建软件。称为“瓶”（bottle）的二进制包是用默认选项预编译好的公式。</p>
<h1 id="安装、配置与使用流程"><a href="#安装、配置与使用流程" class="headerlink" title="安装、配置与使用流程"></a>安装、配置与使用流程</h1><h2 id="homebrew的安装"><a href="#homebrew的安装" class="headerlink" title="homebrew的安装"></a>homebrew的安装</h2><ol>
<li>调用安装指令<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#下载安装脚本</span></span><br><span class="line">/usr/bin/ruby -e <span class="string">&quot;<span class="subst">$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装路径</span></span><br><span class="line"><span class="comment"># curl 安装路径</span></span><br><span class="line"><span class="built_in">cd</span> /usr/local/Homebrew</span><br></pre></td></tr></table></figure>
<center>
  <img src="/2022/03/28/Homebrew/homebrew_path.jpg" width="80%">
</center></li>
</ol>
<p>如果在国内，使用brew会有一定的限制，可以选择换源,确保homebrew的使用。</p>
<blockquote>
<p><em>笔者国内的公司可以合法访问外网，所以并未进行相应的换源。</em></p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1. 替换为清华镜像源</span></span><br><span class="line"><span class="built_in">cd</span> <span class="string">&quot;<span class="subst">$(brew --repo)</span>&quot;</span></span><br><span class="line">git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换homebrew-core.git</span></span><br><span class="line"><span class="built_in">cd</span> <span class="string">&quot;<span class="subst">$(brew --repo)</span>/Library/Taps/homebrew/homebrew-core&quot;</span></span><br><span class="line">git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># 刷新源</span></span><br><span class="line">brew update</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 替换为阿里云源</span></span><br><span class="line"><span class="built_in">cd</span> <span class="string">&quot;<span class="subst">$(brew --repo)</span>&quot;</span></span><br><span class="line">git remote set-url origin https://mirrors.aliyun.com/homebrew/brew.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换homebrew-core.git</span></span><br><span class="line"><span class="built_in">cd</span> <span class="string">&quot;<span class="subst">$(brew --repo)</span>/Library/Taps/homebrew/homebrew-core&quot;</span></span><br><span class="line">git remote set-url origin https://mirrors.aliyun.com/homebrew/homebrew-core.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># 刷新源</span></span><br><span class="line">brew update</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 替换为腾讯云源</span></span><br><span class="line"><span class="built_in">cd</span> <span class="string">&quot;<span class="subst">$(brew --repo)</span>&quot;</span></span><br><span class="line">git remote set-url origin https://mirrors.cloud.tencent.com/homebrew/brew.git</span><br><span class="line"></span><br><span class="line">替换homebrew-core.git:</span><br><span class="line"><span class="built_in">cd</span> <span class="string">&quot;<span class="subst">$(brew --repo)</span>/Library/Taps/homebrew/homebrew-core&quot;</span></span><br><span class="line">git remote set-url origin https://mirrors.cloud.tencent.com/homebrew/homebrew-core.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># 刷新源</span></span><br><span class="line">brew update</span><br></pre></td></tr></table></figure>
<h1 id="cask"><a href="#cask" class="headerlink" title="cask"></a>cask</h1><p>brew 是从下载源码解压然后 .&#x2F;configure &amp;&amp; make install ，同时会包含相关依存库。并自动配置好各种环境变量，而且易于卸载。 </p>
<p>brew cask 是 已经编译好了的应用包 （.dmg&#x2F;.pkg），仅仅是下载解压，放在统一的目录中（&#x2F;opt&#x2F;homebrew-cask&#x2F;Caskroom），省掉了自己去下载、解压、拖拽（安装）等蛋疼步骤，同样，卸载相当容易与干净。这个对一般用户来说会比较方便，包含很多在 AppStore 里没有的常用软件。</p>
<p>也可以理解为，<strong>brew针对CLI程序，brew cask解决GUI程序的安装</strong>。</p>
<p>brew 另一个好处可以管理软件的升级。</p>
<h1 id="软件安装"><a href="#软件安装" class="headerlink" title="软件安装"></a>软件安装</h1><ol>
<li>安装CLI软件以curl为例<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># homebrew 安装curl</span></span><br><span class="line">brew install curl</span><br></pre></td></tr></table></figure>
<img src="/2022/03/28/Homebrew/homebrew_install.jpg"></li>
</ol>
<p>可以看到，curl的安装路径在</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/usr/local/Cellar/curl/</span><br></pre></td></tr></table></figure>
<blockquote>
<p>To clarify: The “Cellar” directory is a location that Homebrew made up for its own use. (The name fits with Homebrew’s “beer” theme: the “cellar” is where you store your “kegs” of “homebrew”.) No other software uses it. So if you don’t need Homebrew and the programs you installed using Homebrew, you can delete Cellar.</p>
</blockquote>
<ol start="2">
<li>安装GUI软件以有道词典为例:<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># homebrew 安装有道词典</span></span><br><span class="line">brew install --cask youdaodict</span><br></pre></td></tr></table></figure>
<center>
  <img src="/2022/03/28/Homebrew/youdaodict.jpg" width="80%">
</center></li>
</ol>
<center>
  <img src="/2022/03/28/Homebrew/youdaologo.jpg" width="80%">
  </center>

<h1 id="brew-常用方法"><a href="#brew-常用方法" class="headerlink" title="brew 常用方法"></a>brew 常用方法</h1><ul>
<li>安装软件: brew install git</li>
<li>卸载软件: brew uninstall git</li>
<li>搜索软件: brew search git</li>
<li>显示已经安装软件列表: brew list</li>
<li>删除旧版本安装包缓存: brew cleanup git、brew cleanup</li>
<li>查看那些已安装的程序需要更新: brew outdated</li>
<li>更新软件，把所有的Formula目录更新: brew update</li>
<li>更新某具体软件: brew upgrade git</li>
<li>锁定某个软件禁止更新: brew pin git</li>
<li>解除禁更锁定: brew unpin git</li>
<li>查看brew存放安装包的缓存地址: brew –cache</li>
<li>显示安装的服务: brew services list</li>
<li>启动: brew services start mysql</li>
<li>停止: brew services stop mysql</li>
<li>重启: brew services restart mysql</li>
</ul>
<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="https://www.zhihu.com/question/22624898">1. 知乎：brew和brew cask有什么区别？</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/325795191">2. 知乎：homebrew与brew的常用命令</a></p>
<p><a href="https://brew.sh/">3. homebrew 官方文档</a></p>
]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Image Fingerprint</title>
    <url>/2022/06/07/Image_Fingerprint/</url>
    <content><![CDATA[<p>When I tried to build a database for images, a parameter was required to designed for the identification of each image. </p>
<p>In this article, I explored how to establish the fingerprint of each image by combining its<br>image dhash code and text hash code.</p>
<center>
        <img src="/2022/06/07/Image_Fingerprint/image_fingerprint_logo.jpg" width="80%">
</center>


<span id="more"></span>

<h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>The fingerprint wsa needed when I tried to establish my database for images. This database not only should be able to<br>insert the new image record, but the old record can be updated when its image content changed. Therefore, it’s necessary to<br>build a parameter including the features of primary key(format name) and image content.</p>
<p>To achieve this two features, I used this two methods below:</p>
<ol>
<li>dHash (image feature)</li>
<li>hexdigest (image format name feature)</li>
</ol>
<h1 id="dHash-Method"><a href="#dHash-Method" class="headerlink" title="dHash Method"></a>dHash Method</h1><p>In common case, there are three image hash methods(aHash, pHash and dHash) in mython. I chose the dhash method to generate<br>the image hash code.</p>
<p>Dhash, also known as  Difference Hash, is a quick algorithm to compare in images visually. Comparing to ahash and phash,<br>this method is far more accurate and quick. That’s the most important reason for me to choose this image hash method.</p>
<p>And this method to create dhash is very simple:</p>
<ol>
<li>Convert the image to grayscale</li>
<li>Downsize it to a 9x9 thumbnail (size&#x3D;8 means an 8+1 by 8+1 image)</li>
<li>Produce a 64-bit “row hash”: a 1 bit means the pixel intensity is increasing in the x direction, 0 means it’s decreasing</li>
<li>Do the same to produce a 64-bit “column hash” in the y direction</li>
<li>Combine the two values to produce the final 128-bit hash value</li>
</ol>
<p>We can apply this method by embedding the following code into our project.</p>
<figure class="highlight pycon"><table><tr><td class="code"><pre><span class="line">import dhash</span><br><span class="line">from PIL import Image</span><br><span class="line"></span><br><span class="line">image = Image.open(&#x27;dhash-test.jpg&#x27;)</span><br><span class="line">row, col = dhash.dhash_row_col(image)</span><br><span class="line">print(dhash.format_bytes(row, col))</span><br><span class="line">print(dhash.format_hex(row, col))</span><br></pre></td></tr></table></figure>

<h1 id="hexdigest"><a href="#hexdigest" class="headerlink" title="hexdigest"></a>hexdigest</h1><p>At first, I used the <strong>hash</strong>() function to get the text parameter’s hash code. However, this result hash code varied<br>every time the project processed.  This is because ths purpose of <strong>hash</strong>() function is to create the unique hash code<br>for program to identify, and its result is not fixed which cannot be used as text unique identification code.</p>
<p>Then, I used hashlib library to construct the text hash code. We can use hexdigest() function by embedding the following<br>code into private code.</p>
<figure class="highlight pycon"><table><tr><td class="code"><pre><span class="line">import hashlib</span><br><span class="line">md5 = hashlib.md5()</span><br><span class="line">md5.update(dev.encode(&#x27;utf-8&#x27;))</span><br><span class="line">format_name_hash = md5.hexdigest()</span><br></pre></td></tr></table></figure>

<h1 id="conference"><a href="#conference" class="headerlink" title="conference"></a>conference</h1><p><a href="https://arxiv.org/abs/2006.00819">1. DHash: Enabling Dynamic and Efficient Hash Tables</a><br><a href="https://pypi.org/project/dhash/">2. Pypi dhash 1.3</a></p>
]]></content>
      <tags>
        <tag>Basic</tag>
      </tags>
  </entry>
  <entry>
    <title>Internship ASA(Apple Search Ads)</title>
    <url>/2022/04/07/Internship%20ASA(Apple%20Search%20Ads)/</url>
    <content><![CDATA[<p>本文是为了记录与总结笔者在实习(前10天)中完成的第一个小项目——<strong>ASA(Apple Search Ads)投放数据拉取</strong>.<br>该项目大体由数据拉取、数据清洗、数据存储三个部分构成，笔者在这个项目中，目前实现了每天定时拉取应用数据，对其进行格式化处理，上传至Bigquery数据库中。</p>
<p><strong>TO BE CONTINUED …</strong></p>
<center>
    <img src="/2022/04/07/Internship%20ASA(Apple%20Search%20Ads)/asa_logo.jpg" , width="80%">
</center>
<span id="more"></span>

<h1 id="What-is-ASA"><a href="#What-is-ASA" class="headerlink" title="What is ASA"></a>What is ASA</h1><p>Apple Search Ads helps people discover your app when they search on the App Store, matching customers with your app right when they’re looking.</p>
<p>苹果搜索广告（Apple Search Ads）是苹果官方设置在iphone、ipad AppStore中的竞价广告，它展示在特定关键词搜索结果首位（ipad为右上角），每次搜索仅展示一个广告位，用户可以通过点击广告下载对应的App。苹果搜索广告展示页面有特殊的标识——蓝色背景和”Ad“字样的图标。</p>
<center>
    <img src="/2022/04/07/Internship%20ASA(Apple%20Search%20Ads)/ad_show.jpg" , width="80%">
</center>

<p>ASA一共有两种模式，basic&#x2F;advanced,实习期间我主要运用的是advanced模式。</p>
<center>
    <img src="/2022/04/07/Internship%20ASA(Apple%20Search%20Ads)/two_kinds.jpg" , width="80%">
</center>

<h1 id="实习部分"><a href="#实习部分" class="headerlink" title="实习部分"></a>实习部分</h1><h1 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h1><h2 id="苹果搜索广告的竞价模式"><a href="#苹果搜索广告的竞价模式" class="headerlink" title="苹果搜索广告的竞价模式"></a>苹果搜索广告的竞价模式</h2><p>搜索广告能否在特定关键词下展示以及展示量级受到竞价系数的影响，影响竞价系数的因素有两个——<strong>相关性</strong>和<strong>出价</strong>。</p>
<p>竞价系数&#x3D;相关性*CPT出价</p>
<p>影响App与投放关键词相关性的因素有以下两个方面：<br><strong>App元数据</strong>。 App的名称、副标题、关键词、描述等文本信息会对App与关键词的相关性产生影响。</p>
<p><strong>用户反馈</strong>。App在特定关键词下的广告从展示到点击、下载的转化率过低时，搜索广告系统会判断该关键与App的相关性较差，从而降低两者的相关性，减少广告展示量甚至不再展示。</p>
<p>苹果搜索广告采用竞价系统，最终按照点击（cost-per-taps）计费，也就是说只有用户点击广告时开发者才需要付出费用。点击的实际成本采用<strong>次价密封竞价模式</strong>，<em>是根据开发者出价和仅次于该出价的竞争对手出价计算得出</em>。</p>
<blockquote>
<p>例如：关键词“games”某开发者出价为5美元&#x2F;CPT,仅次于该出价的为3美元&#x2F;CPT,最后成交价格高于3美元而低于5美元。也就是说开发者可以投标竞价而不用担心过度支付。</p>
</blockquote>
<h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><h3 id="账户体系"><a href="#账户体系" class="headerlink" title="账户体系"></a>账户体系</h3><p>Account<br>账户，任何一个AppleID都可以注册成为搜索广告账户。账户下对投放应用没有限制，可以投放任意一款在线应用，也可以同时投放一款或多款应用。</p>
<p>Campaign Group<br>广告组，广告计划（Campaign）的集合。广告组能够开放查看或修改权限给其他苹果搜索广告账户，便于数据分享。每一个Campaign Group可以创建2000个Campaign。</p>
<p>Campaign<br>广告计划，一个计划对应一款App在一个国家的广告活动，一个广告计划内可以创建2000个Ad Group。</p>
<p>Ad Group<br>关键词组，是关键词的集合。一个关键词组中可以添加1000个关键词、2000个屏蔽词。开发者可以根据关键词的类型设置不同的词组，比如可以将竞品品牌词、行业词设置不同的词组，对比投放效果。</p>
<p>Keywords<br>关键词，竞价广告中最低的投放单元。开发者可针对每一个Campaign设定出价、匹配模式等等。</p>
<center>
    <img src="/2022/04/07/Internship%20ASA(Apple%20Search%20Ads)/asa_structure.png" width="80%">
</center>

<center>
    <img src="/2022/04/07/Internship%20ASA(Apple%20Search%20Ads)/ASA账户结构说明.jpg" , width="80%">
</center>

<p><a href="https://zhuanlan.zhihu.com/p/150152235"><em>ps: ASA 账户结构说明</em></a></p>
<h3 id="创建广告计划"><a href="#创建广告计划" class="headerlink" title="创建广告计划"></a>创建广告计划</h3><p>App Name：应用名称</p>
<p>Storefront：广告投放地区</p>
<p>Budget：总预算，创建搜索广告时为一个App，也就是Campaign（广告计划）设置的预算金额。Budget在广告开启后，只能提高不能降低。</p>
<p>Daily Cap：每日预算，当花费达到每日预算上限时，广告就会在当天停止展示，如果Campaign仍有剩余预算，则会在第二天重新开始投放。每日预算是选填项，苹果搜索广告系统并不会严格执行每日预算，因此实际花费会高于或低于每日预算。</p>
<p>Devices：设备，可选择iphone、ipad或iphone and ipad</p>
<p>Default Max CPT Bid ：默认点击出价，这个价格将默认为广告组中任何关键词以及Search Match的出价。</p>
<p>CPA Goal：目标CPA，是开发者期望的每个获取量（cost-per-acquisition）的价格。目标CPA是选填项，这个数值苹果系统同样不会严格执行，甚至有时候实际CPA会大大高于目标CPA。</p>
<p>Search Match：搜索匹配，是指苹果系统自动为广告匹配搜索词的行为。搜索匹配是一项默认功能，它使用多种资源将广告与App Store上的相关搜索进行匹配，其中包括应用在App Store列表中的元数据，相同分类中类似应用的相关信息以及其他搜索数据。搜索匹配的CPT出价依据为默认最高CPT单价。</p>
<p>Recommended Keywords：推荐关键词，在创建Ad Group时，苹果搜索广告系统为应用推荐的关键词。推荐关键词数量不会超过50个。</p>
<p>Customer Types：受众类型，包括三个选项，All User、Have not downloaded the app、Have downloaded my other apps</p>
<p>Gender：性别，可选择male、famale或all。</p>
<p>Age range：年龄，搜索广告不会向13岁及以下的人群展示广告，年龄最低可选18岁，最高为65+。</p>
<p>Locations：位置，搜索广告支持位置细分，可以针对特定的州或城市投放广告。</p>
<p>Negative Keywords：屏蔽词，屏蔽词可以确保广告不会针对特定关键词展示。在搜索广告中，有两个层级可以添加屏蔽词——Campaign和Ad Group。 屏蔽词可以帮助开发者控制成本并提高广告系列的效率。</p>
<p>Exact Match&#x2F;Broad Match：精确匹配&#x2F;广泛匹配。</p>
<p>精确匹配包含四种匹配方式，即原型、单复数、各种形态、拼写错误，开发者无需单独添加这几种形态的关键词，广告也能够匹配到这些关键词，这种方式能够最大限度的控制可能展示广告的搜索内容，造成广告展示量降低，但点击率（TTR）和转化率（CR）可能会提高。在关键词中，添加有双括号的[keyword]的关键词采用的是精确匹配。</p>
<h3 id="报表"><a href="#报表" class="headerlink" title="报表"></a>报表</h3><p>CPT：Cost-Per-Tap，是搜索广告的计费模式，即广告定价是按照点击数量收取费用。</p>
<p>Impressions：展示量</p>
<p>Taps：点击量</p>
<p>Conversions：获取（安装）量，也可理解为下载量。New Downloads是指首次下载该款App的新用户。Redownloads是指当用户下载某款App后，删除该App并在App Store上点击苹果搜索广告后再次下载同一App，或将该App下载到其他设备时所产生的下载量。LAT是指 Limit Ad Tracking限制广告追踪，开启LAT的设备将不会接收到广告或对其活动进行跟踪。LAT On Conversions来自已启用LAT的用户。LAT Off Conversions来自未在其设备上启用LAT的用户的安装。</p>
<p>CR（Conversion Rate）：下载转化率，下载量&#x2F;点击量</p>
<p>TTR（Tap-Through Rate）：点击转化率，点击量&#x2F;下载量</p>
<p>Avg CPT：平均CPT单价</p>
<p>Avg CPA：平均CPA单价</p>
<p>Search Term：搜索项目，是广告展示、点击或下载量的详细来源，会统计到下载量来自哪个关键词，这里的关键词不是指投放设置的关键词，而是指用户看到并点击广告之前，搜索的关键词。</p>
<p>Match Source：匹配来源，是指搜索项目的来源。匹配来源主要有两种——Keywords、Search Match：Keywords是指搜索项目来源于添加关键词的广泛或精确匹配形式；Search Match是指搜索项目来源于系统自动匹配出的关键词。</p>
<p>Low volume terms：低量，这意味着这些数据低于Apple的隐私权阈值，例如搜索词必须至少达到10词展示，否则搜索词报表中会显示“低量”值。</p>
<p>User withheld：用户保留，如果广告用户在其设备上启用了“显示广告跟踪”或停用了位置服务时，可能会在性别、年龄和位置的报表中看到用户保留。</p>
<p>CPI（cost-per-install）：每个下载（安装）的费用，即按安装付费。</p>
<p>Maximum Cost-Per-Install (CPI)：愿意为每个安装的应用支付的最高金额。 实际CPI永远不会超过这个金额。</p>
<p>Monthly Budget：每月预算。 搜索广告基础版每个App每月最高预算为5000美元。月预算可以随时更改，直至最高金额。需要注意的是，预算增加会立即生效，减少将在下个自然月生效。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://searchads.apple.com/advanced">1. 官方网站</a><br><a href="https://zhuanlan.zhihu.com/p/42119163">2. 值得收藏!Apple Search Ads专有名词解释</a><br><a href="https://zhuanlan.zhihu.com/p/150152235">3. ASA 账户结构说明</a></p>
]]></content>
      <categories>
        <category>Intership</category>
      </categories>
      <tags>
        <tag>intership</tag>
        <tag>ads</tag>
      </tags>
  </entry>
  <entry>
    <title>Intership Appsflyer</title>
    <url>/2022/04/18/Intership%20Appsflyer/</url>
    <content><![CDATA[<p>AppsFlyer是以色列公司APPSFLYER LTD旗下移动归因与营销分析平台品牌。目标是帮助应用营销人员做出决策。</p>
<center>
        <img src="/2022/04/18/Intership%20Appsflyer/appsflyer.png" width="80%">
</center>

<span id="more"></span>

<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>AppsFlyer（以下简称AF）是SaaS移动营销分析和归因平台（类似国内的友盟），总部位于加利福尼亚州的旧金山。出海的应用或多或少都会用到。</p>
<p>所谓归因就是找到事件发生的原因。通常的说法就是，用户安装了你的App，是因为哪个广告带来的效果。</p>
<h1 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h1><p><strong>Organic Install 自然量安装</strong><br>指的是不需要你的推广，用户自发的下载并安装了你的应用。</p>
<p><strong>Non-Organic Install 非自然量安装</strong><br>指的是你通过某些广告点击跳转到App下载的界面下载并安装的。非自然量安装主要是广告商给你带来的，是你早期流量的来源，应该重点关注的。</p>
<p><strong>Impression 广告的曝光或展示</strong></p>
<p><strong>Conversion Rate(CVR) 转化率</strong><br>non-organic installs 除以广告点击数。</p>
<p><strong>Attribution</strong> 归因<br>追溯应用安装和其他事件的源头，确定是哪个渠道最终导致某一激活或者应用内事件的发生。</p>
<p><strong>Multi-touch Attribution 多源归因</strong><br>传统的归因把事件发生的全部功劳都归于产生最后一次点击的渠道，多源归因会考虑在这之前也产生了点击的其他渠道，因为他们对事件的发生也起到了推动作用。</p>
<p><strong>Assisted Installs 辅助性安装</strong><br>在一个 non-organic install 转化的过程中，假设用户分别点击了渠道A，渠道B 和渠道C 的广告，然后进行下载并激活应用; 那么渠道A 和B 就各自贡献一个辅助性安装(assisted install)。</p>
<p><strong>Re-engagement</strong><br>广告类型的主要目标是为了增加已有用户的活跃性，提醒用户更加频繁的体验应用。</p>
<p><strong>Re-targeting 重定向或再营销</strong><br>针对那些已经安装但又卸载了应用的用户的广告类型，为的是调动这部分用户重新安装应用。</p>
<p><strong>Revenue 应用收入</strong><br>统计时间区间内新增用户至今为止产生的收益，而收益的统计依赖于应用内事件(in-app event)埋点设置。例如您如果对事件A 和事件B 设置了收益，那么Revenue 最终呈现的就是对应选中的那部分用户至今为止在事件A 和事件B 的收益总和。</p>
<p><strong>Life-Time Value(LTV) 生命周期价值</strong><br>用户在整个生命周期中给广告主带来的总价值。</p>
<p><strong>Session 应用开启</strong><br>定义忠实用户和计算留存等的依据。</p>
<p><strong>ARPU (AverageRevenue per User) 每个用户平均产生的收益</strong><br>Revenue 除以激活用户数。</p>
<p><strong>DeepLink 深度链接</strong><br>可以直达网站或者应用中某个特定页面的链接，比如可以直接打开手机上的淘宝应用，并跳转到某个商品的详情页。</p>
<p><strong>Media Source 媒体源</strong><br> 进行服务器对服务器对接的渠道统称为媒体源(Media Source)，这些媒体源可以是publisher,移动广告平台和移动广告网盟等。</p>
<p> <strong>In-app Event 应用内事件</strong><br> 在AppsFlyer 平台上分析用户行为的基础。通过在接入AppsFlyer SDK 时对关注的事件(e.g. 购买，充值和注册等)添加对应代码，便可实现对用户从激活到整个生命周期的追踪和分析。</p>
]]></content>
      <categories>
        <category>Intership</category>
      </categories>
      <tags>
        <tag>intership</tag>
        <tag>ads</tag>
      </tags>
  </entry>
  <entry>
    <title>Internship Fetch Data</title>
    <url>/2022/04/14/Internship%20Fetch%20Data/</url>
    <content><![CDATA[<p>在实习的前两个星期，感觉最常接触的一类任务就是<strong>数据的拉取</strong>以及api的调用，本文也是对这个part的内容、方法以及遇到的问题进行一个记录。</p>
<center>
        <img src="/2022/04/14/Internship%20Fetch%20Data/fd_logo.jpg" , width="80%">
</center>
<span id="more"></span>


<p>在向服务器发送拉取数据请求（比如asa，bigo等等），大多都是通过https request的请求实现。其中最常使用的method为GET 与POST,但是当需要我去解释http 报文结构， http request原理以及两个方法区别的时候，竟会一时语塞。这也是写此篇文章的目的，相信此时的记录有助我我对这类知识的理解，对后期的工作会有极大的帮助。</p>
<center>
        <img src="/2022/04/14/Internship%20Fetch%20Data/报文结构.jpg" , width="80%">
</center>

<h1 id="请求报文"><a href="#请求报文" class="headerlink" title="请求报文"></a>请求报文</h1><p>一条请求信息主要四个部分组成：</p>
<ol>
<li>请求行 （request line）</li>
<li>请求头部（header）</li>
<li>空行（填充至头部区域结尾）</li>
<li>请求数据（Optionally a message-body）</li>
</ol>
<center>
        <img src="Internship-Summary-Fetch-Data/http报文.png" width="80%">
</center>

<figure class="highlight http"><table><tr><td class="code"><pre><span class="line">POST /user HTTP/1.1                       // 请求行</span><br><span class="line"><span class="attribute">Host</span><span class="punctuation">: </span>www.user.com</span><br><span class="line"><span class="attribute">Content-Type</span><span class="punctuation">: </span>application/x-www-form-urlencoded</span><br><span class="line"><span class="attribute">Connection</span><span class="punctuation">: </span>Keep-Alive</span><br><span class="line"><span class="attribute">User-agent</span><span class="punctuation">: </span>Mozilla/5.0.                  // 以上是请求头</span><br><span class="line">（此处必须有一空行 |                         // 空行分割header和请求内容 </span><br><span class="line">name=world                                // 请求体(可选，如get请求时可选)</span><br></pre></td></tr></table></figure>
<h2 id="Request-line"><a href="#Request-line" class="headerlink" title="Request line"></a>Request line</h2><p>请求行由方法token开头，伴随着请求url，协议版本，以换行符，这几个部分由空格隔开。</p>
<h2 id="Request-Method"><a href="#Request-Method" class="headerlink" title="Request Method"></a>Request Method</h2><p>请求方法指示要对给定 Request-URI 标识的资源执行的方法。</p>
<p>请求方法比较多：GET、POST、HEAD、PUT、DELETE、OPTIONS、TRACE、CONNECT，其中最常用的是GET和POST。</p>
<ul>
<li><p>GET<br>  使用 GET 的请求应该只检索数据，并且对数据没有其他影响。传递参数长度受限制，因为传递的参数是直接表示在地址栏中，而特定浏览器和服务器对url的长度是有限制的。GET<strong>不适合用来传递私密数据</strong>，也不适合拿来传递大量数据。</p>
</li>
<li><p>POST<br>  POST把传递的数据封装在HTTP请求数据中，以名称&#x2F;值的形式出现，可以传输大量数据，对数据量没有限制，也不会显示在URL中。</p>
</li>
</ul>
<p><a href="https://www.tutorialspoint.com/http/http_requests.htm">more request methods</a></p>
<h2 id="Request-Header"><a href="#Request-Header" class="headerlink" title="Request Header"></a>Request Header</h2><p>请求头部由关键字&#x2F;值对组成，每行一对。<br>例如：  </p>
<ul>
<li><p>User-Agent：产生请求的浏览器类型;</p>
</li>
<li><p>Accept：客户端可识别的响应内容类型列表;星号 “ * ” 用于按范围将类型分组，用 “ &#x2F; ” 指示可接受全部类型，用“ type&#x2F;* ”指示可接受 type 类型的所有子类型;<br>比如 Accept：text&#x2F;xml（application&#x2F;json）表示希望接受到的是xml（json）类型。</p>
</li>
<li><p>Accept-Language：客户端可接受的自然语言;</p>
</li>
<li><p>Accept-Encoding：客户端可接受的编码压缩格式;</p>
</li>
<li><p>Accept-Charset：可接受的应答的字符集;</p>
</li>
<li><p>Host：请求的主机名，允许多个域名同处一个IP 地址，即虚拟主机;</p>
</li>
<li><p>connection：连接方式(close 或 keepalive);</p>
</li>
<li><p>Cookie：存储于客户端扩展字段，向同一域名的服务端发送属于该域的cookie;</p>
</li>
<li><p>Content-Type：发送端发送的实体数据的数据类型。<br>比如，Content-Type：text&#x2F;html（application&#x2F;json）表示发送的是html类型</p>
</li>
</ul>
<center>
        <img src="/2022/04/14/Internship%20Fetch%20Data/rh.jpg" , width="80%">
</center>

<h2 id="Content-Type"><a href="#Content-Type" class="headerlink" title="Content-Type"></a>Content-Type</h2><p>常见的Content-Type：</p>
<table>
<thead>
<tr>
<th align="center">Content-Type</th>
<th align="center">解释</th>
</tr>
</thead>
<tbody><tr>
<td align="center">text&#x2F;html</td>
<td align="center">html格式</td>
</tr>
<tr>
<td align="center">text&#x2F;plain</td>
<td align="center">纯文本格式</td>
</tr>
<tr>
<td align="center">text&#x2F;css</td>
<td align="center">CSS格式</td>
</tr>
<tr>
<td align="center">text&#x2F;javascript</td>
<td align="center">js格式</td>
</tr>
<tr>
<td align="center">image&#x2F;gif</td>
<td align="center">gif图片格式</td>
</tr>
<tr>
<td align="center">image&#x2F;jpeg</td>
<td align="center">jpg图片格式</td>
</tr>
<tr>
<td align="center">image&#x2F;png</td>
<td align="center">png图片格式</td>
</tr>
<tr>
<td align="center">application&#x2F;x-www-form-urlencoded</td>
<td align="center">POST专用：普通的表单提交默认是通过这种方式。form表单数据被编码为key&#x2F;value格式发送到服务器。</td>
</tr>
<tr>
<td align="center"><strong>application&#x2F;json</strong></td>
<td align="center"><strong>POST专用：用来告诉服务端消息主体是序列化后的 JSON 字符串</strong></td>
</tr>
<tr>
<td align="center">text&#x2F;xml</td>
<td align="center">POST专用：发送xml数据</td>
</tr>
<tr>
<td align="center">multipart&#x2F;form-data</td>
<td align="center">POST专用</td>
</tr>
</tbody></table>
<h2 id="空行"><a href="#空行" class="headerlink" title="空行"></a>空行</h2><p>请求头之后是一个空行，通知服务器以下不再有请求头</p>
<h2 id="请求体"><a href="#请求体" class="headerlink" title="请求体"></a>请求体</h2><p>GET没有请求数据，POST有。与请求数据相关的最常使用的请求头是 Content-Type 和 Content-Length 。</p>
<h1 id="响应报文"><a href="#响应报文" class="headerlink" title="响应报文"></a>响应报文</h1><p>HTTP响应由三个部分组成，分别是：状态行、消息报头、响应正文。</p>
<center>
        <img src="/2022/04/14/Internship%20Fetch%20Data/响应报文.jpg" width="80%">
</center>
## Status line/状态行
由三个部分组成：
- **The protocol version（版本协议）**, usually HTTP/1.1.
- **A status code（状态码）**，indicating success or failure of the request. Common status codes are 200, 404, or 302
- **A status text（状态信息）**. A brief, purely informational, textual description of the status code to help a human understand the HTTP message.

<h2 id="Headers-x2F-消息报头"><a href="#Headers-x2F-消息报头" class="headerlink" title="Headers&#x2F;消息报头"></a>Headers&#x2F;消息报头</h2><p><a href="https://en.wikipedia.org/wiki/List_of_HTTP_header_fields">Response fields</a></p>
<center>
                <img src="/2022/04/14/Internship%20Fetch%20Data/response_header.jpg" width="80%">
</center>

<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><blockquote>
<p>通过上述分析，我们可以发现 HTTP 请求其实像发送邮件一样，请求头是我们附加的一些信息，可以告诉收件人，谁发的邮件，谁可以看，这是一封加密的邮件，你要根据什么规则把这封邮件翻译过来等等，请求内容当然就是我们要发送的具体内容。</p>
</blockquote>
<blockquote>
<p>HTTP 响应就是收件人给我的回信，响应头会告诉我们一些附加信息，比如告诉我们，你发送的那个收件人没有（404）或者我正确收到了你的来信（200），我给你的响应是什么加密方式，你要怎么解码，响应内容就是他要告诉我们的具体内容。</p>
</blockquote>
<h1 id="Python-requests模块"><a href="#Python-requests模块" class="headerlink" title="Python requests模块"></a>Python requests模块</h1><p>在实习工作期间，经常会面对拉取服务器数据的需求，这个时候会频繁调用requests的模块来发送http 请求，有必要对此类的知识点进行一个总结整理。</p>
<p>Request官网上对该模块进行描述：</p>
<p>Requests is an elegant and simple HTTP library for Python, built for human beings.</p>
<h2 id="get"><a href="#get" class="headerlink" title="get"></a>get</h2><p>用于获取资源，当采用 GET 方式请求指定资源时， 被访问的资源经服务器解析后立即返回响应内容。通常以 GET 方式请求特定资源时， 请求中不应该包含请求体，所有需要向被请求资源传递的数据都应该通过 URL 向服务器传递。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># post 语法</span></span><br><span class="line">response = requests.request(<span class="string">&quot;get&quot;</span>, <span class="string">&quot;http://www.baidu.com/&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加headers，可以传入headers参数来增加请求头中的headers信息。</span></span><br><span class="line"><span class="comment"># 如果要将参数放在url中传递，可以利用 params 参数。</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"> </span><br><span class="line">kw = &#123;<span class="string">&#x27;wd&#x27;</span>: <span class="string">&#x27;北极熊&#x27;</span>&#125;</span><br><span class="line"> </span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) &quot;</span></span><br><span class="line">                  <span class="string">&quot;AppleWebKit/537.36 (KHTML, like Gecko) &quot;</span></span><br><span class="line">                  <span class="string">&quot;Chrome/54.0.2840.99 Safari/537.36&quot;</span>&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment"># params 接收一个字典或者字符串的查询参数，字典类型自动转换为url编码，不需要urlencode()</span></span><br><span class="line">response = requests.get(<span class="string">&quot;http://www.baidu.com/s?&quot;</span>, params=kw, headers=headers)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 查看响应内容，response.text 返回的是Unicode格式的数据</span></span><br><span class="line"><span class="built_in">print</span>(response.text)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 查看响应内容，response.content返回的字节流数据</span></span><br><span class="line"><span class="built_in">print</span>(response.content)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 查看完整url地址</span></span><br><span class="line"><span class="built_in">print</span>(response.url)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 查看响应头部字符编码</span></span><br><span class="line"><span class="built_in">print</span>(response.encoding)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 查看响应码</span></span><br><span class="line"><span class="built_in">print</span>(response.status_code)</span><br></pre></td></tr></table></figure>


<h2 id="post"><a href="#post" class="headerlink" title="post"></a>post</h2><p>POST 动作：用于提交数据， 当采用 POST 方式向指定位置提交数据时，数据被包含在请求体中，服务器接收到这些数据后可能会建立新的资源、也可能会更新已有的资源。同时 POST 方式的请求体可以包含非常多的数据，而且格式不限。因此 POST 方式用途较为广泛，几乎所有的提交操作都可以使用 POST 方式来完成。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"> </span><br><span class="line">formdata = &#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;AUTO&quot;</span>,</span><br><span class="line">    <span class="string">&quot;i&quot;</span>: <span class="string">&quot;i love python&quot;</span>,</span><br><span class="line">    <span class="string">&quot;doctype&quot;</span>: <span class="string">&quot;json&quot;</span>,</span><br><span class="line">    <span class="string">&quot;xmlVersion&quot;</span>: <span class="string">&quot;1.8&quot;</span>,</span><br><span class="line">    <span class="string">&quot;keyfrom&quot;</span>: <span class="string">&quot;fanyi.web&quot;</span>,</span><br><span class="line">    <span class="string">&quot;ue&quot;</span>: <span class="string">&quot;UTF-8&quot;</span>,</span><br><span class="line">    <span class="string">&quot;action&quot;</span>: <span class="string">&quot;FY_BY_ENTER&quot;</span>,</span><br><span class="line">    <span class="string">&quot;typoResult&quot;</span>: <span class="string">&quot;true&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">url = <span class="string">&quot;http://fanyi.youdao.com/translate?smartresult=dict&amp;smartresult=rule&amp;smartresult=ugc&amp;sessionFrom=null&quot;</span></span><br><span class="line"> </span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; WOW64) &quot;</span></span><br><span class="line">                  <span class="string">&quot;AppleWebKit/537.36 (KHTML, like Gecko) &quot;</span></span><br><span class="line">                  <span class="string">&quot;Chrome/51.0.2704.103 Safari/537.36&quot;</span>&#125;</span><br><span class="line"> </span><br><span class="line">response = requests.post(url, data=formdata, headers=headers)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(response.text)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 如果是json文件可以直接显示</span></span><br><span class="line"><span class="built_in">print</span>(response.json())</span><br></pre></td></tr></table></figure>

<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><ol>
<li><a href="https://docs.python-requests.org/zh_CN/latest/">Requests: 让 HTTP 服务人类</a></li>
</ol>
]]></content>
      <categories>
        <category>Intership</category>
      </categories>
      <tags>
        <tag>intership</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Fragments</title>
    <url>/2022/04/08/Linux-Fragments/</url>
    <content><![CDATA[<p>This article is used to record some knowledge fragments when using linux.</p>
<center>
        <img src="/2022/04/08/Linux-Fragments/linux-logo.png" width="80%">
</center>

<span id="more"></span>

<h1 id="bin-和-sbin-的区别"><a href="#bin-和-sbin-的区别" class="headerlink" title="bin 和 sbin 的区别"></a>bin 和 sbin 的区别</h1><p>&#x2F;bin目录（binary）是二进制执行文件目录，主要用于具体应用</p>
<p>&#x2F;sbin目录（system binary）是系统管理员专用的二进制代码存放目录，主要用于系统管理</p>
<p>bin是binary的缩写，是可执行的二进制文件。&#x2F;bin里面一般是基本的，大家都要用的工具；sbin里面的s是system的意思，是供system administrator使用的工具。</p>
<blockquote>
<p>在hadoop中，&#x2F;bin 目录存放对Hadoop相关服务（HDFS, YARN）进行操作的脚本；&#x2F;sbin 目录存放启动或停止Hadoop相关服务的脚本</p>
</blockquote>
<h1 id="export的用法"><a href="#export的用法" class="headerlink" title="export的用法"></a>export的用法</h1><p>export命令用于设置或显示环境变量。</p>
<p>在shell中执行程序时，shell会提供一组环境变量。export可新增，修改或删除环境变量，供后续执行的程序使用。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export [-fnp][变量名称]=[变量设置值]</span><br><span class="line"> </span><br><span class="line">参数说明：</span><br><span class="line"> </span><br><span class="line">-f 　代表[变量名称]中为函数名称。</span><br><span class="line">-n 　删除指定的变量。变量实际上并未删除，只是不会输出到后续指令的执行环境中。</span><br><span class="line">-p 　列出所有的shell赋予程序的环境变量</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">example</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将/tmp/hello的路径加入到PATH，从而可以在任何地方直接使用hello命令。</span></span><br><span class="line">export PATH=$PATH:/tmp/hello</span><br></pre></td></tr></table></figure>

<p>export设置环境变量是暂时的，只在本次登录中有效，可修改如下文件来使命令长久有效</p>
<ol>
<li><p>修改profile文件：</p>
</li>
<li><p>修改自己home路径下的 ~&#x2F;.bashrc 或 ~&#x2F;.bash_profile ~&#x2F;.zshrc文件：</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Basic</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Pyenv</title>
    <url>/2022/04/02/Pyenv/</url>
    <content><![CDATA[<p>在python编程的过程中，经常需要在2.x 与  3.x 中进行切换，2和3两个版本间差异巨大，需要进行管理。</p>
<p>pyenv是一个forked自ruby社区的简单、低调、遵循UNIX哲学的Python环境管理工具, 它可以轻松切换全局解释器版本, 同时结合vitualenv插件可以方便的管理对应的包源.</p>
<p>pyenv和virtualenv。前者用于管理不同的Python版本，后者用 于管理不同的工作环境，能够极好得解决我们工作学习中遇到的python版本环境控制问题。</p>
<span id="more"></span>

<h1 id="Pyenv简介"><a href="#Pyenv简介" class="headerlink" title="Pyenv简介"></a>Pyenv简介</h1><p>如前言所言，pyenv允许用户在不同版本的python中切换。pyenv基于rbenv进行开发，由ruby语言进行编程，为python而准备的。</p>
<h2 id="Pyenv-用处"><a href="#Pyenv-用处" class="headerlink" title="Pyenv 用处"></a>Pyenv 用处</h2><ol>
<li>允许用户更改全局python的版本</li>
<li>为每个python版本都提供支持</li>
<li>允许使用环境变量重写python版本</li>
<li>有助于使用 tox 跨 Python 版本进行测试</li>
</ol>
<h2 id="Pyenv-不允许"><a href="#Pyenv-不允许" class="headerlink" title="Pyenv 不允许"></a>Pyenv 不允许</h2><ol>
<li>pyenv是由shell 脚本编写的，不存在python的引导问题。</li>
<li>需要将把pyenv安装目录载入到环境中。</li>
<li>pyenv无法管理虚拟环境，但是可以利用 virtualenv或者 pyenv-virtualenv实现。</li>
</ol>
<h1 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h1><p>pyenv 就是使用了中间层的原理来实现的的，即 shims&#x2F;垫片。</p>
<h2 id="初始化-pyenv"><a href="#初始化-pyenv" class="headerlink" title="初始化 pyenv"></a>初始化 pyenv</h2><p>安装 pyenv 后，需要在当前 shell 的配置文件（bash 为 ~&#x2F;.bashrc，zsh 为 ~&#x2F;.zshrc 等等）中增加相应命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vim ~/.bashrc</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/data/sammyshen/.pyenv/bin:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"><span class="built_in">eval</span> <span class="string">&quot;<span class="subst">$(pyenv init -)</span>&quot;</span></span><br><span class="line"><span class="built_in">eval</span> <span class="string">&quot;<span class="subst">$(pyenv virtualenv-init -)</span>&quot;</span></span><br></pre></td></tr></table></figure>

<p>这几个命令在每次登陆 shell 时，会更改 PATH 环境变量，将 pyenv 的路径加入到 PATH 环境变量前面。</p>
<h2 id="shims-x2F-垫片的简化基本原理"><a href="#shims-x2F-垫片的简化基本原理" class="headerlink" title="shims&#x2F;垫片的简化基本原理"></a>shims&#x2F;垫片的简化基本原理</h2><p>Linux 执行命令时，是依次遍历 PATH 环境变量的每个路径，查找所执行的命令。当在某个目录下找到第一个匹配时即停止遍历，所以 PATH 环境变量中，前面的路径比后面的路径具有更高的优先级。</p>
<p>pyenv 在 <del>&#x2F;.pyenv&#x2F;shims 目录下创建了各种 python 相关命令的垫片（</del>&#x2F;.bashrc 中加入的命令调用 pyenv-rehash 生成的，pyenv install 命令也会调用 pyenv-rehash 进行更新）</p>
<center>
        <img src="/2022/04/02/Pyenv/shim.jpg">
</center>

<p>从脚本内容可以看出，当我们执行某个命令 program “param1” “param2” ……时，实际执行的是 pyenv exec “program” “param1” “param2” ……。</p>
<p>例如执行 python -V，实际执行的是 pyenv exec python -V。</p>
<h2 id="确定版本号"><a href="#确定版本号" class="headerlink" title="确定版本号"></a>确定版本号</h2><p>在 pyenv-exec 命令中，首先会调用 pyenv-version-name 确定 python 版本或虚拟环境版本，具体查找规则为：</p>
<center>
        <img src="/2022/04/02/Pyenv/Pyenv 确定版本号.jpg" width="80%">
</center>

<h2 id="确定与版本号对应的可执行文件"><a href="#确定与版本号对应的可执行文件" class="headerlink" title="确定与版本号对应的可执行文件"></a>确定与版本号对应的可执行文件</h2><p>在 pyenv-exec 命令中，会再调用 pyenv-which 确定可执行文件 program 的路径。如果前面 pyenv-version-name 确定了 python 版本或虚拟环境版本，则使用 &lt;pyenv 安装路径&gt;&#x2F;versions&#x2F;&lt;版本号&gt;&#x2F;bin&#x2F;&lt;程序名&gt; 或 &lt;pyenv 安装路径&gt;&#x2F;versions&#x2F;&lt;版本号&gt;&#x2F;env&#x2F;&lt;虚拟环境名&gt;&#x2F;bin&#x2F;&lt;程序名&gt;，否则遍历所有版本号的安装路径，按顺序取第一个匹配到的可执行文件。</p>
<h2 id="执行命令"><a href="#执行命令" class="headerlink" title="执行命令"></a>执行命令</h2><p>确定与版本号对应的可执行文件路径 path 之后，执行以下命令：<br>exec -a program “$path” “param1” “param2” ……</p>
<p>（注：即执行 “$path” “param1” “param2”，并使用 program 作为程序名，程序名即 shell 中的 $0，python 中的 sys.argv0）<br>例如执行 python -V，确定 pyenv 版本为 2.7.17，对应可执行文件为 ~&#x2F;.pyenv&#x2F;versions&#x2F;2.7.17&#x2F;bin&#x2F;python，则执行命令为：<br>exec -a python ~&#x2F;.pyenv&#x2F;versions&#x2F;2.7.17&#x2F;bin&#x2F;python -V<br>以上就是 pyenv 执行命令的基本原理了。</p>
<h1 id="pyenv常用指令"><a href="#pyenv常用指令" class="headerlink" title="pyenv常用指令"></a>pyenv常用指令</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建新的环境,位于 ~/.pyenv/versions/</span></span><br><span class="line">$ pyenv virtualenv 2.7.1 env271</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换到新的环境</span></span><br><span class="line">$ pyenv activate env271</span><br><span class="line"></span><br><span class="line"><span class="comment"># 退回到系统环境</span></span><br><span class="line">$ pyenv deactivate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除新创建的环境</span></span><br><span class="line">$ <span class="built_in">rm</span> -rf ~/.pyenv/versions/env271/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看当前 pyenv 可检测到的所有版本，处于激活状态的版本前以 * 标示。</span></span><br><span class="line">$ pyenv versions</span><br><span class="line">  system</span><br><span class="line">* 3.5.1 (<span class="built_in">set</span> by /root/.pyenv/version)</span><br><span class="line">  3.5.1/envs/flask_py351</span><br><span class="line">  3.5.1/envs/pelican</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看当前处于激活状态的版本，括号中内容表示这个版本是由哪条途径激活的（global、local、shell）</span></span><br><span class="line">$ pyenv version</span><br><span class="line">3.5.1 (<span class="built_in">set</span> by /root/.pyenv/version)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 python-build（一个插件） 安装一个 Python 版本，到 $PYENV_ROOT/versions 路径下。</span></span><br><span class="line">$ pyenv install -v 2.7.3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 卸载</span></span><br><span class="line">$ pyenv uninstall 2.7.3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为所有已安装的可执行文件 （如：~/.pyenv/versions/*/bin/*） 创建 shims，</span></span><br><span class="line"><span class="comment"># 因此，每当你增删了 Python 版本或带有可执行文件的包（如 pip）以后，都应该执行一次本命令</span></span><br><span class="line">$ pyenv <span class="built_in">rehash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置全局的 Python 版本，通过将版本号写入 ~/.pyenv/version 文件的方式。</span></span><br><span class="line">$ pyenv global 3.4.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置面向程序的本地版本，通过将版本号写入当前目录下的 .python-version 文件的方式。</span></span><br><span class="line"><span class="comment"># 通过这种方式设置的 Python 版本优先级较 global 高。pyenv 会从当前目录开始向上逐级查找 .python-version 文件，直到根目录为止。</span></span><br><span class="line"><span class="comment">#若找不到，就用 global 版本。</span></span><br><span class="line">$ pyenv <span class="built_in">local</span> 2.7.3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置面向 shell 的 Python 版本，通过设置当前 shell 的 PYENV_VERSION 环境变量的方式。</span></span><br><span class="line"><span class="comment"># 这个版本的优先级比 local 和 global 都要高。--unset 参数可以用于取消当前 shell 设定的版本。</span></span><br><span class="line">$ pyenv shell pypy-2.2.1</span><br><span class="line">$ pyenv shell --<span class="built_in">unset</span></span><br></pre></td></tr></table></figure>

<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="https://github.com/pyenv/pyenv">1. pyenv-官方文档</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1593478">2. pyenv神器原理分析</a></p>
]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Ripple--The News Real Time Heat Analysis Platform</title>
    <url>/2022/03/20/Ripple-The-News-Real-Time-Heat-Analysis-Platform/</url>
    <content><![CDATA[<p>Ripple 该平台实现对当前新闻网舆论热点事件的实时可视化分析，主要在<a href="https://www.bilibili.com/video/BV1mK411T7WY?p=1">B站:新闻网大数据实时分析可视化系统</a>这一项目基础进行进一步改造，使用框架组件包括：Hadoop、Zookeeper、Flume、Kafka、Hive、HBase、Cloudera HUE、Spark、Echart等。</p>
<p>本文主要Ripple项目的业务分析、技术造型、集群规划、安装部署、整合集成与开发和可视化设计等部分组成。项目目标为充分理解搭建过程中涉及的大数据组件，提升个人相关开发能力。</p>
<span id="more"></span>
<h1 id="项目需求分析、架构设计、数据流程设计"><a href="#项目需求分析、架构设计、数据流程设计" class="headerlink" title="项目需求分析、架构设计、数据流程设计"></a>项目需求分析、架构设计、数据流程设计</h1><h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2><ol>
<li>捕获用户浏览的日志信息(TB)</li>
<li>实时分析前20名流量最高的新闻话题</li>
<li>实时统计当前线上已曝光的新闻话题</li>
<li>统计哪些时段用户浏览量最高</li>
<li>报表</li>
</ol>
<h2 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h2><center>
<img src="/2022/03/20/Ripple-The-News-Real-Time-Heat-Analysis-Platform/project_structure.png" width="80%">
</center>

<h2 id="数据流程"><a href="#数据流程" class="headerlink" title="数据流程"></a>数据流程</h2><center>
<img src="/2022/03/20/Ripple-The-News-Real-Time-Heat-Analysis-Platform/data_flow.png" width="80%">
</center>

<h1 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h1><h2 id="集群资源规划"><a href="#集群资源规划" class="headerlink" title="集群资源规划"></a>集群资源规划</h2><p>该项目出于学习目的，比较腾讯云、阿里云、华为云等云服务，选择租用腾讯云的高性能云服务器,由于我们选择同一子网下的三台机器，所以我们只需使用节点的内网ip即可，并且保证了数据传输速度。  </p>
<center>
<img src="/2022/03/20/Ripple-The-News-Real-Time-Heat-Analysis-Platform/cloud_machine.png" width="80%">
</center>

<p>三台服务器相关资源的部署规划如图所示:</p>
<center>
  <img src="/2022/03/20/Ripple-The-News-Real-Time-Heat-Analysis-Platform/cluster_resources.png" width="80%">
</center>

<br>

<p>为了方便三台云服务器间的数据传输与登录，需要设计三台云服务器间的ssh免密登录，其原理为将每台主机authorized_keys文件里面包含的主机（ssh密钥），该主机都能无密码登录，所以只要每台主机的authorized_keys文件里面都放入其他主机（需要无密码登录的主机）的ssh密钥即可,参考<a href="https://www.cnblogs.com/shireenlee4testing/p/10366061.html">Hadoop集群配置免密SSH登录方法</a>。</p>
<p>完成ssh免密登录之后，由于ip地址相对难以记忆，通过修改&#x2F;etc&#x2F;hosts中的映射关系，这样能够方便再服务期间传输文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 利用如下指令,在hosts末尾中添加ip映射</span></span><br><span class="line">vi /etc/hosts</span><br></pre></td></tr></table></figure>
<center>
  <img src="/2022/03/20/Ripple-The-News-Real-Time-Heat-Analysis-Platform/ssh.png">
</center>
<br>


<h1 id="Hadoop-配置"><a href="#Hadoop-配置" class="headerlink" title="Hadoop 配置"></a>Hadoop 配置</h1><p>首先，根据教程，再&#x2F;opt文件夹下文件树为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">|-- opt <span class="comment"># 主要文件夹</span></span><br><span class="line">|   |-- data <span class="comment"># 存放数据</span></span><br><span class="line">|   |-- modules <span class="comment"># haddop</span></span><br><span class="line">|   |-- softwares <span class="comment"># 相关软件下载包</span></span><br><span class="line">|   |-- tool <span class="comment"># 工具插件</span></span><br><span class="line">|</span><br></pre></td></tr></table></figure>
<p>在<a href="https://archive.apache.org/dist">A.hadoop资源下载</a>中，-&gt; hadoop -&gt; core -&gt;   hadoop-2.6.5.tar.gz，下载相关资源，并下载在software，最终解压至&#x2F;opt&#x2F;modules&#x2F;，重命名为hadoop。</p>
<p>其中hadoop文件夹中的各文件及其功能如图所示:</p>
<center>
    <img src="/2022/03/20/Ripple-The-News-Real-Time-Heat-Analysis-Platform/Hadoop_安装目录.png" , width="80%">
</center>

<ul>
<li>&#x2F;bin 目录存放对Hadoop相关服务（HDFS, YARN）进行操作的脚本；</li>
<li>&#x2F;etc 目录存放Hadoop的配置文件</li>
<li>&#x2F;lib 目录存放Hadoop的本地库（对数据进行压缩解压缩功能）</li>
<li>&#x2F;sbin 目录存放启动或停止Hadoop相关服务的脚本</li>
<li>&#x2F;share 目录存放Hadoop的依赖jar包、文档、和官方案例</li>
</ul>
<p>下载相关jdk也安装在&#x2F;opt&#x2F;modules中，配置&#x2F;etc&#x2F;profile环境变量。对于hadoop，有几个关键文件需要配置:</p>
<h2 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h2><p>路径: &#x2F;opt&#x2F;modules&#x2F;hadoop&#x2F;etc&#x2F;hadoop</p>
<p>功能:  配置集群全局参数属性，用于定义系统级别的参数，如HDFS URL 、Hadoop的临时目录等</p>
<h2 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h2><p>路径: &#x2F;opt&#x2F;modules&#x2F;hadoop&#x2F;etc&#x2F;hadoop&#x2F;hdfs-site.xml</p>
<p>功能: 配置HDFS组件的属性，如名称节点和数据节点的存放位置、文件副本的个数、文件的读取权限等</p>
<h2 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title="mapred-site.xml"></a>mapred-site.xml</h2><p>路径: &#x2F;opt&#x2F;modules&#x2F;hadoop&#x2F;etc&#x2F;hadoop&#x2F;mapred-site.xml</p>
<p>功能：配置map-reduce组件的属性，包括JobHistory Server 和应用程序参数两部分，如reduce任务的默认个数、任务所能够使用内存的默认上下限等</p>
<h2 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h2><p>路径: &#x2F;opt&#x2F;modules&#x2F;hadoop&#x2F;etc&#x2F;hadoop&#x2F;yarn-site.xml</p>
<p>功能: 集群资源管理系统参数，配置ResourceManager ，nodeManager的通信端口，web监控端口等</p>
<p>yran日志聚集：日志聚集是YARN提供的日志中央化管理功能，它能将运行完成的Container任务日志上传到HDFS上，从而减轻NodeManager负载，且提供一个中央化存储和分析机制。</p>
<h2 id="hadoop-env-xml"><a href="#hadoop-env-xml" class="headerlink" title="hadoop-env.xml"></a>hadoop-env.xml</h2><p>路径: &#x2F;opt&#x2F;modules&#x2F;hadoop&#x2F;etc&#x2F;hadoop&#x2F;haddop-env.sh</p>
<p>功能: hadoop运行环境,用来定义hadoop运行环境相关的配置信息</p>
<h1 id="hadoop集群启动"><a href="#hadoop集群启动" class="headerlink" title="hadoop集群启动"></a>hadoop集群启动</h1><p>在2.2节中对hadoop文件夹下的bin与sbin进行了说明</p>
<blockquote>
<ul>
<li>&#x2F;bin 目录存放对Hadoop相关服务（HDFS, YARN）进行操作的脚本；</li>
<li>&#x2F;sbin 目录存放启动或停止Hadoop相关服务的脚本</li>
</ul>
</blockquote>
<p>在启动集群的时候，主要调用&#x2F;sbin中的函数。</p>
<p>首先,在<strong>第一次启动</strong>集群的时候，我们需要对Namenode进行格式化。</p>
<h2 id="NameNode的格式化"><a href="#NameNode的格式化" class="headerlink" title="NameNode的格式化"></a>NameNode的格式化</h2><p><strong>为什么需要格式化</strong></p>
<p>Hadoop NameNode是HDFS文件系统的集中位置，它保存文件系统中所有文件的目录树，并跟踪整个集群中文件数据的保存位置。简而言之，它将元数据与datanode保持相关。当我们格式化namenode时，它会<strong>格式化与数据节点相关的元数据</strong>。通过这样做，所有关于datanode的信息都将丢失，它们可以用于新数据。</p>
<p><strong>如何格式化</strong><br>格式化NameNode前，先关闭掉NameNode节点和DataNode节点，然后一定要删除hadoop目录下的data文件夹和log日志文件夹。最后再进行格式化。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/hadoop namenode -format</span><br></pre></td></tr></table></figure>
<h2 id="hdfs-yarn启动"><a href="#hdfs-yarn启动" class="headerlink" title="hdfs, yarn启动"></a>hdfs, yarn启动</h2><h3 id="启动流程"><a href="#启动流程" class="headerlink" title="启动流程"></a>启动流程</h3><p>在完成NameNode的格式化之后，可以开始启动 hdfs(NameNode, DataNode, SecondaryNameNode) 与 yarn（ResourceManager，NodeManager）。<br>首先，启动hdfs。在2.3中了解，sbin文件夹是用来存储集群启动、关闭等时候调用的文件，其内部主要文件机器功能如下：</p>
<center>
    <img src="/2022/03/20/Ripple-The-News-Real-Time-Heat-Analysis-Platform/sbin（存放启停hadoop服务的脚本文件）.png" width="80%">
</center>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 首先启动hdfs</span></span><br><span class="line">sbin/start-dfs.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动yarn</span></span><br><span class="line">sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在ripple1的启动hdfs，yarn情况如下，ripple1，ripple2，ripple3正常启动</p>
</blockquote>
<center>
<img src="/2022/03/20/Ripple-The-News-Real-Time-Heat-Analysis-Platform/启动hdfs1.jpg" width="80%">
</center>

<center>
    <img src="/2022/03/20/Ripple-The-News-Real-Time-Heat-Analysis-Platform/启动yarn.jpg" width="80%">
</center>


<h3 id="hdfs启动出现问题"><a href="#hdfs启动出现问题" class="headerlink" title="hdfs启动出现问题"></a>hdfs启动出现问题</h3><p>Q1: sbin&#x2F;start-dfs.sh 后ripple2，ripple3机器datanode没有启动</p>
<p>A1: datanode与namenode 的clusterid不一致导致。</p>
<p>查看ripple2的日志。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">默认在hadoop的路径下</span></span><br><span class="line">tail  -25 log/hadoop-root-datanode*.log</span><br></pre></td></tr></table></figure>

<center>
    <img src="/2022/03/20/Ripple-The-News-Real-Time-Heat-Analysis-Platform/Q-datanode启动失败.png" width="80%">
</center>


<p>可以看到错误</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">2022-04-09 17:29:29,989 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-55814a25-a013-48af-ad24-f4689b57728b; datanode clusterID = CID-34619a23-71d3-4112-9ab8-1d39fdbca5ad</span><br><span class="line">2022-04-09 17:29:29,989 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool &lt;registering&gt; (Datanode Uuid unassigned) service to ripple1/172.17.0.13:9000. Exiting.</span><br><span class="line">java.io.IOException: All specified directories are failed to load.</span><br><span class="line">	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:478)</span><br><span class="line">	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1342)</span><br><span class="line">	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1308)</span><br><span class="line">	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:314)</span><br><span class="line">	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:226)</span><br><span class="line">	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:867)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:823)</span><br><span class="line">2022-04-09 17:29:29,990 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool &lt;registering&gt; (Datanode Uuid unassigned) service to ripple1/172.17.0.13:9000</span><br><span class="line">2022-04-09 17:29:30,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool &lt;registering&gt; (Datanode Uuid unassigned)</span><br></pre></td></tr></table></figure>
<p><strong>原因</strong><br>这是我们在format namnode的时候会重置，导致namenode 的clusterID与datanode的clusterID不一致。</p>
<blockquote>
<p>You will get this error when the cluster ID of name node and cluster ID of data node are different. We can see the cluster ID of name node in &lt;dfs.namenode.name.dir&gt;&#x2F;current&#x2F;VERSION file and cluster ID of data node in &lt;dfs.datanode.data.dir&gt;&#x2F;current&#x2F;VERSION file.</p>
</blockquote>
<p><strong>解决方案</strong>：</p>
<p>预防措施：在format namenode之前，我们需要删除所有datanode上的 &lt;dfs.datanode.data.dir&gt; 路径下的所有目录。</p>
<p>解决方案：</p>
<ul>
<li>方案一：如果hdfs中有数据且不想删除，复制namenode的version文件下的clusterID到各个datanode中的VERSION文件即可。</li>
<li>方案二：删除所有namnode与datanode的&lt;dfs.datanode.data.dir&gt; 下的文件，然后再重新format  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/hdfs namenode -format</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="启动测试"><a href="#启动测试" class="headerlink" title="启动测试"></a>启动测试</h3><p>利用yarn集群运行mapreduce程序，来测试hdfs与yarn是否正常启动。<br>主要代码为：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">核心代码：利用yarn运行mapreduce程序</span></span><br><span class="line">bin/yarn jar share/hadoop/mapreduce/hadoop-examples-2.6.5 wordcount 数据源目录 数据输出目录</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">事例代码</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hdfs 构建文件夹 -<span class="built_in">mkdir</span> -p 路径</span></span><br><span class="line"> bin/hdfs dfs -mkdir -p /user/ripple/data/input/</span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash">本地文件存入hdfs之中</span></span><br><span class="line"> bin/hdfs dfs -put /opt/data/wc.input /user/ripple/data/input/</span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash">yarn调用mapreduce 进行wordcount计算</span></span><br><span class="line"> bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar wordcount /user/ripple/data/input/wc.input /user/ripple/data/output/wordcount</span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash"> 查看运行结果</span></span><br><span class="line"> bin/hdfs dfs -text /user/ripple/data/output/wordcount/part*</span><br></pre></td></tr></table></figure>

<center>
    <img src="/2022/03/20/Ripple-The-News-Real-Time-Heat-Analysis-Platform/yarn启动mapreduce.png" width="80%">
</center>

<p>至此，hdfs与yarn的集群启动完毕。</p>
<h1 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h1><p>zookeeper 的部分可以查看<a href="https://wjmars98.github.io/2022/04/10/Zookeeper-Basic/">zookeeper基础</a>.</p>
<h1 id="hdfs-ha-高可用下模式"><a href="#hdfs-ha-高可用下模式" class="headerlink" title="hdfs-ha 高可用下模式"></a>hdfs-ha 高可用下模式</h1><h2 id="hdfs-ha-高可用性"><a href="#hdfs-ha-高可用性" class="headerlink" title="hdfs-ha 高可用性"></a>hdfs-ha 高可用性</h2><p>对于hdfs-ha高可用性的必要性，是因为目前只有一台namenode，如果所在的机器down了，那么hdfs将无法提供服务，所以提出了hdfs-ha的架构模式。</p>
<center>
    <img src="/2022/03/20/Ripple-The-News-Real-Time-Heat-Analysis-Platform/hdfs_ha.jpg" width="80%">
</center>

<p>HDFS通常由两个NameNode组成，一个处于active状态，另一个处于standby状态。Active NameNode对外提供服务，比如处理来自客户端的RPC请求，而Standby NameNode则不对外提供服务，仅同步Active NameNode的状态，以便能够在它失败时快速进行切换，为了让Standby Node与Active Node保持同步，这两个Node都与一组称为JNS的互相独立的进程保持通信(Journal Nodes)。</p>
<h2 id="hdfs-ha-配置"><a href="#hdfs-ha-配置" class="headerlink" title="hdfs-ha 配置"></a>hdfs-ha 配置</h2><p>查看官方文档：<br><a href="https://hadoop.apache.org/docs/r2.10.1/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html">HDFS High Availability Using the Quorum Journal Manager</a></p>
<h2 id="hdfs-ha-各类顺序"><a href="#hdfs-ha-各类顺序" class="headerlink" title="hdfs-ha 各类顺序"></a>hdfs-ha 各类顺序</h2><p>在启动hdfs-ha模式的时候，其中启动，关闭的顺序都十分重要，对hdfs-ha会产生影响，该节来记录一下hdfs-ha的相关正确顺序。</p>
<p><strong>应用层次：ZooKeeper -&gt; Hadoop -&gt; HBase</strong></p>
<p>服务层次： ZooKeeper -&gt; JournalNode (Hadoop) -&gt; NameNode (Hadoop) -&gt; DataNode (Hadoop) -&gt; 主 ResourceManager&#x2F;NodeManager (Hadoop) -&gt; 备份 ResourceManager (Hadoop) -&gt; ZKFC (Hadoop) -&gt; MapReduce JobHistory (Hadoop) -&gt; 主 Hmaster&#x2F;HRegionServer (HBase) -&gt;备份 Hmaster (HBase)</p>
<h3 id="hdfs-ha首次启动顺序"><a href="#hdfs-ha首次启动顺序" class="headerlink" title="hdfs-ha首次启动顺序"></a>hdfs-ha首次启动顺序</h3><ol>
<li>启动 ZooKeeper 集群. 分别登陆到三台机子（ripple1, ripple2, ripple3）上执行<code>zkServer.sh start</code></li>
<li>格式化 ZooKeeper 集群. 在任意的 namenode 上都可以执行.<code>hdfs zkfc –formatZK</code></li>
<li>启动 JournalNode 集群. 分别在ipple1, ripple2, ripple3上执行<code>hadoop-daemon.sh start journalnode</code>.</li>
<li>格式化集群的 NameNode, 在ripple1上格式化namenode<code>hdfs namenode -format</code></li>
<li>启动刚格式化的 NameNode. 在ripple1上执行<code>hadoop-daemon.sh start namenode</code>.</li>
<li>同步 NameNode1 元数据到 NameNode2 上. 在ripple2上执行<code>hdfs namenode -bootstrapStandby</code></li>
<li>启动 NameNode2. ripple2拷贝了元数据之后，就接着启动 namenode 进程<code>hadoop-daemon.sh start namenode</code></li>
<li>启动集群中所有的DataNode. 在ripple1上执行 <code>hadoop-daemons.sh start datanode</code></li>
<li>在 RM1 启动 YARN,在ripple1上执行<code>start-yarn.sh</code></li>
<li>在 RM2 单独启动 YARN。<code>yarn-daemon.sh start resourcemanager</code></li>
<li>启动 ZKFC. 在ripple1与ripple2分别启动<code>hadoop-daemon.sh start zkfc</code></li>
<li>开启历史日志服务, 在ripple1与ripple2分别启动<code>mr-jobhistory-daemon.sh   start historyserver</code><br>至此hdfs-ha正式启动，在ripple1上jps结果，如下图所示：<center>
    <img src="/2022/03/20/Ripple-The-News-Real-Time-Heat-Analysis-Platform/hdfs-ha.jpg" , width="80%">
</center></li>
</ol>
<h3 id="hdfs-ha-非首次启动与关闭顺序"><a href="#hdfs-ha-非首次启动与关闭顺序" class="headerlink" title="hdfs-ha 非首次启动与关闭顺序"></a>hdfs-ha 非首次启动与关闭顺序</h3><p>参考网址: <a href="https://blog.csdn.net/jingsiyu6588/article/details/100166928#t6">3.1 Hadoop 生态系统集群的启动顺序概览</a><br>ps: </p>
<ol>
<li>与 “首次启动格式化集群” 不同的是没有 格式化 ZooKeeper 集群 和 格式化集群的 NameNode 这两个步骤！</li>
<li>一定要按顺序停止，如果先停 ZooKeeper 再停 HBase 的话，基本停不下来</li>
</ol>
<p><strong>未完待续 | To be continued</strong></p>
<h1 id="附录A：Problem"><a href="#附录A：Problem" class="headerlink" title="附录A：Problem"></a>附录A：Problem</h1><h1 id="附录B：参考网站"><a href="#附录B：参考网站" class="headerlink" title="附录B：参考网站"></a>附录B：参考网站</h1><ol>
<li><a href="https://www.bilibili.com/video/BV1mK411T7WY?p=1">B站:新闻网大数据实时分析可视化系统</a></li>
<li><a href="https://hadoop.apache.org/docs/r2.6.5/">Hadoop官方文档</a></li>
<li><a href="https://archive.apache.org/dist">A.hadoop资源下载</a></li>
<li><a href="http://archive.cloudera.com/cdh5">B.hadoop资源下载</a></li>
<li><a href="https://intellipaat.com/community/161/what-exactly-is-hadoop-namenode-formatting">What exactly is hadoop namenode formatting?</a></li>
<li><a href="https://sparkbyexamples.com/hadoop/incompatible-clusterids/">datanode无法启动</a></li>
<li><a href="https://blog.csdn.net/jingsiyu6588/article/details/100166928">HA模式下的各种启动顺序</a></li>
</ol>
]]></content>
      <categories>
        <category>Projects</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Zookepper</tag>
        <tag>Flume</tag>
        <tag>Kafka</tag>
        <tag>Hive</tag>
        <tag>Hbase</tag>
        <tag>Spark</tag>
        <tag>Hue</tag>
      </tags>
  </entry>
  <entry>
    <title>SSL</title>
    <url>/2022/04/05/SSL/</url>
    <content><![CDATA[<p>在处理实习的业务需求的时候，涉及到ssl公钥私钥部分的相关知识。本文用以记录与ssl相关的基础知识及其应用。</p>
<center>
        <img src="/2022/04/05/SSL/SSL encrypted.jpg" width="60%">
</center>

<span id="more"></span>

<h1 id="What-is-SSL"><a href="#What-is-SSL" class="headerlink" title="What is SSL?"></a>What is SSL?</h1><p>安全套接字层 (SSL) 是一种加密安全协议。它最初由 Netscape 于 1995 年开发，旨在确保 Internet 通信中的隐私、身份验证和数据完整性。SSL 是如今使用的现代 TLS 加密的前身。</p>
<p>实施 SSL&#x2F;TLS 的网站的 URL 中带有“HTTPS”，而不是“HTTP”。</p>
<h2 id="TLS-握手"><a href="#TLS-握手" class="headerlink" title="TLS 握手"></a>TLS 握手</h2><blockquote>
<p>TLS 是一种旨在保护互联网通信安全的加密协议。TLS 握手是启动 TLS 加密通信会话的过程。在 TLS 握手过程中，通信双方交换消息以相互确认，彼此验证，确立它们将使用的加密算法，并生成一致的会话密钥。TLS 握手是 HTTPS 工作原理的基础部分。</p>
</blockquote>
<center>
        <img src="/2022/04/05/SSL/TLS.jpg" width="80%">
</center>

<p>通过 TCP 握手打开 TCP 连接后，将发生 TLS 握手。</p>
<h2 id="TLS握手会发生什么"><a href="#TLS握手会发生什么" class="headerlink" title="TLS握手会发生什么"></a>TLS握手会发生什么</h2><ul>
<li>指定将要使用的 TLS 版本（TLS 1.0、1.2、1.3 等）</li>
<li>决定将要使用哪些密码套件（见下文）</li>
<li>通过服务器的公钥和 SSL 证书颁发机构的数字签名来验证服务器的身份</li>
<li>生成会话密钥，以在握手完成后使用对称加密</li>
</ul>
<h2 id="TLS步骤"><a href="#TLS步骤" class="headerlink" title="TLS步骤"></a>TLS步骤</h2><p>TLS 握手的确切步骤将根据所使用的密钥交换算法的类型以及双方支持的密码套件而有所不同。RSA 密钥交换算法最为常用。</p>
<ol>
<li>“客户端问候（client hello）” 消息： 客户端通过向服务器发送“问候”消息来开始握手。该消息将包含<strong>客户端支持的 TLS 版本</strong>，<strong>支持的密码套件</strong>，以及称为一串称为“<strong>客户端随机数（client random）</strong>”的随机字。</li>
<li>“服务器问候（server hello）”消息： 作为对 client hello 消息的回复，服务器发送一条消息，内含<strong>服务器的 SSL 证书</strong>、服务器选择的<strong>密码套件</strong>，以及“<strong>服务器随机数</strong>（server random）”，即由服务器生成的另一串随机字节。</li>
<li>身份验证： 客户端使用颁发该证书的证书颁发机构验证服务器的 SSL 证书。此举确认服务器是其声称的身份，且客户端正在与该域的实际所有者进行交互。</li>
<li>预主密钥： 客户端再发送一串随机字节，即“<strong>预主密钥（premaster secret）</strong>”。预主密钥是<strong>使用公钥加密的，只能使用服务器的私钥解密</strong>。（客户端从服务器的 SSL 证书中获得公钥。）</li>
<li>私钥被使用：服务器对预主密钥进行解密</li>
<li>生成会话密钥：<strong>客户端和服务器均使用客户端随机数、服务器随机数和预主密钥生成会话密钥</strong>。双方应得到相同的结果。</li>
<li>客户端就绪：客户端发送一条“已完成”消息，该消息用会话密钥加密。</li>
<li>服务器就绪：服务器发送一条“已完成”消息，该消息用会话密钥加密。</li>
<li>实现安全对称加密：已完成握手，并使用会话密钥继续进行通信。</li>
</ol>
<h2 id="Diffie-Hellman-握手过程"><a href="#Diffie-Hellman-握手过程" class="headerlink" title="Diffie-Hellman 握手过程"></a>Diffie-Hellman 握手过程</h2><p>所有 TLS 握手均使用非对称加密（公钥和私钥），但并非全都会在生成会话密钥的过程中使用私钥。例如，短暂的 Diffie-Hellman 握手过程如下：</p>
<ol>
<li>客户端问候：客户端发送客户端问候消息，内含协议版本、客户端随机数和密码套件列表。</li>
<li>服务器问候：服务器以其 SSL 证书、其选定的密码套件和服务器随机数回复。与上述 RSA 握手相比，服务器在此消息中还包括以下内容（步骤 3）：</li>
<li>服务器的数字签名：<strong>服务器使用其私钥对客户端随机数、服务器随机数及其 DH 参数</strong> 进行加密。加密后的数据用作服务器的数字签名，从而确定<strong>服务器具有与 SSL 证书中的公钥相匹配的私钥</strong>。</li>
<li>确认数字签名：客户端使用公钥解密服务器的数字签名，验证服务器控制私钥并且是其声称的身份。客户端 DH 参数：客户端将其 DH 参数发送到服务器。</li>
<li>客户端和服务器计算预主密钥：客户端和服务器使用交换的 DH 参数分别计算匹配的预主密钥，而不像 RSA 握手那样由客户端生成预主密钥并将其发送到服务器。</li>
<li>创建会话密钥：与 RSA 握手中一样，客户端和服务器现在从预主密钥、客户端随机数和服务器随机数计算会话密钥。</li>
<li>客户端就绪：与 RSA 握手相同。</li>
<li>服务器就绪</li>
<li>实现安全对称加密</li>
</ol>
<h2 id="密码套件"><a href="#密码套件" class="headerlink" title="密码套件"></a>密码套件</h2><p>密码套件是一组用于建立安全通信连接的加密算法。（加密算法是对数据执行的一组数学运算，以使数据显得随机。）广泛使用的密码套件有多种，而且 TLS 握手的一个重要组成部分就是对这个握手使用哪一密码套件达成一致意见。</p>
<h2 id="使用会话密钥的对称加密"><a href="#使用会话密钥的对称加密" class="headerlink" title="使用会话密钥的对称加密"></a>使用会话密钥的对称加密</h2><p>与非对称加密不同，在对称加密中，会话中的两方使用相同的密钥。TLS 握手后，双方使用相同的会话密钥进行加密。一旦使用了会话密钥，就不再使用公钥和私钥。会话密钥是临时密钥，会话终止后便不再使用。下一会话需要创建一组新的随机会话密钥。</p>
<center>
        <img src="/2022/04/05/SSL/asymmetric.jpg" , width="80%">
</center>


<h1 id="验证源站服务器身份"><a href="#验证源站服务器身份" class="headerlink" title="验证源站服务器身份"></a>验证源站服务器身份</h1><p>来自服务器的 TLS 通信包括消息身份验证码或 MAC，它是用于确认通信源自实际网站的数字签名。这将对服务器进行身份验证，从而防止在途攻击和域欺骗。它还确保数据在传输过程中没有被篡改。</p>
<h1 id="什么是-SSL-证书？"><a href="#什么是-SSL-证书？" class="headerlink" title="什么是 SSL 证书？"></a>什么是 SSL 证书？</h1><p>SSL 证书是网站的源服务器上安装的文件。它只是一个数据文件，包含公钥和网站所有者身份以及其他信息。如果没有 SSL 证书，就无法使用 TLS 来加密网站的流量。</p>
<p>从技术上讲，任何网站所有者都可以创建自己的 SSL 证书，这些证书称为自签名证书。但是，浏览器不认为自签名证书像证书颁发机构颁发的 SSL 证书一样值得信赖。</p>
<h1 id="网站如何获得-SSL-证书？"><a href="#网站如何获得-SSL-证书？" class="headerlink" title="网站如何获得 SSL 证书？"></a>网站如何获得 SSL 证书？</h1><p>网站所有者需要从证书颁发机构获取 SSL 证书，然后将其安装到自己的 Web 服务器上（通常 Web 主机可以处理此过程）。证书颁发机构是一个外部方，可以确认网站所有者是他们所称的身份。他们保留所颁发证书的副本。</p>
<h1 id="HTTP-和-HTTPS-有什么区别？"><a href="#HTTP-和-HTTPS-有什么区别？" class="headerlink" title="HTTP 和 HTTPS 有什么区别？"></a>HTTP 和 HTTPS 有什么区别？</h1><p>“HTTPS”中的 S 代表“安全”。HTTPS 只是具有 SSL&#x2F;TLS 的 HTTP。拥有 HTTPS 地址的网站具有由证书颁发机构颁发的合法 SSL 证书，并且使用 SSL&#x2F;TLS 协议对往返于该网站的流量进行身份验证和加密。</p>
<p>为了鼓励整个互联网转向更安全的 HTTPS，许多 Web 浏览器已开始将 HTTP 网站标记为“不安全”。因此，HTTPS 不仅对于确保用户和用户数据的安全至关重要，而且对于建立与用户的信任也至关重要。测试网站的 SSL&#x2F;HTTPS 问题。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://www.cloudflare.com/zh-cn/learning/ssl/what-is-ssl/">1. Cloudflare 什么是ssl</a></p>
<p><a href="https://www.cloudflare.com/zh-cn/learning/ssl/what-happens-in-a-tls-handshake/">2. TLS握手</a></p>
]]></content>
      <categories>
        <category>Basic</category>
      </categories>
      <tags>
        <tag>SSL</tag>
      </tags>
  </entry>
  <entry>
    <title>Scrapy——DebuggingSpiders</title>
    <url>/2022/04/28/Scrapy-Debug/</url>
    <content><![CDATA[<p>在使用scrapy的时候，由于不能像平常一样对代码进行调试，花费了大量的时间在scrapy运行的等待上，每次溯源去寻找问题都非常麻烦。后来发现scrapy也有属于自己的调试方法，也用此文来记录学习一下scrapy的调试知识。</p>
<span id="more"></span>

<p>考虑下面的spider:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> myproject.items <span class="keyword">import</span> MyItem</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MySpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;myspider&#x27;</span></span><br><span class="line">    start_urls = (</span><br><span class="line">        <span class="string">&#x27;http://example.com/page1&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;http://example.com/page2&#x27;</span>,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="comment"># collect `item_urls`</span></span><br><span class="line">        <span class="keyword">for</span> item_url <span class="keyword">in</span> item_urls:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(item_url, self.parse_item)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_item</span>(<span class="params">self, response</span>):</span><br><span class="line">        item = MyItem()</span><br><span class="line">        <span class="comment"># populate `item` fields</span></span><br><span class="line">        <span class="comment"># and extract item_details_url</span></span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(item_details_url, self.parse_details, meta=&#123;<span class="string">&#x27;item&#x27;</span>: item&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_details</span>(<span class="params">self, response</span>):</span><br><span class="line">        item = response.meta[<span class="string">&#x27;item&#x27;</span>]</span><br><span class="line">        <span class="comment"># populate more `item` fields</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<p>简单地说，该spider分析了两个包含item的页面(start_urls)。Item有详情页面， 所以我们使用 Request 的 meta 功能来传递已经部分获取的item。</p>
<h1 id="Scrapy-Shell"><a href="#Scrapy-Shell" class="headerlink" title="Scrapy Shell"></a>Scrapy Shell</h1><p>Scrapy终端是一个交互终端，供您在未启动spider的情况下尝试及调试您的爬取代码。 其本意是用来测试提取数据的代码，不过您可以将其作为正常的Python终端，在上面测试任何的Python代码。</p>
<h2 id="可用的快捷命令-shortcut"><a href="#可用的快捷命令-shortcut" class="headerlink" title="可用的快捷命令(shortcut)"></a>可用的快捷命令(shortcut)</h2><ul>
<li><p>shelp( ) - 打印可用对象及快捷命令的帮助列表</p>
</li>
<li><p>fetch(request_or_url) - 根据给定的请求(request)或URL获取一个新的response，并更新相关的对象</p>
</li>
<li><p>view(response) - 在本机的<strong>浏览器</strong>打开给定的response。 其会在response的body中添加一个 <base> tag ，使得外部链接(例如图片及css)能正确显示。</p>
</li>
</ul>
<h2 id="可用的Scrapy对象"><a href="#可用的Scrapy对象" class="headerlink" title="可用的Scrapy对象"></a>可用的Scrapy对象</h2><p>Scrapy终端根据下载的页面会自动创建一些方便使用的对象，例如 Response 对象及 Selector 对象(对HTML及XML内容)。</p>
<p>这些对象有:</p>
<ul>
<li><p>crawler - 当前 Crawler 对象.</p>
</li>
<li><p>spider - 处理URL的spider。 对当前URL没有处理的Spider时则为一个 Spider 对象。</p>
</li>
<li><p>request - 最近获取到的页面的 Request 对象。 您可以使用 replace() 修改该request。或者 使用 fetch 快捷方式来获取新的request。</p>
</li>
<li><p>response - 包含最近获取到的页面的 Response 对象。</p>
</li>
<li><p>sel - 根据最近获取到的response构建的 Selector 对象。</p>
</li>
<li><p>settings - 当前的 Scrapy settings</p>
</li>
</ul>
<h2 id="在spider中启动shell来查看response"><a href="#在spider中启动shell来查看response" class="headerlink" title="在spider中启动shell来查看response"></a>在spider中启动shell来查看response</h2><p>有时您想在spider的某个位置中查看被处理的response， 以确认您期望的response到达特定位置。<br>这可以通过 <code>scrapy.shell.inspect_response</code> 函数来实现。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MySpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&quot;myspider&quot;</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">&quot;http://example.com&quot;</span>,</span><br><span class="line">        <span class="string">&quot;http://example.org&quot;</span>,</span><br><span class="line">        <span class="string">&quot;http://example.net&quot;</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="comment"># We want to inspect one specific response.</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;.org&quot;</span> <span class="keyword">in</span> response.url:</span><br><span class="line">            <span class="keyword">from</span> scrapy.shell <span class="keyword">import</span> inspect_response</span><br><span class="line">            inspect_response(response, self)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Rest of parsing code.</span></span><br></pre></td></tr></table></figure>

<p>当运行spider时，您将得到类似下列的输出:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">2014-01-23 17:48:31-0400 [myspider] DEBUG: Crawled (200) &lt;GET http://example.com&gt; (referer: None)</span><br><span class="line">2014-01-23 17:48:31-0400 [myspider] DEBUG: Crawled (200) &lt;GET http://example.org&gt; (referer: None)</span><br><span class="line">[s] Available Scrapy objects:</span><br><span class="line">[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x1e16b50&gt;</span><br><span class="line">...</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; response.url</span></span><br><span class="line">&#x27;http://example.org&#x27;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>也就是运行到指定代码的时候，能够中断爬取，利用shell进行调用。<br>最后您可以点击Ctrl-D(Windows下Ctrl-Z)来退出终端，恢复爬取。</p>
<blockquote>
<p>注意: 由于该终端屏蔽了Scrapy引擎，您在这个终端中不能使用 fetch 快捷命令(shortcut)。 当您离开终端时，spider会从其停下的地方恢复爬取，正如上面显示的那样。</p>
</blockquote>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/shell.html">1. Scrapy终端(Scrapy shell)</a></p>
]]></content>
      <categories>
        <category>Big Data</category>
      </categories>
      <tags>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title>Scrapy: Manage Multiple Pipelines</title>
    <url>/2022/05/10/Scrapy-Manage-Multiple-Pipelines/</url>
    <content><![CDATA[<p>It’s a common situation that managing multiple pipelines are required  when we try to develop some scrapy projects and decide the order of the pipelines. </p>
<p>What’s worse, there may be not only one spider in the porject, and each  spider own different requirements to the project pipelines. And there is no doubt that <strong>effective management of pipelines can greatly improve our efficiency</strong> which is also the purpose of this article.</p>
<center>
    <img src="/2022/05/10/Scrapy-Manage-Multiple-Pipelines/logo.png" , width="80%">
</center>
<span id="more"></span>

<h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>To be more specific, I would love to share a software developing program situation appeared in my program developing process.</p>
<p>When I tried to develop a scrapy project to crawl some data on the imdb website, which not only included the titles and release time, rating and other text data, but also contained the images data like movie posters, I found the a single item contains both.</p>
<p>To solve this problem, of course, we can try to create different spiders which can crawl text data while the other can crawl image data. However, basing on our observation, this data can be crawled by only one spider if we can assemble a functional pipeline module.  Comparing to the first solution, this approach has several advantages:</p>
<ul>
<li>High Efficiency</li>
<li>Code Modularization</li>
<li>Easy to Debug</li>
</ul>
<h2 id="Understand-Pipeline-Module"><a href="#Understand-Pipeline-Module" class="headerlink" title="Understand Pipeline Module"></a>Understand Pipeline Module</h2><p>According to <a href="https://docs.scrapy.org/en/latest/topics/item-pipeline.html">scrapy document</a>, the pipeline is briefly descriped as: </p>
<blockquote>
<p>Item has been scraped by a spider, it is sent to the Item Pipeline which processes it through several components that are executed sequentially.</p>
</blockquote>
<p>As mentioned above, pipeline is designed to process the item data from spiders. And to achieve the designated function, we can try to assemble a number of pipelines in a specific order which is the key to  make a pipeline module to implement complex functions.</p>
<p>As the following code shows, the “custom_setting” decided each pipelines’ order for item data.  In this way, we can make full use of the data contained in item.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># For example</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MovieSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&quot;list&quot;</span></span><br><span class="line">    allowed_domains = [<span class="string">&quot;imdb.com&quot;</span>]</span><br><span class="line">    start_urls = [<span class="string">&quot;https://www.imdb.com/title/tt4788734/&quot;</span>]</span><br><span class="line"></span><br><span class="line">    custom_settings = &#123;</span><br><span class="line">        <span class="string">&quot;ITEM_PIPELINES&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;imdbSpider.pipelines.InitSettingPipeline&quot;</span>: <span class="number">100</span>,</span><br><span class="line">            <span class="string">&quot;imdbSpider.pipelines.BannerPipeline&quot;</span>: <span class="number">200</span>,</span><br><span class="line">            <span class="string">&quot;imdbSpider.pipelines.ImagePipeline&quot;</span>: <span class="number">400</span>,</span><br><span class="line">            <span class="string">&#x27;imdbSpider.pipelines.ProcessImagePipeline&#x27;</span>: <span class="number">500</span>,</span><br><span class="line">            <span class="string">&#x27;imdbSpider.pipelines.UploadPipeline&#x27;</span>: <span class="number">600</span>,</span><br><span class="line">            <span class="string">&quot;imdbSpider.pipelines.ListPipeline&quot;</span>: <span class="number">700</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h1 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h1><h2 id="Crawl-Requirements"><a href="#Crawl-Requirements" class="headerlink" title="Crawl Requirements"></a>Crawl Requirements</h2><p>Firstly, let me to show you the project requirement  as following.</p>
<p>Target crawk website: <a href="https://www.imdb.com/title/tt1877830">imd: The Batman</a></p>
<center>
        <img src="/2022/05/10/Scrapy-Manage-Multiple-Pipelines/imdb-the-batman.jpg" , width="80%">
</center>

<p>Target crawl text info:</p>
<ul>
<li><p>Text: title, rating, description</p>
</li>
<li><p>Image: image</p>
</li>
</ul>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://docs.scrapy.org/en/latest/intro/overview.html">1. Scrapy at a glance</a></p>
]]></content>
      <categories>
        <category>Big Data</category>
      </categories>
      <tags>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title>Scrapy Introduction</title>
    <url>/2022/04/21/Scrapy/</url>
    <content><![CDATA[<p>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。</p>
<p>其最初是为了 页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取API所返回的数据(例如 Amazon Associates Web Services ) 或者通用的网络爬虫。</p>
<p>本文也是对scrapy进行一个初步的介绍。</p>
<center>
        <img src="/2022/04/21/Scrapy/scrapy_logo.png" width="80%">
</center>

<span id="more"></span>
<h1 id="Scrapy-简介"><a href="#Scrapy-简介" class="headerlink" title="Scrapy 简介"></a>Scrapy 简介</h1><p>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。</p>
<p>其最初是为了 页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取API所返回的数据(例如 Amazon Associates Web Services ) 或者通用的网络爬虫。</p>
<h1 id="Scrapy框架、组件与流程"><a href="#Scrapy框架、组件与流程" class="headerlink" title="Scrapy框架、组件与流程"></a>Scrapy框架、组件与流程</h1><p>首先，给出scrapy的基本框架：</p>
<h2 id="Scrapy-框架"><a href="#Scrapy-框架" class="headerlink" title="Scrapy 框架"></a>Scrapy 框架</h2><center>
        <img src="/2022/04/21/Scrapy/structure.jpg" width="80%">
</center> 

<h2 id="Scrapy组件"><a href="#Scrapy组件" class="headerlink" title="Scrapy组件"></a>Scrapy组件</h2><p><strong>Scrapy Engine(引擎)</strong>: 负责Spider、ItemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等。</p>
<p><strong>Scheduler(调度器)</strong>: 它负责接受引擎发送过来的Request请求，并按照一定的方式进行整理排列，入队，当引擎需要时，交还给引擎。</p>
<p><strong>Downloader（下载器）</strong>：负责下载Scrapy Engine(引擎)发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine(引擎)，由引擎交给Spider来处理，</p>
<p><strong>Spider（爬虫）</strong>：它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler(调度器)，</p>
<p>**Item Pipeline(管道)**：它负责处理Spider中获取到的Item，并进行进行后期处理（详细分析、过滤、存储等）的地方.</p>
<p><strong>Downloader Middlewares（下载中间件）</strong>：你可以当作是一个可以自定义扩展下载功能的组件。</p>
<p><strong>Spider Middlewares（Spider中间件）</strong>：你可以理解为是一个可以自定扩展和操作引擎和Spider中间通信的功能组件（比如进入Spider的Responses;和从Spider出去的Requests）</p>
<h2 id="Scrapy-流程"><a href="#Scrapy-流程" class="headerlink" title="Scrapy  流程"></a>Scrapy  流程</h2><p>（1）引擎向Spider请求第一个要爬取的URL(s)。</p>
<p>（2）引擎从Spider中获取到第一个要爬取的URL，封装成Request并交给调度器。</p>
<p>（3）引擎向调度器请求下一个要爬取的Request。</p>
<p>（4）调度器返回下一个要爬取的Request给引擎，引擎将Request通过下载中间件转发给下载器。</p>
<p>（5）一旦页面下载完毕，下载器生成一个该页面的Response，并将其通过下载中间件发送给引擎。</p>
<p>（6）引擎从下载器中接收到Response并通过Spider中间件发送给Spider处理。</p>
<p>（7）Spider处理Response并返回爬取到的Item及新的Request给引擎。</p>
<p>（8）引擎将爬取到的Item给Item Pipeline，将Request给调度器。</p>
<p>（9）从（2）开始重复，直到调度器中没有更多的Request。</p>
<h1 id="构建scrapy项目"><a href="#构建scrapy项目" class="headerlink" title="构建scrapy项目"></a>构建scrapy项目</h1><h2 id="scrapy-安装"><a href="#scrapy-安装" class="headerlink" title="scrapy 安装"></a>scrapy 安装</h2><p>能够直接参考<a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/intro/install.html">官方安装文档</a>，不多追叙，需要掌握一下pyenv与pyenv-virtualenv，构建python的虚拟环境。</p>
<h2 id="构建scrapy项目-1"><a href="#构建scrapy项目-1" class="headerlink" title="构建scrapy项目"></a>构建scrapy项目</h2><p>创建一个新的Scrapy项目。 进入您打算存储代码的目录中，运行下列命令:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scrapy startproject tutorial</span><br></pre></td></tr></table></figure>
<p>该命令将会创建包含下列内容的 tutorial 目录:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tutorial/</span><br><span class="line">    scrapy.cfg</span><br><span class="line">    tutorial/</span><br><span class="line">        __init__.py</span><br><span class="line">        items.py</span><br><span class="line">        pipelines.py</span><br><span class="line">        settings.py</span><br><span class="line">        spiders/</span><br><span class="line">            __init__.py</span><br><span class="line">            ...</span><br></pre></td></tr></table></figure>

<p>这些文件分别是:</p>
<ul>
<li>scrapy.cfg: 项目的配置文件</li>
<li>tutorial&#x2F;: 该项目的python模块。之后您将在此加入代码。</li>
<li>tutorial&#x2F;items.py: 项目中的item文件.</li>
<li>tutorial&#x2F;pipelines.py: 项目中的pipelines文件.</li>
<li>tutorial&#x2F;settings.py: 项目的设置文件.</li>
<li>tutorial&#x2F;spiders&#x2F;: 放置spider代码的目录.<br>只需要基于概况进行开发即可。</li>
</ul>
<h2 id="构建Iterm"><a href="#构建Iterm" class="headerlink" title="构建Iterm"></a>构建Iterm</h2><p>Item 是保存爬取到的数据的容器；其使用方法和python字典类似， 并且提供了额外保护机制来避免拼写错误导致的未定义字段错误。</p>
<p>打开tutorial&#x2F;items.py文件，创建一个 scrapy.Item 类， 并且定义类型为 scrapy.Field 的类属性来定义一个Item。</p>
<p>首先根据需要从”dmo.org（爬取的网页）”获取到的数据对item进行建模，我们需要从dmoz中获取名字，url，以及网站的描述。 对此，在item中定义相应的字段。编辑 tutorial 目录中的tutorial&#x2F;items.py 文件:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DmozItem</span>(scrapy.Item):</span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    link = scrapy.Field()</span><br><span class="line">    desc = scrapy.Field()</span><br></pre></td></tr></table></figure>

<h2 id="编写spider"><a href="#编写spider" class="headerlink" title="编写spider"></a>编写spider</h2><p>Spider是用户编写用于从单个网站(或者一些网站)爬取数据的类。</p>
<p>其包含了一个用于下载的初始URL，如何跟进网页中的链接以及如何分析页面中的内容， 提取生成 item 的方法。</p>
<p>为了创建一个Spider，您必须继承 scrapy.Spider 类， 且定义以下三个属性:</p>
<ul>
<li><p>name: 用于区别Spider。 <strong>该名字必须是唯一的</strong>，您不可以为不同的Spider设定相同的名字。</p>
</li>
<li><p>start_urls: 包含了Spider在启动时进行爬取的url列表。 因此，第一个被获取到的页面将是其中之一。 <strong>后续的URL则从初始的URL获取到的数据中提取</strong>。</p>
</li>
<li><p>parse() 是spider的一个方法。 被调用时，每个初始URL完成下载后生成的 Response 对象将会作为<strong>唯一的参数</strong>传递给该函数。 该方法负责解析返回的数据(response data)，<strong>提取数据(生成item)<strong>以及</strong>生成需要进一步处理的URL的 Request 对象</strong>。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># sample code</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DmozSpider</span>(scrapy.Spider):</span><br><span class="line">    <span class="comment"># unique spider name</span></span><br><span class="line">    name = <span class="string">&quot;dmoz&quot;</span></span><br><span class="line">    <span class="comment"># 允许的网页路径为dmoz.org域名下</span></span><br><span class="line">    allowed_domains = [<span class="string">&quot;dmoz.org&quot;</span>]</span><br><span class="line">    <span class="comment"># start urls</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">&quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&quot;</span>,</span><br><span class="line">        <span class="string">&quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/&quot;</span></span><br><span class="line">    ]</span><br><span class="line">    <span class="comment"># 解析返回的reponse吗，生成item，进一步生成request</span></span><br><span class="line">    <span class="comment"># 此处代码没有显示相关功能</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        filename = response.url.split(<span class="string">&quot;/&quot;</span>)[-<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br></pre></td></tr></table></figure>
<h2 id="爬取内容"><a href="#爬取内容" class="headerlink" title="爬取内容"></a>爬取内容</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scrapy crawl dmoz</span><br><span class="line"><span class="comment"># 在我的mac上需要制定python</span></span><br><span class="line">python -m scrapy crawl dmoz</span><br></pre></td></tr></table></figure>

<h2 id="提取Item"><a href="#提取Item" class="headerlink" title="提取Item"></a>提取Item</h2><p><strong>1. Selectors 选择器介绍</strong></p>
<p>从网页中提取数据有很多方法。Scrapy使用了一种基于 XPath 和 CSS 表达式机制: Scrapy Selectors 。 关于selector和其他提取机制的信息请参考 Selector文档 。<em>后期可以写一下相关的博客，深入研究一下。</em></p>
<p>Selector有四个基本的方法(点击相应的方法</p>
<ul>
<li>xpath(): 传入xpath表达式，返回该表达式所对应的所有节点的<strong>selector list列表</strong> 。</li>
<li>css(): 传入CSS表达式，返回该表达式所对应的所有节点的selector list列表.</li>
<li>extract(): 序列化该节点为unicode字符串并返回<strong>list</strong>。</li>
<li>re(): 根据传入的正则表达式对数据进行提取，返回unicode字符串list列表</li>
</ul>
<p>每个 .xpath() 调用返回selector组成的list，因此我们可以拼接更多的 .xpath() 来进一步获取某个节点</p>
<h2 id="保存数据"><a href="#保存数据" class="headerlink" title="保存数据"></a>保存数据</h2><p>Item 对象是自定义的python字典。 您可以使用标准的字典语法来获取到其每个字段的值。(字段即是我们之前用Field赋值的属性):</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tutorial.items <span class="keyword">import</span> DmozItem</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DmozSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&quot;dmoz&quot;</span></span><br><span class="line">    allowed_domains = [<span class="string">&quot;dmoz.org&quot;</span>]</span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">&quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&quot;</span>,</span><br><span class="line">        <span class="string">&quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/&quot;</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="keyword">for</span> sel <span class="keyword">in</span> response.xpath(<span class="string">&#x27;//ul/li&#x27;</span>):</span><br><span class="line">            item = DmozItem()</span><br><span class="line">            item[<span class="string">&#x27;title&#x27;</span>] = sel.xpath(<span class="string">&#x27;a/text()&#x27;</span>).extract()</span><br><span class="line">            item[<span class="string">&#x27;link&#x27;</span>] = sel.xpath(<span class="string">&#x27;a/@href&#x27;</span>).extract()</span><br><span class="line">            item[<span class="string">&#x27;desc&#x27;</span>] = sel.xpath(<span class="string">&#x27;text()&#x27;</span>).extract()</span><br><span class="line">            <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>

<p>调用结果：</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">[dmoz] <span class="keyword">DEBUG</span>: Scraped <span class="keyword">from</span> &lt;<span class="number">200</span> http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&gt;</span><br><span class="line">     &#123;<span class="string">&#x27;desc&#x27;</span>: [u<span class="string">&#x27; - By David Mertz; Addison Wesley. Book in progress, full text, ASCII format. Asks for feedback. [author website, Gnosis Software, Inc.\n],</span></span><br><span class="line"><span class="string">      &#x27;</span>link<span class="string">&#x27;: [u&#x27;</span>http://gnosis.cx/TPiP/<span class="string">&#x27;],</span></span><br><span class="line"><span class="string">      &#x27;</span>titl<span class="string">e&#x27;: [u&#x27;</span><span class="type">Text</span> Processing <span class="keyword">in</span> Python<span class="string">&#x27;]&#125;</span></span><br><span class="line"><span class="string">[dmoz] DEBUG: Scraped from &lt;200 http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&gt;</span></span><br><span class="line"><span class="string">     &#123;&#x27;</span><span class="keyword">desc</span><span class="string">&#x27;: [u&#x27;</span> - <span class="keyword">By</span> Sean McGrath; Prentice Hall PTR, <span class="number">2000</span>, ISBN <span class="number">0130211192</span>, has CD-ROM. Methods <span class="keyword">to</span> build <span class="type">XML</span> applications fast, Python tutorial, DOM <span class="keyword">and</span> SAX, <span class="built_in">new</span> Pyxie <span class="keyword">open</span> source <span class="type">XML</span> processing library. [Prentice Hall PTR]\n<span class="string">&#x27;],</span></span><br><span class="line"><span class="string">      &#x27;</span>link<span class="string">&#x27;: [u&#x27;</span>http://www.informit.com/store/product.aspx?isbn=<span class="number">0130211192</span><span class="string">&#x27;],</span></span><br><span class="line"><span class="string">      &#x27;</span>titl<span class="string">e&#x27;: [u&#x27;</span><span class="type">XML</span> Processing <span class="keyword">with</span> Python<span class="string">&#x27;]&#125;</span></span><br></pre></td></tr></table></figure>
<p>该命令将采用 JSON 格式对爬取的数据进行序列化，生成 items.json 文件。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scrapy crawl dmoz -o items.json</span><br></pre></td></tr></table></figure>
<h1 id="Scrapy-Shell"><a href="#Scrapy-Shell" class="headerlink" title="Scrapy Shell"></a>Scrapy Shell</h1><p>前文可知，spider将爬取的结果储存在item中，返回reponse。通过调用scrapy shell，能够实现对其的交互。</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line">scrapy <span class="keyword">shell</span><span class="language-bash"> <span class="string">&#x27;example.com&#x27;</span></span></span><br></pre></td></tr></table></figure>
<p>其中可以利用xpath，css进行数据的抽取，后期有机会可以写相关的文章，深入了解一下。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://book.itheima.net/course/221/1270308787172941826/1271354340677787651">Scrapy框架的运作流程</a></li>
<li><a href="https://segmentfault.com/a/1190000013178839">Scrapy框架简介</a></li>
<li><a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/intro/overview.html">Scrapy官方文档</a></li>
</ol>
]]></content>
      <categories>
        <category>Big Data</category>
      </categories>
      <tags>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title>Sql-Fragments</title>
    <url>/2022/04/11/Sql-Fragments/</url>
    <content><![CDATA[<p>This article is used for recording some study fragments in mysql.</p>
<center>
        <img src="/2022/04/11/Sql-Fragments/sf-logo.png" width="60%">
</center>

<span id="more"></span>

<h1 id="如何阅读长sql"><a href="#如何阅读长sql" class="headerlink" title="如何阅读长sql"></a>如何阅读长sql</h1><p><a href="https://cloud.tencent.com/developer/article/1559983">提升阅读sql的快感</a></p>
<ul>
<li>通读，非技术性的通读</li>
<li>需要联想，也就是想象力</li>
<li>批评</li>
</ul>
<ol>
<li>目前我用的是vscode来阅读sql代码。首先我会尝试用beautify sql这个vscode插件来美化sql代码，分出层级。</li>
<li>select – from – where 基本的sql逻辑，由外向内拆分，理解各层逻辑。给自己找问题，千万别一遍看完代码，什么都没留下来。</li>
<li>理解sql的业务逻辑，你也可以在手边，画画流程图，帮助记忆。</li>
</ol>
<blockquote>
<p>“在我们编程这个圈子，也有很多书，专讲这方面的。我给你推荐几本吧，《编程珠玑》，《CLR Via C#》, 尤其是 SQL 数据库方面，《数据库索引设计与优化》，《Oracle 优化日记》，《T-SQL Querying》,《T-SQL 性能调优秘籍-基于SQL Server 2012 窗口函数》”</p>
</blockquote>
<h1 id="阅读长sql时的整体感"><a href="#阅读长sql时的整体感" class="headerlink" title="阅读长sql时的整体感"></a>阅读长sql时的整体感</h1><p>经常会遇到一些比较长，且层级结果比较多的sql语句，在阅读的过程中，时常会发生读到一半忘掉前面的代码逻辑的情况。在阅读sql语句的时候，需要保持整体感。整体感的保持。</p>
<ul>
<li>首先需要了解sql的输入与输出，明白这个sql的主要目的是什么。</li>
<li>其次，需要逐层拆分，理解层级表。要理解同一层的各个select -from-where检索出来的表，因为是同一层吗，在逻辑上是并列的，比较好理解。</li>
<li>最后，在对sql基本脉络了解之后，再根据需要去阅读代码，而非阅读所有代码。</li>
</ul>
<p>如果以学习为目的，则能适当阅读所有代码。</p>
<h1 id="coalesce"><a href="#coalesce" class="headerlink" title="coalesce()"></a>coalesce()</h1><p>The COALESCE() function returns the first non-null value in a list.<br>返回列表中第一个非空元素</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># The <span class="built_in">COALESCE</span>() <span class="keyword">function</span> <span class="keyword">returns</span> the <span class="keyword">first</span> non<span class="operator">-</span><span class="keyword">null</span> <span class="keyword">value</span> <span class="keyword">in</span> a list.</span><br><span class="line"><span class="built_in">COALESCE</span>(val1, val2, ...., val_n)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="unnest"><a href="#unnest" class="headerlink" title="unnest"></a>unnest</h1><p>The UNNEST function takes an ARRAY and returns a table with a row for each element in the ARRAY.</p>
<p>unnest函数输入一个array数组，返回array数组中每一个元素作为行的表。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># Syntax: <span class="built_in">UNNEST</span>(<span class="keyword">ARRAY</span>) [<span class="keyword">WITH</span> <span class="keyword">OFFSET</span>]</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">  <span class="built_in">UNNEST</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="keyword">NULL</span>]) <span class="keyword">AS</span> unnest_column</span><br><span class="line"></span><br><span class="line"># <span class="keyword">Result</span></span><br><span class="line"># <span class="number">1</span></span><br><span class="line"># <span class="number">2</span></span><br><span class="line"># <span class="number">2</span></span><br><span class="line"># <span class="number">5</span></span><br><span class="line"># <span class="keyword">null</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 其中还有一个<span class="keyword">offset</span>选项，为每一行提供了一个附加列，其中包含数组中每个元素的位置（从零开始）</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">  <span class="built_in">UNNEST</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="keyword">NULL</span>]) <span class="keyword">AS</span> unnest_column <span class="keyword">WITH</span> <span class="keyword">OFFSET</span> <span class="keyword">AS</span> `<span class="keyword">offset</span>`</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="cast"><a href="#cast" class="headerlink" title="cast"></a>cast</h1><p>CAST函数用于将某种数据类型的表达式显式转换为另一种数据类型。CAST()函数的参数是一个表达式，它包括用AS关键字分隔的源值和目标数据类型。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># Syntax: <span class="built_in">CAST</span> (expression <span class="keyword">AS</span> data_type)</span><br><span class="line"># expression：任何有效的SQServer表达式。</span><br><span class="line"># <span class="keyword">AS</span>：用于分隔两个参数，在<span class="keyword">AS</span>之前的是要处理的数据，在<span class="keyword">AS</span>之后是要转换的数据类型。</span><br><span class="line"># data_type：目标系统所提供的数据类型，包括<span class="type">bigint</span>和sql_variant，不能使用用户定义的数据类型。</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">CAST</span>(<span class="string">&#x27;9.0&#x27;</span> <span class="keyword">AS</span> <span class="type">decimal</span>)  # 结果：<span class="number">9</span></span><br></pre></td></tr></table></figure>

<h1 id="interval"><a href="#interval" class="headerlink" title="interval"></a>interval</h1><p>MySQL 间隔值(interval)主要用于日期和时间计算,创建间隔值。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># <span class="type">INTERVAL</span> keyword <span class="keyword">is</span> the expr that determines the <span class="type">interval</span> <span class="keyword">value</span>, <span class="keyword">and</span> unit that specifies the <span class="type">interval</span> unit</span><br><span class="line"># <span class="type">INTERVAL</span> expr unit</span><br><span class="line"><span class="type">INTERVAL</span> <span class="number">1</span> <span class="keyword">DAY</span></span><br><span class="line"></span><br><span class="line"># We mainly use <span class="type">interval</span> <span class="keyword">values</span> <span class="keyword">for</span> <span class="type">date</span> <span class="keyword">and</span> <span class="type">time</span> arithmetic <span class="keyword">as</span> shown below</span><br><span class="line"><span class="type">date</span> <span class="operator">+</span> <span class="type">INTERVAL</span> expr unit</span><br><span class="line"><span class="type">date</span> <span class="operator">-</span> <span class="type">INTERVAL</span> expr unit</span><br></pre></td></tr></table></figure>
<h1 id="DATE-SUB"><a href="#DATE-SUB" class="headerlink" title="DATE_SUB()"></a>DATE_SUB()</h1><p>DATE_SUB() 函数从日期减去指定的时间间隔。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># <span class="type">date</span> 参数是合法的日期表达式。expr 参数是您希望添加的时间间隔。</span><br><span class="line">DATE_SUB(<span class="type">date</span>,<span class="type">INTERVAL</span> expr type)</span><br></pre></td></tr></table></figure>

<h1 id="IFNULL"><a href="#IFNULL" class="headerlink" title="IFNULL()"></a>IFNULL()</h1><p>IFNULL() 函数用于判断第一个表达式是否为 NULL，如果为 NULL 则返回第二个参数的值，如果不为 NULL 则返回第一个参数的值。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 如果第一个参数的表达式 expression 为 <span class="keyword">NULL</span>，则返回第二个参数的备用值。</span><br><span class="line">IFNULL(expression, alt_value)</span><br></pre></td></tr></table></figure>

<h1 id="union-all"><a href="#union-all" class="headerlink" title="union all"></a>union all</h1><p>UNION 操作符用于连接两个以上的 SELECT 语句的结果组合到一个结果集合中。多个 SELECT 语句会删除重复的数据。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># expression1, expression2, ... expression_n: 要检索的列。</span><br><span class="line"># tables: 要检索的数据表</span><br><span class="line"># <span class="keyword">WHERE</span> conditions: 可选， 检索条件。</span><br><span class="line"># <span class="keyword">DISTINCT</span>: 可选，删除结果集中重复的数据。默认情况下 <span class="keyword">UNION</span> 操作符已经删除了重复数据，所以 <span class="keyword">DISTINCT</span> 修饰符对结果没啥影响。</span><br><span class="line"># <span class="keyword">ALL</span>: 可选，返回所有结果集，包含重复数据。</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> expression1, expression2, ... expression_n</span><br><span class="line"><span class="keyword">FROM</span> tables</span><br><span class="line">[<span class="keyword">WHERE</span> conditions]</span><br><span class="line"><span class="keyword">UNION</span> [<span class="keyword">ALL</span> <span class="operator">|</span> <span class="keyword">DISTINCT</span>]</span><br><span class="line"><span class="keyword">SELECT</span> expression1, expression2, ... expression_n</span><br><span class="line"><span class="keyword">FROM</span> tables</span><br><span class="line">[<span class="keyword">WHERE</span> conditions];</span><br></pre></td></tr></table></figure>
<p> <a href="https://www.runoob.com/mysql/mysql-union-operation.html">union all样例</a></p>
<h1 id="acid"><a href="#acid" class="headerlink" title="acid"></a>acid</h1>]]></content>
      <tags>
        <tag>Sql</tag>
      </tags>
  </entry>
  <entry>
    <title>Yarn</title>
    <url>/2022/04/08/Yarn/</url>
    <content><![CDATA[<p>YARN is an open source Apache project that stands for “Yet Another Resource Negotiator”. It is a Hadoop cluster manager that is responsible for allocating resources (such as cpu, memory, disk and network), for scheduling &amp; monitoring jobs across the Hadoop cluster.</p>
<p>YARN是Apache的一个开源项目，它的意思是“另一个资源协商者”。它是一个Hadoop集群管理器，负责分配资源(如cpu、内存、磁盘和网络)，用于跨Hadoop集群调度和监控作业。</p>
<center>
        <img src="/2022/04/08/Yarn/yarn_logo.png" , width="80%">
</center>
<span id="more"></span>

<h1 id="What-is-yarn"><a href="#What-is-yarn" class="headerlink" title="What is yarn"></a>What is yarn</h1><p>YARN是Apache的一个开源项目，它的意思是“另一个资源协商者”。它是一个Hadoop集群管理器，负责分配资源(如cpu、内存、磁盘和网络)，用于跨Hadoop集群调度和监控作业。</p>
<p>早期版本的Hadoop只支持在Hadoop集群上运行MapReduce任务;然而，YARN的出现也使得在Hadoop集群上运行其他大数据解决方案框架成为可能，比如Spark、Flink、Samza等。</p>
<p>YARN支持不同类型的工作负载，如流处理、批处理、图形处理和迭代处理。</p>
<h1 id="Yarn’s-Architecture"><a href="#Yarn’s-Architecture" class="headerlink" title="Yarn’s Architecture"></a>Yarn’s Architecture</h1><p>Apache YARN由两个主要组件组成:资源管理器和节点管理器。资源管理器每个集群一个，而节点管理器守护进程运行在所有工作节点上。</p>
<center>
        <img src="/2022/04/08/Yarn/yarn_architecture.jpg" , width="80%,">
</center>

<ol>
<li><p>资源管理器(Resource Manager)是一个守护进程，负责在集群中分配资源。它有两个主要组件，即<strong>调度程序和应用程序管理器</strong>。调度器负责根据内存和cpu需求跨集群调度应用程序。每个集群只有一个资源管理器。</p>
</li>
<li><p>应用程序管理器(APP Manager)接受作业并创建特定的应用程序主程序，并在出现故障时重新启动它们。<strong>Application Master负责处理Application的整个生命周期</strong>，从资源协商、跟踪和监控作业状态开始。</p>
</li>
<li><p>节点管理器(Node Manager)是运行在所有工作节点上的守护进程，在<strong>机器级别管理资源</strong>。节点管理器定义节点上可用的资源，并跟踪其使用情况。它还跟踪节点的运行状况，如果<strong>发现不正常，则将其通信给资源管理器</strong>。Node Manager与资源管理器通信，发送关于报告使用情况的定期报告，并与应用程序主机协调生成用于任务执行的JVM。</p>
</li>
</ol>
<h1 id="Yarn-Scheduler"><a href="#Yarn-Scheduler" class="headerlink" title="Yarn Scheduler"></a>Yarn Scheduler</h1><p>YARN 支持三种调度策略，即 FIFO、Capacity 和 Fair Scheduling，它们决定了传入作业的调度或优先级。</p>
<h2 id="FIFO-Scheduler"><a href="#FIFO-Scheduler" class="headerlink" title="FIFO Scheduler"></a>FIFO Scheduler</h2><p>在 FIFO 调度器策略中，应用程序以“先进先出”的方式提供服务，但如果集群在多个用户之间共享，此策略可能会导致作业匮乏。所以，这个策略在共享集群中并不是最优的。默认情况下，YARN 始终设置为 FIFO 策略。</p>
<h2 id="Capacity-Scheduler"><a href="#Capacity-Scheduler" class="headerlink" title="Capacity Scheduler:"></a>Capacity Scheduler:</h2><p>在容量调度程序中，不同的组织共享他们的 Hadoop 集群以最大限度地利用集群。尽管组织正在共享他们的集群，但容量调度程序可确保每个组织都获得所需的容量。</p>
<p>容量调度器(Capacity Scheduler)提供容量保证、弹性、基于资源的调度、优先级调度、多租户等等。我们必须在 conf&#x2F;yarn-site.xml 文件中设置以下属性以在 YARN 中启用容量调度程序。</p>
<h2 id="Fair-Scheduler"><a href="#Fair-Scheduler" class="headerlink" title="Fair Scheduler:"></a>Fair Scheduler:</h2><p>公平调度策略(Fair Scheduler)确保所有正在运行的作业获得大致相等的资源份额（内存或 CPU）。</p>
<p>作业被划分为队列，资源在这些队列之间平均共享。它始终保证队列的最小份额，如果队列为空，则将多余的资源分配给在其他队列中运行的作业。我们还可以定义一组应用于提交的应用程序的规则，以便应用程序进入适当的队列以进行进一步处理.</p>
<h1 id="High-Availability"><a href="#High-Availability" class="headerlink" title="High Availability"></a>High Availability</h1><p>在 Hadoop 2.4 之后，资源管理器以 Active&#x2F;StandBy 模式工作，以提供容错和高可用性。</p>
<p>Standby Resource Manager始终跟踪活动资源管理器中发生的所有更改，并可以在出现故障时替换其位置。资源管理器与zookeeper密切合作，记录其状态，并决定在出现故障时哪个资源管理器应该处于活动状态。</p>
<center>
        <img src="/2022/04/08/Yarn/active_standby.png" , width="80%">
</center>

<p>故障转移从active mode 到 standby mode 可以手动进行，也可以自动进行。</p>
<h2 id="手动转换与failover"><a href="#手动转换与failover" class="headerlink" title="手动转换与failover"></a>手动转换与failover</h2><p>当自动 <em>failover</em> 没有开启时，管理员需要手动将RM的状态转为Active。为了完成failover，首先需要将Active-RM 转换为Standby，然后将Standby-RM 转换为Active。这些均可以通过 <em>yarn rmadmin</em> 命令完成。</p>
<h2 id="自动failover"><a href="#自动failover" class="headerlink" title="自动failover"></a>自动failover</h2><p>RMs可以配置一个内置的，基于 Zookeeper 的ActiveStandbyElector，用于决定哪个RM应该是Active的。当Active RM 出现故障下线，或者无法响应了，另一个RM会被自动推选为Active，并接管之后的工作。需要注意的是，这里没有必要像 HDFS HA 那样运行一个额外的ZKFC守护进程，因为ActiveStandbyElector 内置于RM，担任failure detector以及leader elector的角色，可以替代ZKFC守护进程</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="aegissofttech.com/articles/what-is-yarn-in-big-data.html">1. What is YARN? How Does it Work and Support Big Data Framework?</a></p>
<p><a href="https://www.cnblogs.com/zackstang/p/10812523.html">2. YARN High Availablity</a></p>
<p><a href="https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html">3. Apache Hadoop YARN</a></p>
]]></content>
      <categories>
        <category>Big Data</category>
      </categories>
      <tags>
        <tag>yarn</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper Basic</title>
    <url>/2022/04/10/Zookeeper-Basic/</url>
    <content><![CDATA[<p>ZooKeeper是一个分布式、开源的分布式应用协调服务。它公开了一组简单的原语，分布式应用程序可以在此基础上构建，以实现同步、配置维护、组和命名等更高级别的服务。它的设计是易于编程的，并使用了一个数据模型，其样式类似于熟悉的文件系统的目录树结构。它在Java中运行，并且有Java和C的绑定。</p>
<p>众所周知，协调服务很难做好。它们特别容易出现竞争条件和死锁等错误。ZooKeeper背后的动机是为了减轻分布式应用从头开始实现协调服务的责任。</p>
<center>
        <img src="/2022/04/10/Zookeeper-Basic/Apache_ZooKeeper_logo.svg.png" width="80%">
</center>

<span id="more"></span>

<h1 id="What-is-zookeeper"><a href="#What-is-zookeeper" class="headerlink" title="What is zookeeper"></a>What is zookeeper</h1><p>ZooKeeper是一个分布式、开源的分布式<strong>应用协调服务</strong>。它公开了<strong>一组简单的原语</strong>，分布式应用程序可以在此基础上构建，以实现同步、配置维护、组和命名等更高级别的服务。它的设计是易于编程的，并使用了一个数据模型，其样式类似于熟悉的文件系统的目录树结构。它在Java中运行，并且有Java和C的绑定。</p>
<p>众所周知，协调服务很难做好。它们特别容易出现竞争条件和死锁等错误。ZooKeeper背后的动机是为了<strong>减轻分布式应用从头开始实现协调服务的责任</strong>。</p>
<h1 id="What-is-zookeeper’s-goals"><a href="#What-is-zookeeper’s-goals" class="headerlink" title="What is zookeeper’s goals?"></a>What is zookeeper’s goals?</h1><h2 id="zookeeper-结构简单"><a href="#zookeeper-结构简单" class="headerlink" title="zookeeper 结构简单"></a>zookeeper 结构简单</h2><p>ZooKeeper允许分布式进程通过一个<strong>共享的层次命名空间相互协调</strong>，这个命名空间的组织方式<strong>类似于标准的文件系统</strong>。命名空间由数据寄存器组成——用ZooKeeper的话说叫做znode——它们类似于文件和目录。与典型的存储文件系统不同，<strong>ZooKeeper的数据保存在内存中</strong>，这意味着ZooKeeper可以实现<strong>高吞吐量和低时延</strong>。</p>
<h2 id="zookeeper-是被复制的"><a href="#zookeeper-是被复制的" class="headerlink" title="zookeeper 是被复制的"></a>zookeeper 是被复制的</h2><center>
                <img src="/2022/04/10/Zookeeper-Basic/zookeeper_structure.jpg" width="80%">
</center>

<p>组成zookeeper的服务器都认识彼此，它们在内存中维护状态图像，以及持久存储中的事务日志和快照。只要大多数服务器可用，ZooKeeper 服务就可用。</p>
<p>**”2n+1原则”**：集群中运行的机器需要超过一半</p>
<ul>
<li>“2n+1”的原因是zookeeper应用需要可靠性&#x2F;可用性，与性能无关</li>
<li>ZooKeeper集合(服务集群)是由一个或多个服务器组成的，这些服务器对每个更改进行“投票”。大多数原始服务器在接受任何更改之前都需要“批准”。</li>
<li>集成中有 3 台服务器（n&#x3D;1），如果其中一台出现故障，服务仍然正常（2 台占多数）。但是，如果第二台服务器发生故障，则服务将关闭。</li>
</ul>
<h2 id="zookeeper是有序的"><a href="#zookeeper是有序的" class="headerlink" title="zookeeper是有序的"></a>zookeeper是有序的</h2><p>ZooKeeper 使用反映所有 ZooKeeper 事务顺序的数字标记每个更新。后续操作可以使用顺序来实现更高级别的抽象，例如同步原语。</p>
<h2 id="zookeeper很迅速"><a href="#zookeeper很迅速" class="headerlink" title="zookeeper很迅速"></a>zookeeper很迅速</h2><p>它在“以读取为主”的工作负载中尤其快。 ZooKeeper 应用程序在数千台机器上运行，它在读取比写入更常见的情况下表现最佳，比率约为 10:1。</p>
<h1 id="数据模型与命名空间"><a href="#数据模型与命名空间" class="headerlink" title="数据模型与命名空间"></a>数据模型与命名空间</h1><p>ZooKeeper 提供的命名空间很像标准文件系统。名称是由斜杠 (&#x2F;) 分隔的一系列路径元素。 ZooKeeper 命名空间中的每个节点都由路径标识。</p>
<center>
                <img src="/2022/04/10/Zookeeper-Basic/zookeeper_hn.jpg" width="80%">
</center>

<h2 id="节点与临时节点"><a href="#节点与临时节点" class="headerlink" title="节点与临时节点"></a>节点与临时节点</h2><p>与标准的文件系统不同，ZooKeeper名称空间中的每个节点都可以有与其关联的数据以及子节点。这就像拥有一个允许文件同时也是目录的文件系统。(ZooKeeper是用来<strong>存储协调数据</strong>的:<strong>状态信息、配置信息、位置信息</strong>等，所以每个节点存储的数据通常很小，在字节到千字节之间。)我们使用术语znode来说明我们谈论的是ZooKeeper数据节点。</p>
<p>znode维护一个统计结构，其中包括数据更改的版本号、ACL更改和时间戳，以允许缓存验证和协调更新。znode的数据每次更改，版本号就会增加。例如，每当客户端检索数据时，它也会接收到数据的版本。</p>
<p>存储在名称空间中的每个znode上的数据是原子式读写的。读获取与znode关联的所有数据字节，写则替换所有数据。每个节点都有一个访问控制列表(Access Control List, ACL)来限制谁可以做什么。</p>
<p>ZooKeeper也有临时节点的概念。只要创建znode的会话处于活动状态，这些znode就会存在。当会话结束时，删除znode。</p>
<h1 id="zookeeper特点"><a href="#zookeeper特点" class="headerlink" title="zookeeper特点"></a>zookeeper特点</h1><ul>
<li>顺序一致性</li>
<li>原子性</li>
<li>单一系统映像：无论客户端连接到哪个服务器，客户端都将看到相同的服务视图。即，即使客户端故障转移到具有相同会话的不同服务器，客户端也永远不会看到系统的旧视图。</li>
<li>可靠性</li>
<li>实效性</li>
</ul>
<h1 id="调用接口api"><a href="#调用接口api" class="headerlink" title="调用接口api"></a>调用接口api</h1><ul>
<li>create : creates a node at a location in the tree</li>
<li>delete : deletes a node</li>
<li>exists : tests if a node exists at a location</li>
<li>get data : reads the data from a node</li>
<li>set data : writes data to a node</li>
<li>get children : retrieves a list of children of a node</li>
<li>sync : waits for data to be propagated</li>
</ul>
<h1 id="zookeeper组成"><a href="#zookeeper组成" class="headerlink" title="zookeeper组成"></a>zookeeper组成</h1><p>除了请求处理器(request processor)之外，组成 ZooKeeper 服务的每个服务器都复制自己的每个组件的副本。</p>
<center>
<img src="/2022/04/10/Zookeeper-Basic/zk_component.jpg" width="80%">
</center>

<p>复制数据库是包含整个数据树的内存数据库。更新被记录到磁盘以便恢复，写入在应用到内存数据库之前被序列化到磁盘。</p>
<p>每个 ZooKeeper 服务器都服务于客户端。客户端仅连接到一台服务器以提交请求。<strong>从每个服务器数据库的本地副本为读取请求提供服务</strong>。请求会改变服务状态，其中写请求，由协议协议处理。</p>
<p>作为协议协议的一部分，来自客户端的所有写入请求都被转发到单个服务器，称为领导者（leader）。余下服务器称为跟随者（follower），并接收来自领导者的消息提议并同意消息传递。</p>
<h1 id="表现"><a href="#表现" class="headerlink" title="表现"></a>表现</h1><p>zookeeper在读超过写的时候，性能较高，因为写涉及到同步所有服务器的状态。</p>
<center>
                <img src="/2022/04/10/Zookeeper-Basic/zk_performance.jpg" width="80%">
</center>

<h1 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h1><blockquote>
<p>为了显示系统在注入故障时的行为，我们运行了一个由 7 台机器组成的 ZooKeeper 服务。我们运行与之前相同的饱和度基准测试，但这次我们将写入百分比保持在恒定的 30%，这是我们预期工作负载的保守比率。</p>
</blockquote>
<center>
                <img src="/2022/04/10/Zookeeper-Basic/zk_reliability.jpg" width="80%">
</center>

<p>图像中存在几个重要的观察特点：</p>
<ol>
<li><p>如果追随者失败并迅速恢复，那么即使失败，ZooKeeper 也能够维持高吞吐量。</p>
</li>
<li><p>领导者选举算法允许系统以足够快的速度恢复，以防止吞吐量大幅下降。ZooKeeper 用不到 200 毫秒的时间来选举一个新的领导者。</p>
</li>
<li><p>随着追随者的恢复，ZooKeeper 能够在他们开始处理请求后再次提高吞吐量。</p>
</li>
</ol>
<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="https://zookeeper.apache.org/doc/r3.4.14/zookeeperOver.html">1. zookeeper 概述</a></p>
<p><a href="https://stackoverflow.com/questions/4228227/what-does-2n-1-quorum-mean">2. zookeeper 2n+1 原理</a></p>
]]></content>
      <categories>
        <category>Big Data</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>crontab</title>
    <url>/2022/05/02/crontab/</url>
    <content><![CDATA[<p>Linux下的任务调度分为两类：系统任务调度和用户任务调度。Linux系统任务是由 cron (crond) 这个系统服务来控制的，这个系统服务是默认启动的。用户自己设置的计划任务则使用crontab 命令，可以实现某一任务在指定的时间运行。</p>
<span id="more"></span>

<p>Linux下的任务调度分为两类：系统任务调度和用户任务调度。Linux系统任务是由 cron (crond) 这个系统服务来控制的，这个系统服务是默认启动的。用户自己设置的计划任务则使用crontab 命令。</p>
<h1 id="crontab配置文件"><a href="#crontab配置文件" class="headerlink" title="crontab配置文件"></a>crontab配置文件</h1><p>在centos系统中，通过调用</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看配置指令</span></span><br><span class="line">cat /etc/crontab</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">能够看到如下解释</span></span><br><span class="line">SHELL=/bin/bash</span><br><span class="line">PATH=/sbin:/bin:/usr/sbin:/usr/bin</span><br><span class="line">MAILTO=root</span><br><span class="line">HOME=/</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">For details see man 4 crontabs</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Example of job definition:</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">.---------------- minute (0 - 59)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">| .------------- hour (0 - 23)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">| | .---------- day of month (1 - 31)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">| | | .------- month (1 - 12) OR jan,feb,mar,apr ...</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">| | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">| | | | |</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">* * * * * user-name <span class="built_in">command</span> to be executed</span></span><br></pre></td></tr></table></figure>

<h1 id="crontab文件含义"><a href="#crontab文件含义" class="headerlink" title="crontab文件含义"></a>crontab文件含义</h1><p>前四行是用来配置crond任务运行的环境变量</p>
<ol>
<li><p>第一行SHELL变量指定了系统要使用哪个shell，这里是bash；</p>
</li>
<li><p>第二行PATH变量指定了系统执行命令的路径；</p>
</li>
<li><p>第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务执行信息给用户；</p>
</li>
<li><p>第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。</p>
</li>
</ol>
<center>
    <img src="/2022/05/02/crontab/crontab.png" , width="80%">
</center>

<p>在以上各个字段中，还可以使用以下特殊字符：</p>
<p>“*“代表所有的取值范围内的数字，如月份字段为*，则表示1到12个月；</p>
<p>“&#x2F;“代表每一定时间间隔的意思，如分钟字段为*&#x2F;10，表示每10分钟执行1次。</p>
<p>“-“代表从某个区间范围，是闭区间。如“2-5”表示“2,3,4,5”，小时字段中0-23&#x2F;2表示在0~23点范围内每2个小时执行一次。</p>
<p>“,”分散的数字（不一定连续），如1,2,3,4,7,9。</p>
<p>注：由于各个地方每周第一天不一样，因此Sunday&#x3D;0（第一天）或Sunday&#x3D;7（最后1天）。</p>
<h1 id="crontab命令详解"><a href="#crontab命令详解" class="headerlink" title="crontab命令详解"></a>crontab命令详解</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">crontab [-u user] file</span><br><span class="line">crontab [ -u user ] [ -i ] &#123; -e | -l | -r &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>-u user：用于设定某个用户的crontab服务；</li>
<li>file: file为命令文件名，表示将file作为crontab的任务列表文件并载入crontab；</li>
<li>-e：编辑某个用户的crontab文件内容，如不指定用户则表示当前用户；</li>
<li>-l：显示某个用户的crontab文件内容，如不指定用户则表示当前用户；</li>
<li>-r：从&#x2F;var&#x2F;spool&#x2F;cron目录中删除某个用户的crontab文件。</li>
<li>-i：在删除用户的crontab文件时给确认提示。</li>
</ul>
<h1 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h1><ol>
<li><p>crontab有2种编辑方式：直接编辑&#x2F;etc&#x2F;crontab文件与<br>crontab –e，其中&#x2F;etc&#x2F;crontab里的计划任务是系统中的计划任务，而用户的计划任务需要通过crontab –e来编辑；</p>
</li>
<li><p>每次编辑完某个用户的cron设置后，cron自动在&#x2F;var&#x2F;spool&#x2F;cron下生成一个与此用户同名的文件，此用户的cron信息都记录在这个文件中，这个文件是不可以直接编辑的，只可以用crontab -e 来编辑。</p>
</li>
<li><p>crontab中的command尽量使用绝对路径，否则会经常因为路径错误导致任务无法执行。</p>
</li>
<li><p>新创建的cron job不会马上执行，至少要等2分钟才能执行，可从起cron来立即执行。</p>
</li>
<li><p>%在crontab文件中表示“换行”，因此假如脚本或命令含有%,需要使用%来进行转义。</p>
</li>
</ol>
<h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><ol>
<li><a href="https://www.linuxprobe.com/how-to-crontab.html">crontab用法与实例</a></li>
<li><a href="https://man7.org/linux/man-pages/man5/crontab.5.html">crontab(5) — Linux manual page</a></li>
</ol>
]]></content>
      <categories>
        <category>Basic</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>imdb-scrapy</title>
    <url>/2022/04/22/imdb-scrapy/</url>
    <content><![CDATA[<p>在有了一定的scrapy基础之后，便可以尝试将scrapy的知识应用起来，做一些小项目。本文将介绍一个基于scrapy的imdb数据爬取项目，其主要功能有以下三点：</p>
<ul>
<li><p>imdb最受欢迎榜单数据，新片榜单数据爬取</p>
</li>
<li><p>md5文件监视与crontab定时运行</p>
</li>
<li><p>报告邮件形式发送</p>
</li>
</ul>
<p>Github入口： <a href="https://github.com/wjmars98/imdb-scrapy">imdb-scrapy：基于scrapy的imdb数据爬取项目</a></p>
<center>
        <img src="/2022/04/22/imdb-scrapy/logo.jpg" , width="80%">
</center>

<span id="more"></span>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>在实习期间，流媒体部分的同事需要imdb相关的数据，这个任务最后落在了我的身上，正好这个项目与公司项目相对独立，不涉及保密协议的部分，所以我打算将这个项目放在自己的github上，深入自己对scrapy的理解，同时也丰富自己的工程经验。</p>
<p>Github入口： <a href="https://github.com/wjmars98/imdb-scrapy">imdb-scrapy：基于scrapy的imdb数据爬取项目</a></p>
<h1 id="项目需求"><a href="#项目需求" class="headerlink" title="项目需求"></a>项目需求</h1><h2 id="爬取对象"><a href="#爬取对象" class="headerlink" title="爬取对象"></a>爬取对象</h2><p><strong>1. IMDB影片信息获取</strong><br>根据IMDB链接，获取IMDB页面信息供资讯站内容填充，所需信息如下(详见图片)：<br>例子：<a href="https://www.imdb.com/title/tt10048342/">https://www.imdb.com/title/tt10048342/</a></p>
<ul>
<li>ID：10048342</li>
<li>影片标题</li>
<li>IMDB评分</li>
<li>影片热度：popularity，对应图中302</li>
<li>影片描述</li>
<li>影片图片：封面图，尺寸(像素)：198*261，大小：≤50k</li>
<li>影片IMDB ID<br>更新频率：24小时&#x2F;次</li>
</ul>
<center>
        <img src="/2022/04/22/imdb-scrapy/src1.png" , width="80%">
</center>


<p><strong>2. IMDB新片上映信息获取</strong><br>根据IMDB新片上映页面，获取影片信息供资讯站内容筛选参考，所需信息如下(详见图片)：</p>
<ul>
<li>新片上映页面：<a href="https://www.imdb.com/calendar/">https://www.imdb.com/calendar/</a></li>
<li>影片上映时间：包含年月日</li>
<li>影片名称：包含年份</li>
<li>影片热度：点击影片获取影片热度，如图③</li>
<li>影片IMDB ID</li>
<li>影片链接</li>
</ul>
<p>更新频率：24小时&#x2F;次<br>爬取条数：最近两个月的影片</p>
<center>
        <img src="/2022/04/22/imdb-scrapy/src2.png" , width="80%">
</center>

<center>
        <img src="/2022/04/22/imdb-scrapy/src3.png" , width="80%">
</center>


<p><strong>3. IMDB喜爱榜单信息获取</strong><br>根据IMDB喜爱榜单页面，获取影片信息供资讯站内容筛选参考，所需信息如下(详见图片)：<br>新片上映页面：<a href="https://www.imdb.com/chart/moviemeter/?ref_=nv_mv_mpm">https://www.imdb.com/chart/moviemeter/?ref_=nv_mv_mpm</a></p>
<ul>
<li>排名</li>
<li>影片名称：包含年份</li>
<li>IMDB 评分</li>
<li>影片IMDB ID</li>
<li>影片链接</li>
<li>影片热度：点击影片获取影片热度</li>
</ul>
<p>更新频率：24小时&#x2F;次<br>爬取条数：前100条</p>
<center>
        <img src="/2022/04/22/imdb-scrapy/src4.png" , width="80%">
</center>

<h2 id="报告输出格式"><a href="#报告输出格式" class="headerlink" title="报告输出格式"></a>报告输出格式</h2><p>《IMDB新片上映信息获取》、《IMDB喜爱榜单信息获取》以csv格式导出，csv所要字段如表所示：</p>
<center>
                <img src="/2022/04/22/imdb-scrapy/favourite-new.jpg" , width="80%">
</center>
备注：

<p>《IMDB新片上映信息获取》：<a href="https://www.imdb.com/calendar/">https://www.imdb.com/calendar/</a></p>
<p>《IMDB喜爱榜单信息获取》：<a href="https://www.imdb.com/chart/moviemeter/">https://www.imdb.com/chart/moviemeter/</a></p>
<p>《爬取提供imdb-url-list》以csv格式导出，csv所要字段如表所示：</p>
<center>
                <img src="/2022/04/22/imdb-scrapy/imdb-url-list.jpg" , width="80%">
</center>

<h1 id="项目编写"><a href="#项目编写" class="headerlink" title="项目编写"></a>项目编写</h1><h2 id="scrapy框架"><a href="#scrapy框架" class="headerlink" title="scrapy框架"></a>scrapy框架</h2><center>
                <img src="/2022/04/22/imdb-scrapy/structure.png" , width="80%">
</center>


<h2 id="项目文件树"><a href="#项目文件树" class="headerlink" title="项目文件树"></a>项目文件树</h2><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── README<span class="selector-class">.md</span></span><br><span class="line">├── imdbSpider</span><br><span class="line">│   ├── bin</span><br><span class="line">│   │   ├── get_report<span class="selector-class">.py</span></span><br><span class="line">│   │   ├── lib_noti<span class="selector-class">.py</span></span><br><span class="line">│   │   └── spy_list<span class="selector-class">.sh</span></span><br><span class="line">│   ├── conf</span><br><span class="line">│   │   └── list</span><br><span class="line">│   │       ├── imdb-url-list</span><br><span class="line">│   │       └── imdb-url-list<span class="selector-class">.md5</span></span><br><span class="line">│   ├── data</span><br><span class="line">│   │   ├── favourite<span class="selector-class">.csv</span></span><br><span class="line">│   │   ├── list<span class="selector-class">.csv</span></span><br><span class="line">│   │   └── new<span class="selector-class">.csv</span></span><br><span class="line">│   ├── images</span><br><span class="line">│   │   ├── full</span><br><span class="line">│   │   └── thumbs</span><br><span class="line">│   │       └── format</span><br><span class="line">│   ├── imdbSpider</span><br><span class="line">│   │   ├── __init__<span class="selector-class">.py</span></span><br><span class="line">│   │   ├── items<span class="selector-class">.py</span></span><br><span class="line">│   │   ├── middlewares<span class="selector-class">.py</span></span><br><span class="line">│   │   ├── pipelines<span class="selector-class">.py</span></span><br><span class="line">│   │   ├── settings<span class="selector-class">.py</span></span><br><span class="line">│   │   └── spiders</span><br><span class="line">│   │       ├── __init__<span class="selector-class">.py</span></span><br><span class="line">│   │       ├── favourite<span class="selector-class">.py</span></span><br><span class="line">│   │       ├── list<span class="selector-class">.py</span></span><br><span class="line">│   │       └── new<span class="selector-class">.py</span></span><br><span class="line">│   ├── log</span><br><span class="line">│   │   ├── spider<span class="selector-class">.log</span></span><br><span class="line">│   │   ├── spy-list<span class="selector-class">.log</span></span><br><span class="line">│   │   └── spy-profile<span class="selector-class">.log</span></span><br><span class="line">│   ├── run<span class="selector-class">.sh</span></span><br><span class="line">│   ├── scrapy<span class="selector-class">.cfg</span></span><br><span class="line">│   └── spy<span class="selector-class">.sh</span></span><br><span class="line">└── pic</span><br><span class="line">    ├── project_structure<span class="selector-class">.png</span></span><br><span class="line">    ├── scrapy_logo<span class="selector-class">.png</span></span><br><span class="line">    ├── spider_structure<span class="selector-class">.png</span></span><br><span class="line">    └── structure.png</span><br></pre></td></tr></table></figure>

<h2 id="自动化部署与监视"><a href="#自动化部署与监视" class="headerlink" title="自动化部署与监视"></a>自动化部署与监视</h2><h3 id="crontab-自动化部署"><a href="#crontab-自动化部署" class="headerlink" title="crontab 自动化部署"></a>crontab 自动化部署</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">```shell</span><br><span class="line"># imdb-scrapy crontab profile</span><br><span class="line">0 8 * * * cd /home/apps/wj/stream-media-pump/imdbSpider;/bin/sh /home/apps/wj/stream-media-pump/imdbSpider/run.sh &gt; /home/apps/wj/stream-media-pump/imdbSpider/crontab-log.txt</span><br></pre></td></tr></table></figure>

<p>crontab的详细配置可以查看：<br><a href="https://wjmars98.github.io/2022/05/02/crontab/#more">Mars’ Blog crontab</a></p>
<h3 id="md5文件数据监视"><a href="#md5文件数据监视" class="headerlink" title="md5文件数据监视"></a>md5文件数据监视</h3><p>在imdb-scrapy项目中，存在对imdb-url-list文件进行监视的需求，当用户上传新的imdb-url-list时，服务器能够捕捉到数据改变，启动list 爬虫进行数爬取。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">监视shell 脚本储存于```imdbSpider/bin/spy-list.sh```中，如下所示。</span><br><span class="line">```shell</span><br><span class="line">#!/bin/sh</span><br><span class="line">while true</span><br><span class="line">do</span><br><span class="line">&#123;</span><br><span class="line">  cd /path/to/imdbSpider</span><br><span class="line">  # Using md5 to check whether the imdb-url-list changed.</span><br><span class="line">  char=$(md5sum -c conf/list/imdb-url-list.md5 2&gt;/dev/null|grep &quot;OK&quot;|wc -l)</span><br><span class="line"></span><br><span class="line">  if [ $char -eq 1 ];then</span><br><span class="line">    echo &quot;yes&quot;</span><br><span class="line">  else</span><br><span class="line">    echo &quot;begin output list csv&quot;</span><br><span class="line"></span><br><span class="line">    # Fetch the new list data</span><br><span class="line">    python -m scrapy crawl list</span><br><span class="line"></span><br><span class="line">    # Path of the server which store the report.</span><br><span class="line">    scp data/list.csv server:path</span><br><span class="line">    python bin/get_report.py -r &quot;list&quot;</span><br><span class="line"></span><br><span class="line">    # Update the imdb-url-list md5</span><br><span class="line">    md5sum conf/list/imdb-url-list &gt; conf/list/imdb-url-list.md5</span><br><span class="line">  fi</span><br><span class="line">  sleep 10</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://wjmars98.github.io/">1. Mars’ Blog</a></p>
<p><a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/intro/overview.html">2. 初窥Scrapy</a></p>
<p><a href="https://www.imdb.com/">3. imdb官网</a></p>
]]></content>
      <categories>
        <category>Projects</category>
      </categories>
      <tags>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title>Log4j</title>
    <url>/2022/04/13/log4j/</url>
    <content><![CDATA[<p>Apache Log4j是一个基于Java的日志记录工具</p>
<center>
        <img src="/2022/04/13/log4j/log4j_logo.jpg">
</center>

<span id="more"></span>

<p>Log4j是一种非常流行的日志框架。</p>
<p>Log4j是一个组件化设计的日志系统，它的架构大致如下：</p>
<center>
                <img src="/2022/04/13/log4j/log4j_structure.jpg" , width="80%">
</center>

<h1 id="log4j-结构"><a href="#log4j-结构" class="headerlink" title="log4j 结构"></a>log4j 结构</h1><h2 id="appender"><a href="#appender" class="headerlink" title="appender"></a>appender</h2><p>使用Log4j输出一条日志时，Log4j自动通过不同的Appender把同一条日志输出到不同的目的地。例如：</p>
<p>console：输出到屏幕；<br>file：输出到文件；<br>socket：通过网络输出到远程计算机；<br>jdbc：输出到数据库</p>
<h2 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h2><p>通过Filter来过滤哪些log需要被输出，哪些log不需要被输出。</p>
<p>其中，存在8个日志级别，优先级从高到低依次为：OFF、FATAL、ERROR、WARN、INFO、DEBUG、TRACE、 ALL。</p>
<h2 id="layout"><a href="#layout" class="headerlink" title="layout"></a>layout</h2><p>通过Layout来格式化日志信息，例如，自动添加日期、时间、方法名称等信息。</p>
<h1 id="log4j-使用"><a href="#log4j-使用" class="headerlink" title="log4j 使用"></a>log4j 使用</h1><p>上述结构虽然复杂，但我们在实际使用的时候，并不需要关心Log4j的API，而是通过配置文件来配置它。</p>
<h2 id="log4j-配置"><a href="#log4j-配置" class="headerlink" title="log4j 配置"></a>log4j 配置</h2><p>以xml配置为例，使用Log4j的时候，我们把一个log4j2.xml的文件放到classpath下就可以让Log4j读取配置文件并按照我们的配置来输出日志。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">Configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">Properties</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 定义日志格式 --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">Property</span> <span class="attr">name</span>=<span class="string">&quot;log.pattern&quot;</span>&gt;</span>%d&#123;MM-dd HH:mm:ss.SSS&#125; [%t] %-5level %logger&#123;36&#125;%n%msg%n%n<span class="tag">&lt;/<span class="name">Property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 定义文件名变量 --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">Property</span> <span class="attr">name</span>=<span class="string">&quot;file.err.filename&quot;</span>&gt;</span>log/err.log<span class="tag">&lt;/<span class="name">Property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">Property</span> <span class="attr">name</span>=<span class="string">&quot;file.err.pattern&quot;</span>&gt;</span>log/err.%i.log.gz<span class="tag">&lt;/<span class="name">Property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">Properties</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 定义Appender，即目的地 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">Appenders</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 定义输出到屏幕 --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">Console</span> <span class="attr">name</span>=<span class="string">&quot;console&quot;</span> <span class="attr">target</span>=<span class="string">&quot;SYSTEM_OUT&quot;</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 日志格式引用上面定义的log.pattern --&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">PatternLayout</span> <span class="attr">pattern</span>=<span class="string">&quot;$&#123;log.pattern&#125;&quot;</span> /&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">Console</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 定义输出到文件,文件名引用上面定义的file.err.filename --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">RollingFile</span> <span class="attr">name</span>=<span class="string">&quot;err&quot;</span> <span class="attr">bufferedIO</span>=<span class="string">&quot;true&quot;</span> <span class="attr">fileName</span>=<span class="string">&quot;$&#123;file.err.filename&#125;&quot;</span> <span class="attr">filePattern</span>=<span class="string">&quot;$&#123;file.err.pattern&#125;&quot;</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">PatternLayout</span> <span class="attr">pattern</span>=<span class="string">&quot;$&#123;log.pattern&#125;&quot;</span> /&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Policies</span>&gt;</span></span><br><span class="line">                <span class="comment">&lt;!-- 根据文件大小自动切割日志 --&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">SizeBasedTriggeringPolicy</span> <span class="attr">size</span>=<span class="string">&quot;1 MB&quot;</span> /&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">Policies</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 保留最近10份 --&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">DefaultRolloverStrategy</span> <span class="attr">max</span>=<span class="string">&quot;10&quot;</span> /&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">RollingFile</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">Appenders</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">Loggers</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">Root</span> <span class="attr">level</span>=<span class="string">&quot;info&quot;</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 对info级别的日志，输出到console --&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">AppenderRef</span> <span class="attr">ref</span>=<span class="string">&quot;console&quot;</span> <span class="attr">level</span>=<span class="string">&quot;info&quot;</span> /&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 对error级别的日志，输出到err，即上面定义的RollingFile --&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">AppenderRef</span> <span class="attr">ref</span>=<span class="string">&quot;err&quot;</span> <span class="attr">level</span>=<span class="string">&quot;error&quot;</span> /&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">Root</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">Loggers</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">Configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://www.liaoxuefeng.com/wiki/1252599548343744/1264739436350112">使用Log4j</a></li>
</ol>
]]></content>
      <categories>
        <category>Basic</category>
      </categories>
      <tags>
        <tag>Log4j</tag>
      </tags>
  </entry>
  <entry>
    <title>随想录：长期竞争价值</title>
    <url>/2022/04/19/%E9%9A%8F%E6%83%B3%E5%BD%95%EF%BC%9A%E9%95%BF%E6%9C%9F%E7%AB%9E%E4%BA%89%E4%BB%B7%E5%80%BC/</url>
    <content><![CDATA[<p>我之后会不断记录下自己的想法、自己的生活，或者对之前的想法进行批判。希望这篇随想是随想的录的开始而非结束。</p>
<p>综上，为了应对未来的中年危机，我有提升技术的必要，但千万不能以为仅仅自己凭借技术能养活自己一辈子；其次，我得去寻找自身的平衡点，了解多个领域的知识，尽量做跨领域的工作，能够减少自身的竞争压力；第三，当前国内就业环境太差，我可以利用自己出国留学的机会，正确去国外工作几年，相信国外的工作经验也是自己的长期竞争力之一。我们要学会构建自己的长期竞争力，而构建自身长期竞争力的方法与途径就是不断对自己进行长期投资。</p>
<center>
        <img src="/2022/04/19/%E9%9A%8F%E6%83%B3%E5%BD%95%EF%BC%9A%E9%95%BF%E6%9C%9F%E7%AB%9E%E4%BA%89%E4%BB%B7%E5%80%BC/first.jpg" , width="80%">
</center>
<span id="more"></span>

<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>到广州实习的第一个月，遇见了各类形形色色的人，做了陌生完全不熟悉的事，接受的海量的外界信息，对自己的生活态度乃至价值观产生了巨大的冲击。</p>
<p>最近自己逐渐养成了一个习惯——思考。不但是对眼前所欲事物的思考，更是对自己职业规划，自己人生理想与目标的思考。虽然和父母的交流中，他们更希望我不要多想，安心做眼前的事物。但是我还是觉得多思考总归是胜于麻木盲从，思考也让我受益非浅。</p>
<p>遂建立随想录这一目录，记录一些自己的思考过程与结果，或长或短，或真知灼见，或可笑万分，我姑且都记下，就当作是眼下生活的小小总结，留下些许痕迹。</p>
<h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><p>最近，一直在思考自己未来10年后，也就是程序员的35岁的中年危机我该如何度过。30到35岁是一道坎，很多搞技术的人也就倒在这到坎上，一蹶不振，我该如何去应对，是否应该按部就班的听我父母一步一个脚印走好，比如：找份大厂工作，好好努力，一步一个脚印走上高级技术员或者管理层等等。</p>
<p>在和俊哥吃饭的时候，我也聊到35岁危机的问题，他提出一个长期竞争力的概念，我觉得还是挺有道理。</p>
<p>第一，是扎实底层技术。我们常说核心竞争力，但是到底什么是核心竞争力呢？说白了，就是你的某个优势，别人难以取代，可以称为你的核心竞争力。俊哥也由此展开，说明互联网的技术日新月异，但是其底层的技术其实变化十分缓慢，如果把底层的技术打扎实了，那么学习新技术的时间也就很短，能维持自己长期的竞争力，这点是值得我去思考与学习的，不断扎实自己对底层技术的了解。</p>
<p>第二，平衡点。中国是一个人口大国，近年经济形势下滑，考研考公人数屡创新高，这也说明了在未来的一段时间人才与职位会出现供大于求，竞争异常激烈。</p>
<p>第一条路，不断提升自己技术，卷过绝大多数人。这也是我父母期望我走的路，按部就班，一步一个较硬。但是这难度真的实在太大了，竞争的人数是如此之多，而且未来会更多，我们每个人就像一颗螺丝钉，完全可以替换，对自己的健康也会有很大的损坏，而且我也不认为自己是一个长于技术的人，这条路对我来说性价比不高，虽然技术是我的立足之本，但我不能靠技术吃一辈子的饭。</p>
<p>第二条路，寻找自己多领域的平衡点。当前的赛道竞争对手是如此之多，是否有办法寻找一条跨学科交叉的道路，减少我们的竞争压力。比如数据与金融的结合，数据与车企的结合，数据与医疗的结合等等，这都是值得我去研究的领域。找到适合自己的平衡点，多放下注，广积粮（扎实技术，保持多领域信息优势，减少信息差）、缓称王（不要没思考、调研，就浪费大量精力前进）。</p>
<p>第三条路，更换自己的环境。目前国内的就业环境不行，但并不代表这国外的坏境不行。可以尝试去外企，或者一步到位直接利用自己去hk留学的继续，去hk或者新加坡、新西兰、澳大利亚找相应的岗位，也是未尝不可。这里又涉及绿卡移民的问题，值得我之后为此专门写一篇文章聊聊。</p>
<p>我要时刻问问自己，自己向往什么样的生活？成为大厂的一颗螺丝钉，还是有自己的生活，实现wlb，靠投资实现财富自由。永远学会去投资自己，要做长期投资，比如学习新的技能（保持生活的新鲜感），扎实自己的技术（这是我的立足之本），多结交优秀的朋友（了解更多行业的情况），等等。</p>
<p>虽然长期投资的回报是有延后性的，但是长期投资的回报也是丰厚。因为我们在时间是公平的，我们在对自己进行长期投资，正是在培养自身的长期竞争力，而别人要取代你的优势，也需要付出相应的时间成本，这是有门槛的，所以多做对自己作长期投资吧，我的朋友。</p>
<p>虽然长期投资是如此重要，但这也不代表着我们要放弃短期的收益，比如准备考试、应酬、娱乐等等。短期投资，回报快，能增长自己生活的激情。但是千万不要做竭泽而渔，比如沉迷于游戏，沉迷于无意义的消遣。任何致瘾的都是有害的，千万小心。</p>
<h1 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h1><p>综上，为了应对未来的中年危机，我有提升技术的必要，但千万不能以为仅仅自己凭借技术能养活自己一辈子；其次，我得去寻找自身的平衡点，了解多个领域的知识，尽量做跨领域的工作，能够减少自身的竞争压力；第三，当前国内就业环境太差，我可以利用自己出国留学的机会，正确去国外工作几年，相信国外的工作经验也是自己的长期竞争力之一。我们要学会构建自己的长期竞争力，而构建自身长期竞争力的方法与途径就是不断对自己进行长期投资。</p>
<p>我之后会不断记录下自己的想法、自己的生活，或者对之前的想法进行批判。希望这篇随想是随想的录的开始而非结束，</p>
]]></content>
      <categories>
        <category>Collection Of Essays</category>
      </categories>
      <tags>
        <tag>essay</tag>
      </tags>
  </entry>
</search>
